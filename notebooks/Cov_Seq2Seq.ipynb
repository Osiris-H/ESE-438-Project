{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "RVEbNLwtHBcc",
        "Igp6-0E_4nTG",
        "ANHHvcVR3kYR",
        "TRYyFZvZ4uN-",
        "x8JxG2ow8Mo4",
        "clynP5e2WO28",
        "JrNuvmPvbJsR",
        "sp_0qNUxaecE",
        "GBwOAd2pc-E8"
      ],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()  # 先做一次账号授权\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Omo5nMk33VAN",
        "outputId": "0612759b-ed73-43a5-978d-a10c2f813a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd drive/MyDrive/ESE5380TimeSeries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qGCg2RP4Zks",
        "outputId": "f5d4d098-7e7b-4a3d-fd98-eb7e759eaead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ESE5380TimeSeries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download package"
      ],
      "metadata": {
        "id": "RVEbNLwtHBcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) 升级 pip（用当前 Python 的 pip）\n",
        "!pip install -U pip\n",
        "\n",
        "# 2) 安装 PyTorch 2.4.0 + cu118（三件套）\n",
        "# !pip install \\\n",
        "#   \"torch==2.4.0+cu118\" \\\n",
        "#   \"torchvision==0.19.0+cu118\" \\\n",
        "#   \"torchaudio==2.4.0+cu118\" \\\n",
        "#   --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# 3) 安装 xarray + zarr + numcodecs + gcsfs\n",
        "#    （numcodecs 是刚才缺的那个 _shuffle 扩展）\n",
        "!pip install \\\n",
        "  \"numpy\" \\\n",
        "  \"pandas\" \\\n",
        "  \"xarray>=2024.6.0\" \\\n",
        "  \"zarr>=2.18.0\" \\\n",
        "  \"numcodecs>=0.13.1\" \\\n",
        "  \"gcsfs>=2024.6.0\"\n",
        "\n",
        "!python -m pip install \"dask[complete]\"\n",
        "!pip install zarr numcodecs gcsfs fsspec\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnA7oNHAHrYl",
        "outputId": "964ded7d-2732-40ae-8221-8bb81ee62247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: xarray>=2024.6.0 in /usr/local/lib/python3.12/dist-packages (2025.12.0)\n",
            "Collecting zarr>=2.18.0\n",
            "  Downloading zarr-3.1.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting numcodecs>=0.13.1\n",
            "  Downloading numcodecs-0.16.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: gcsfs>=2024.6.0 in /usr/local/lib/python3.12/dist-packages (2025.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.12/dist-packages (from xarray>=2024.6.0) (25.0)\n",
            "Collecting donfig>=0.8 (from zarr>=2.18.0)\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: google-crc32c>=1.5 in /usr/local/lib/python3.12/dist-packages (from zarr>=2.18.0) (1.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9 in /usr/local/lib/python3.12/dist-packages (from zarr>=2.18.0) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.6.0) (3.13.2)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.6.0) (4.4.2)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.6.0) (2025.3.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.6.0) (2.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.6.0) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.6.0) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from gcsfs>=2024.6.0) (2.32.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2024.6.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2024.6.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2024.6.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2024.6.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2024.6.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2024.6.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2024.6.0) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs>=2024.6.0) (3.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr>=2.18.0) (6.0.3)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2024.6.0) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2024.6.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs>=2024.6.0) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs>=2024.6.0) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib->gcsfs>=2024.6.0) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.6.0) (3.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->gcsfs>=2024.6.0) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->gcsfs>=2024.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->gcsfs>=2024.6.0) (2025.11.12)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs>=2024.6.0) (2.28.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs>=2024.6.0) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs>=2024.6.0) (2.8.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs>=2024.6.0) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs>=2024.6.0) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs>=2024.6.0) (1.26.1)\n",
            "Downloading zarr-3.1.5-py3-none-any.whl (284 kB)\n",
            "Downloading numcodecs-0.16.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (9.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: numcodecs, donfig, zarr\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [zarr]\n",
            "\u001b[1A\u001b[2KSuccessfully installed donfig-0.8.1.post1 numcodecs-0.16.5 zarr-3.1.5\n",
            "Requirement already satisfied: dask[complete] in /usr/local/lib/python3.12/dist-packages (2025.9.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (3.1.2)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (25.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (6.0.3)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (0.12.1)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (18.1.0)\n",
            "Collecting lz4>=4.3.2 (from dask[complete])\n",
            "  Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.12/dist-packages (from partd>=1.4.0->dask[complete]) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (2.2.2)\n",
            "Requirement already satisfied: distributed==2025.9.1 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (2025.9.1)\n",
            "Requirement already satisfied: bokeh>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (3.7.3)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from dask[complete]) (3.1.6)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (1.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (3.2.2)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (6.5.1)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (2.5.0)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed==2025.9.1->dask[complete]) (3.0.0)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.12/dist-packages (from bokeh>=3.1.0->dask[complete]) (1.3.3)\n",
            "Requirement already satisfied: narwhals>=1.13 in /usr/local/lib/python3.12/dist-packages (from bokeh>=3.1.0->dask[complete]) (2.13.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from bokeh>=3.1.0->dask[complete]) (11.3.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.12/dist-packages (from bokeh>=3.1.0->dask[complete]) (2025.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.10.3->dask[complete]) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[complete]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[complete]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0->dask[complete]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[complete]) (1.17.0)\n",
            "Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4\n",
            "Successfully installed lz4-4.4.5\n",
            "Requirement already satisfied: zarr in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numcodecs in /usr/local/lib/python3.12/dist-packages (0.16.5)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.12/dist-packages (2025.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (2025.3.0)\n",
            "Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.12/dist-packages (from zarr) (0.8.1.post1)\n",
            "Requirement already satisfied: google-crc32c>=1.5 in /usr/local/lib/python3.12/dist-packages (from zarr) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from zarr) (2.0.2)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from zarr) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9 in /usr/local/lib/python3.12/dist-packages (from zarr) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from gcsfs) (3.13.2)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.12/dist-packages (from gcsfs) (2.43.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.12/dist-packages (from gcsfs) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from gcsfs) (3.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from gcsfs) (2.32.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (3.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr) (6.0.3)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.2->gcsfs) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib->gcsfs) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.3.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->gcsfs) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->gcsfs) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->gcsfs) (2025.11.12)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.27.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs) (2.28.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->gcsfs) (2.8.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.27.0->google-cloud-storage->gcsfs) (1.26.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download Data"
      ],
      "metadata": {
        "id": "Igp6-0E_4nTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "import os, time\n",
        "\n",
        "print(\"xarray version:\", xr.__version__)\n",
        "\n",
        "# gcs_path_6h = (\n",
        "#     \"gs://weatherbench2/datasets/era5/\"\n",
        "#     \"1959-2023_01_10-6h-240x121_equiangular_with_poles_conservative.zarr\"\n",
        "# )\n",
        "\n",
        "gcs_path_1h = (\n",
        "    \"gs://weatherbench2/datasets/era5/\"\n",
        "    \"1959-2023_01_10-1h-240x121_equiangular_with_poles_conservative.zarr\" # 1.5 deg resolution\n",
        ")\n",
        "\n",
        "# 1959-2022-1h-240x121_equiangular_with_poles_conservative.zarr --> 1.5 deg resolution\n",
        "# weatherbench2/datasets/era5/1959-2023_01_10-1h-240x121_equiangular_with_poles_conservative.zarr\n",
        "\n",
        "\n",
        "# print(f\"正在打开 GCS 路径 (1.5-deg, 6-hourly): {gcs_path_6h}\")\n",
        "\n",
        "# ds_6h = xr.open_dataset(\n",
        "#     gcs_path_6h,\n",
        "#     engine=\"zarr\",\n",
        "#     chunks={},\n",
        "#     storage_options={\"token\": \"anon\"},\n",
        "# )\n",
        "# print(\"6-hourly 数据集元数据加载成功。\")\n",
        "\n",
        "\n",
        "### valid\n",
        "ds_1h = xr.open_dataset(\n",
        "    gcs_path_1h,\n",
        "    engine=\"zarr\",\n",
        "    chunks={},\n",
        "    storage_options={\"token\": \"anon\"},\n",
        ")\n",
        "print(\"1-hourly 数据集元数据加载成功。\")\n",
        "\n",
        "# data_train = ds_6h.sel(time=slice(\"2019-01-01\", \"2021-12-31\"))\n",
        "\n",
        "# data_2022 = ds_6h.sel(time=slice(\"2022-01-01\", \"2022-12-31\")) # test dataset\n",
        "\n",
        "\n",
        "\n",
        "data_train = ds_1h.sel(time=slice(\"2019-01-01\", \"2020-12-31\"))\n",
        "data_val   = ds_1h.sel(time=slice(\"2021-01-01\", \"2021-12-31\"))\n",
        "data_test  = ds_1h.sel(time=slice(\"2022-01-01\", \"2022-12-31\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "variables = [\n",
        "    \"2m_temperature\",\n",
        "    \"10m_u_component_of_wind\",\n",
        "    \"10m_v_component_of_wind\",\n",
        "    \"mean_sea_level_pressure\",\n",
        "    \"total_precipitation\"\n",
        "]\n",
        "data_vars = data_train[variables]\n",
        "\n",
        "\n",
        "\n",
        "# # 裁剪纬度: 121 -> 112 (H)\n",
        "# data_final_lazy = data_vars.isel(latitude=slice(0, 112))\n",
        "\n",
        "# H:121 * W:240\n",
        "\n",
        "data_final_lazy = data_vars\n",
        "print(data_final_lazy)\n",
        "print(f\"T={len(data_final_lazy.time)}, \"\n",
        "      f\"H={len(data_final_lazy.latitude)}, \"\n",
        "      f\"W={len(data_final_lazy.longitude)}, \"\n",
        "      f\"C={len(data_final_lazy.data_vars)}\")\n",
        "\n",
        "# array: dims: (variable, time, latitude, longitude)\n",
        "data_array = data_final_lazy.to_array(dim=\"variable\")\n",
        "# convert to (T, H, W, C)\n",
        "data_np = data_array.transpose(\"time\", \"latitude\", \"longitude\", \"variable\").values.astype(np.float32)\n",
        "\n",
        "T_all, H, W, C = data_np.shape\n",
        "print(f\"all_data shape: {data_np.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YN4elu6HHR7",
        "outputId": "5e9ee353-7ded-4484-cf2e-3959625be2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xarray version: 2025.12.0\n",
            "1-hourly 数据集元数据加载成功。\n",
            "<xarray.Dataset> Size: 10GB\n",
            "Dimensions:                  (time: 17544, longitude: 240, latitude: 121)\n",
            "Coordinates:\n",
            "  * time                     (time) datetime64[ns] 140kB 2019-01-01 ... 2020-...\n",
            "  * longitude                (longitude) float64 2kB 0.0 1.5 3.0 ... 357.0 358.5\n",
            "  * latitude                 (latitude) float64 968B -90.0 -88.5 ... 88.5 90.0\n",
            "Data variables:\n",
            "    2m_temperature           (time, longitude, latitude) float32 2GB dask.array<chunksize=(24, 240, 121), meta=np.ndarray>\n",
            "    10m_u_component_of_wind  (time, longitude, latitude) float32 2GB dask.array<chunksize=(24, 240, 121), meta=np.ndarray>\n",
            "    10m_v_component_of_wind  (time, longitude, latitude) float32 2GB dask.array<chunksize=(24, 240, 121), meta=np.ndarray>\n",
            "    mean_sea_level_pressure  (time, longitude, latitude) float32 2GB dask.array<chunksize=(24, 240, 121), meta=np.ndarray>\n",
            "    total_precipitation      (time, longitude, latitude) float32 2GB dask.array<chunksize=(24, 240, 121), meta=np.ndarray>\n",
            "T=17544, H=121, W=240, C=5\n",
            "all_data shape: (17544, 121, 240, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataloader(Old Version)"
      ],
      "metadata": {
        "id": "ANHHvcVR3kYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "variables = [\n",
        "    \"2m_temperature\",\n",
        "    \"10m_u_component_of_wind\",\n",
        "    \"10m_v_component_of_wind\",\n",
        "    \"mean_sea_level_pressure\",\n",
        "    \"total_precipitation\",\n",
        "]\n",
        "\n",
        "class ERA5XYDataset(Dataset):\n",
        "    def __init__(self, data_np: np.ndarray, variables: list[str],\n",
        "                 sample_step: int = 6,\n",
        "                 x_len: int = 8, y_len: int = 4,\n",
        "                 stride: int = 1,\n",
        "                 normalize: bool = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_np: (T, H, W, C)\n",
        "            variables: 变量名\n",
        "            sample_step: 6h 聚合步长\n",
        "        \"\"\"\n",
        "        self.variables = variables\n",
        "        self.x_len = x_len\n",
        "        self.y_len = y_len\n",
        "        self.normalize = normalize\n",
        "\n",
        "        # 找 total_precipitation 通道\n",
        "        tp_idx = variables.index(\"total_precipitation\") if \"total_precipitation\" in variables else None\n",
        "\n",
        "        # --- 1️⃣ 构建 6 小时步数据 ---\n",
        "        data_list = []\n",
        "        for c in range(data_np.shape[-1]):\n",
        "            if c == tp_idx:\n",
        "                # 降水 → 过去6小时累计\n",
        "                summed = np.add.reduceat(data_np[..., c], np.arange(0, data_np.shape[0], sample_step), axis=0)\n",
        "                data_list.append(summed[..., None])\n",
        "            else:\n",
        "                # 其他变量 → 每6小时取当前值\n",
        "                sampled = data_np[sample_step-1::sample_step, :, :, c]\n",
        "                data_list.append(sampled[..., None])\n",
        "\n",
        "        data_6h = np.concatenate(data_list, axis=-1)  # (T6,H,W,C)\n",
        "        self.data = data_6h\n",
        "        T, H, W, C = data_6h.shape\n",
        "\n",
        "        # --- 2️⃣ 构造滑动窗口索引 ---\n",
        "        Xs, Ys = [], []\n",
        "        for start in range(0, T - (x_len + y_len), stride):\n",
        "            x_idx = np.arange(start, start + x_len)\n",
        "            y_idx = np.arange(start + x_len, start + x_len + y_len)\n",
        "            Xs.append(x_idx)\n",
        "            Ys.append(y_idx)\n",
        "        self.indices = list(zip(Xs, Ys))\n",
        "\n",
        "        # --- 3️⃣ 均值方差（只用于 normalization） ---\n",
        "        mean = data_6h.mean(axis=(0, 1, 2), keepdims=True)\n",
        "        std = data_6h.std(axis=(0, 1, 2), keepdims=True) + 1e-6\n",
        "        self.mean = torch.from_numpy(mean).permute(3, 0, 1, 2).float()\n",
        "        self.std = torch.from_numpy(std).permute(3, 0, 1, 2).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_idx, y_idx = self.indices[idx]\n",
        "        x = self.data[x_idx]  # (Tin, H, W, C)\n",
        "        y = self.data[y_idx]  # (Tout, H, W, C)\n",
        "\n",
        "        # 转换为 torch tensor\n",
        "        x = torch.from_numpy(x).permute(0, 3, 1, 2).float()  # (Tin, C, H, W)\n",
        "        y = torch.from_numpy(y).permute(0, 3, 1, 2).float()  # (Tout, C, H, W)\n",
        "\n",
        "        if self.normalize:\n",
        "            mean = self.mean.squeeze(1)  # (C,1,1)\n",
        "            std = self.std.squeeze(1)    # (C,1,1)\n",
        "            x = (x - mean) / std         # 广播: Tin 与 (C,1,1)\n",
        "            y = (y - mean) / std\n",
        "        return x, y\n",
        "\n",
        "\n",
        "def xr_to_np(ds):\n",
        "    arr = ds[variables].to_array(dim=\"variable\")\n",
        "    return arr.transpose(\"time\", \"latitude\", \"longitude\", \"variable\").values.astype(np.float32)\n",
        "\n",
        "np_train = xr_to_np(data_train)\n",
        "np_val   = xr_to_np(data_val)\n",
        "\n",
        "# ===== 假设你已经有 np_train, np_val =====\n",
        "# 比如你前面用 xarray 转好了：\n",
        "# import xarray as xr\n",
        "# def xr_to_np(ds):\n",
        "#     arr = ds[variables].to_array(dim=\"variable\")\n",
        "#     return arr.transpose(\"time\", \"latitude\", \"longitude\", \"variable\").values.astype(np.float32)\n",
        "# np_train = xr_to_np(data_train)\n",
        "# np_val   = xr_to_np(data_val)\n",
        "\n",
        "ds_train = ERA5XYDataset(np_train, variables)\n",
        "ds_val   = ERA5XYDataset(np_val, variables)\n",
        "\n",
        "train_loader = DataLoader(ds_train, batch_size=2, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "val_loader   = DataLoader(ds_val,   batch_size=2, shuffle=False, num_workers=0, pin_memory=False)\n",
        "\n",
        "print(f\"Train samples: {len(ds_train)} | Val samples: {len(ds_val)}\")\n",
        "x_in, y_out = next(iter(train_loader))\n",
        "print(\"x_in:\", x_in.shape)\n",
        "print(\"y_out:\", y_out.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr7qQwWOyqhs",
        "outputId": "f3d70613-6ce5-4b01-8b8a-5e5be55c0798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 2912 | Val samples: 1448\n",
            "x_in: torch.Size([2, 8, 5, 121, 240])\n",
            "y_out: torch.Size([2, 4, 5, 121, 240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataloader(New version)"
      ],
      "metadata": {
        "id": "TRYyFZvZ4uN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "variables = [\n",
        "    \"2m_temperature\",\n",
        "    \"10m_u_component_of_wind\",\n",
        "    \"10m_v_component_of_wind\",\n",
        "    \"mean_sea_level_pressure\",\n",
        "    \"total_precipitation\",\n",
        "]\n",
        "\n",
        "class ERA5XYDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_np: np.ndarray,          # (T, H, W, C)\n",
        "        variables: list[str],\n",
        "        sample_step: int = 6,\n",
        "        x_len: int = 8,\n",
        "        y_len: int = 4,\n",
        "        stride: int = 1,\n",
        "        normalize: bool = True,\n",
        "        mean: torch.Tensor | None = None,   # 允许外部传入 mean/std (C,1,1,1) or (1,1,1,C)\n",
        "        std:  torch.Tensor | None = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_np: (T, H, W, C)\n",
        "            variables: 变量名\n",
        "            sample_step: 例如 6 表示从 1h 分辨率聚合到 6h\n",
        "            x_len: 输入序列长度（时间步数）\n",
        "            y_len: 预测序列长度（时间步数）\n",
        "            stride: 滑动窗口步长\n",
        "            normalize: 是否返回标准化后的 x,y\n",
        "            mean/std: 若不为 None，则使用给定的 mean/std 进行归一化\n",
        "        \"\"\"\n",
        "        self.variables = variables\n",
        "        self.x_len = x_len\n",
        "        self.y_len = y_len\n",
        "        self.normalize = normalize\n",
        "\n",
        "        # -------- 1️⃣ 6h 聚合 --------\n",
        "        tp_idx = variables.index(\"total_precipitation\") if \"total_precipitation\" in variables else None\n",
        "\n",
        "        data_list = []\n",
        "        T_raw = data_np.shape[0]\n",
        "        for c in range(data_np.shape[-1]):\n",
        "            if c == tp_idx:\n",
        "                # total_precipitation: 过去 6 小时累计\n",
        "                summed = np.add.reduceat(\n",
        "                    data_np[..., c],\n",
        "                    np.arange(0, T_raw, sample_step),\n",
        "                    axis=0\n",
        "                )  # (T6, H, W)\n",
        "                data_list.append(summed[..., None])  # (T6,H,W,1)\n",
        "            else:\n",
        "                # 其他变量: 每 6 小时取一个 instantaneous 值（比如 5,11,17,...）\n",
        "                sampled = data_np[sample_step-1::sample_step, :, :, c]  # (T6,H,W)\n",
        "                data_list.append(sampled[..., None])\n",
        "\n",
        "        data_6h = np.concatenate(data_list, axis=-1)  # (T6, H, W, C)\n",
        "        self.data = data_6h\n",
        "        T, H, W, C = data_6h.shape\n",
        "\n",
        "        # -------- 2️⃣ 滑动窗口索引（修复 off-by-one） --------\n",
        "        Xs, Ys = [], []\n",
        "        max_start = T - (x_len + y_len)\n",
        "        for start in range(0, max_start + 1, stride):\n",
        "            x_idx = np.arange(start, start + x_len)\n",
        "            y_idx = np.arange(start + x_len, start + x_len + y_len)\n",
        "            Xs.append(x_idx)\n",
        "            Ys.append(y_idx)\n",
        "        self.indices = list(zip(Xs, Ys))\n",
        "\n",
        "        # -------- 3️⃣ 计算或接收 mean/std --------\n",
        "        if mean is None or std is None:\n",
        "            # 按 (T,H,W) 维度求各通道统计量\n",
        "            mean_np = data_6h.mean(axis=(0, 1, 2), keepdims=True)  # (1,1,1,C)\n",
        "            std_np  = data_6h.std(axis=(0, 1, 2), keepdims=True) + 1e-6\n",
        "            mean_t  = torch.from_numpy(mean_np).permute(3, 0, 1, 2).float()  # (C,1,1,1)\n",
        "            std_t   = torch.from_numpy(std_np ).permute(3, 0, 1, 2).float()  # (C,1,1,1)\n",
        "        else:\n",
        "            # 允许传入 (C,1,1,1) 或 (1,C,1,1) 等，统一成 (C,1,1,1)\n",
        "            mean_t = mean\n",
        "            std_t  = std\n",
        "            if mean_t.ndim == 4 and mean_t.shape[0] == 1:\n",
        "                # (1,C,1,1) -> (C,1,1,1)\n",
        "                mean_t = mean_t.permute(1,0,2,3).contiguous()\n",
        "            if std_t.ndim == 4 and std_t.shape[0] == 1:\n",
        "                std_t = std_t.permute(1,0,2,3).contiguous()\n",
        "            mean_t = mean_t.float()\n",
        "            std_t  = std_t.float()\n",
        "\n",
        "        self.mean = mean_t  # (C,1,1,1)\n",
        "        self.std  = std_t   # (C,1,1,1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_idx, y_idx = self.indices[idx]\n",
        "        x = self.data[x_idx]  # (Tin, H, W, C)\n",
        "        y = self.data[y_idx]  # (Tout, H, W, C)\n",
        "\n",
        "        # -> torch & 调整维度为 (T,C,H,W)\n",
        "        x = torch.from_numpy(x).permute(0, 3, 1, 2).float()\n",
        "        y = torch.from_numpy(y).permute(0, 3, 1, 2).float()\n",
        "\n",
        "        if self.normalize:\n",
        "            # self.mean/self.std: (C,1,1,1)\n",
        "            mean = self.mean.squeeze(1)  # (C,1,1)\n",
        "            std  = self.std.squeeze(1)   # (C,1,1)\n",
        "            x = (x - mean) / std\n",
        "            y = (y - mean) / std\n",
        "\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "cpfHDUoh4_U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "\n",
        "def xr_to_np(ds):\n",
        "    # ds: xarray.Dataset，包含 variables 中的变量\n",
        "    arr = ds[variables].to_array(dim=\"variable\") \\\n",
        "                       .transpose(\"time\", \"latitude\", \"longitude\", \"variable\")\n",
        "    return arr.values.astype(np.float32)  # (T,H,W,C)\n",
        "\n",
        "# 假设你已经有 data_train, data_val 两个 xarray.Dataset\n",
        "np_train = xr_to_np(data_train)\n",
        "np_val   = xr_to_np(data_val)\n",
        "\n",
        "# 1) 先构建 train dataset，让它自己算 mean/std\n",
        "ds_train = ERA5XYDataset(\n",
        "    np_train,\n",
        "    variables,\n",
        "    sample_step=6,\n",
        "    x_len=8,\n",
        "    y_len=4,\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        ")\n",
        "\n",
        "# 2) val 复用 train 的 mean/std（保证归一化一致）\n",
        "ds_val = ERA5XYDataset(\n",
        "    np_val,\n",
        "    variables,\n",
        "    sample_step=6,\n",
        "    x_len=8,\n",
        "    y_len=4,\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        "    mean=ds_train.mean,\n",
        "    std=ds_train.std,\n",
        ")\n",
        "\n",
        "# 3) DataLoader\n",
        "train_loader = DataLoader(ds_train, batch_size=2, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "val_loader   = DataLoader(ds_val,   batch_size=2, shuffle=False, num_workers=0, pin_memory=False)\n",
        "\n",
        "print(f\"Train samples: {len(ds_train)} | Val samples: {len(ds_val)}\")\n",
        "x_in, y_out = next(iter(train_loader))\n",
        "print(\"x_in:\", x_in.shape)   # (B, Tin, C, H, W)\n",
        "print(\"y_out:\", y_out.shape) # (B, Tout, C, H, W)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdpziSt95AXJ",
        "outputId": "5f365bc6-472c-4019-f3b9-9be28e338632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 2913 | Val samples: 1449\n",
            "x_in: torch.Size([2, 8, 5, 121, 240])\n",
            "y_out: torch.Size([2, 4, 5, 121, 240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataloader(6h New version)"
      ],
      "metadata": {
        "id": "x8JxG2ow8Mo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "\n",
        "print(\"xarray version:\", xr.__version__)\n",
        "\n",
        "# 6-hourly ERA5 (WeatherBench2 提供的 1.5° 数据)\n",
        "gcs_path_6h = (\n",
        "    \"gs://weatherbench2/datasets/era5/\"\n",
        "    \"1959-2023_01_10-6h-240x121_equiangular_with_poles_conservative.zarr\"\n",
        ")\n",
        "\n",
        "print(f\"正在打开 GCS 路径 (1.5-deg, 6-hourly): {gcs_path_6h}\")\n",
        "\n",
        "ds_6h = xr.open_dataset(\n",
        "    gcs_path_6h,\n",
        "    engine=\"zarr\",\n",
        "    chunks={},\n",
        "    storage_options={\"token\": \"anon\"},\n",
        ")\n",
        "\n",
        "print(\"6-hourly 数据集元数据加载成功。\")\n",
        "print(ds_6h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUPqv5tb_JxR",
        "outputId": "167d92f3-e596-4fc5-fe81-b781be347758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xarray version: 2025.12.0\n",
            "正在打开 GCS 路径 (1.5-deg, 6-hourly): gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-240x121_equiangular_with_poles_conservative.zarr\n",
            "6-hourly 数据集元数据加载成功。\n",
            "<xarray.Dataset> Size: 2TB\n",
            "Dimensions:                                           (time: 93544,\n",
            "                                                       longitude: 240,\n",
            "                                                       latitude: 121, level: 13)\n",
            "Coordinates:\n",
            "  * time                                              (time) datetime64[ns] 748kB ...\n",
            "  * longitude                                         (longitude) float64 2kB ...\n",
            "  * latitude                                          (latitude) float64 968B ...\n",
            "  * level                                             (level) int64 104B 50 ....\n",
            "Data variables: (12/62)\n",
            "    10m_u_component_of_wind                           (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    10m_v_component_of_wind                           (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    10m_wind_speed                                    (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    2m_dewpoint_temperature                           (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    2m_temperature                                    (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    above_ground                                      (time, level, longitude, latitude) float32 141GB dask.array<chunksize=(8, 13, 240, 121), meta=np.ndarray>\n",
            "    ...                                                ...\n",
            "    volumetric_soil_water_layer_1                     (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    volumetric_soil_water_layer_2                     (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    volumetric_soil_water_layer_3                     (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    volumetric_soil_water_layer_4                     (time, longitude, latitude) float32 11GB dask.array<chunksize=(8, 240, 121), meta=np.ndarray>\n",
            "    vorticity                                         (time, level, longitude, latitude) float32 141GB dask.array<chunksize=(8, 13, 240, 121), meta=np.ndarray>\n",
            "    wind_speed                                        (time, level, longitude, latitude) float32 141GB dask.array<chunksize=(8, 13, 240, 121), meta=np.ndarray>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_train = ds_6h.sel(time=slice(\"2019-01-01\", \"2020-12-31\"))\n",
        "data_val   = ds_6h.sel(time=slice(\"2021-01-01\", \"2021-12-31\"))\n",
        "data_test  = ds_6h.sel(time=slice(\"2022-01-01\", \"2022-12-31\"))\n"
      ],
      "metadata": {
        "id": "DQ6vZS0D_LAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variables = [\n",
        "    \"2m_temperature\",\n",
        "    \"10m_u_component_of_wind\",\n",
        "    \"10m_v_component_of_wind\",\n",
        "    \"mean_sea_level_pressure\",\n",
        "    \"total_precipitation_6hr\",\n",
        "]\n",
        "\n",
        "def xr_to_np_6h(ds, variables):\n",
        "    # ds: xarray.Dataset\n",
        "    arr = ds[variables].to_array(dim=\"variable\") \\\n",
        "                       .transpose(\"time\", \"latitude\", \"longitude\", \"variable\")\n",
        "    return arr.values.astype(np.float32)  # (T,H,W,C)\n",
        "\n",
        "np_train = xr_to_np_6h(data_train, variables)\n",
        "np_val   = xr_to_np_6h(data_val,   variables)\n",
        "np_test  = xr_to_np_6h(data_test,  variables)\n",
        "\n",
        "print(\"np_train shape:\", np_train.shape)\n",
        "print(\"np_val shape:\",   np_val.shape)\n",
        "print(\"np_test shape:\",  np_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3wi6IH-_M4_",
        "outputId": "96f0a073-7c41-44f5-ccdf-65cc1f0d3095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np_train shape: (2924, 121, 240, 5)\n",
            "np_val shape: (1460, 121, 240, 5)\n",
            "np_test shape: (1460, 121, 240, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# 变量名\n",
        "variables = [\n",
        "    \"2m_temperature\",\n",
        "    \"10m_u_component_of_wind\",\n",
        "    \"10m_v_component_of_wind\",\n",
        "    \"mean_sea_level_pressure\",\n",
        "    \"total_precipitation_6hr\",\n",
        "]\n",
        "\n",
        "\n",
        "class ERA5XYDataset6h(Dataset):\n",
        "    \"\"\"\n",
        "    专门用于已经是 6 小时间隔的数据：\n",
        "    - 不再做 1h -> 6h 聚合\n",
        "    - 只做时间滑窗 + 归一化\n",
        "    - 降水通道可以选择 m->mm、log1p 变换\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_np: np.ndarray,\n",
        "        variables: list[str],\n",
        "        x_len: int = 8,\n",
        "        y_len: int = 4,\n",
        "        stride: int = 1,\n",
        "        normalize: bool = True,\n",
        "        mean: torch.Tensor | None = None,   # (1,C,1,1) 或兼容形状\n",
        "        std:  torch.Tensor | None = None,\n",
        "        precip_to_mm: bool = True,          # 是否把降水从 m 转成 mm\n",
        "        precip_log1p: bool = False,         # 是否对降水做 log1p 变换\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_np: (T, H, W, C) 6-hourly data\n",
        "            variables: 变量名列表\n",
        "            x_len: 输入序列长度（时间步数）\n",
        "            y_len: 预测序列长度（时间步数）\n",
        "            stride: 滑动窗口步长\n",
        "            normalize: 是否做标准化\n",
        "            mean/std: 若不为 None，则复用给定统计量（保证 train/val 一致）\n",
        "            precip_to_mm: 将降水从 m 转为 mm（乘 1000）\n",
        "            precip_log1p: 对降水做 log1p 变换（在乘 mm 之后）\n",
        "        \"\"\"\n",
        "        assert data_np.ndim == 4, f\"data_np shape must be (T,H,W,C), got {data_np.shape}\"\n",
        "        self.variables = variables\n",
        "        self.x_len = x_len\n",
        "        self.y_len = y_len\n",
        "        self.normalize = normalize\n",
        "\n",
        "        T, H, W, C = data_np.shape\n",
        "\n",
        "        # ---------- 找到降水通道索引 ----------\n",
        "        precip_candidates = [\n",
        "            \"total_precipitation\",\n",
        "            \"total_precipitation_6hr\",\n",
        "            \"total_precipitation_6h\",\n",
        "        ]\n",
        "        tp_idx = None\n",
        "        for name in precip_candidates:\n",
        "            if name in variables:\n",
        "                tp_idx = variables.index(name)\n",
        "                break\n",
        "        self.tp_idx = tp_idx\n",
        "\n",
        "        # ----------  对降水做可选变换 ----------\n",
        "        data_proc = data_np.astype(np.float32).copy()\n",
        "        if tp_idx is not None:\n",
        "            if precip_to_mm:\n",
        "                data_proc[..., tp_idx] *= 1000.0  # m -> mm\n",
        "\n",
        "            if precip_log1p:\n",
        "                # log(1 + mm)，保证非负安全\n",
        "                data_proc[..., tp_idx] = np.log1p(np.clip(data_proc[..., tp_idx], a_min=0.0, a_max=None))\n",
        "\n",
        "        self.data = data_proc  # (T,H,W,C)\n",
        "\n",
        "        # ---------- 生成滑动窗口索引 ----------\n",
        "        max_start = T - (x_len + y_len)\n",
        "        if max_start < 0:\n",
        "            raise ValueError(\n",
        "                f\"Time dimension T={T} is too short for x_len={x_len}, \"\n",
        "                f\"y_len={y_len}\"\n",
        "            )\n",
        "\n",
        "        Xs, Ys = [], []\n",
        "        for start in range(0, max_start + 1, stride):\n",
        "            x_idx = np.arange(start, start + x_len)\n",
        "            y_idx = np.arange(start + x_len, start + x_len + y_len)\n",
        "            Xs.append(x_idx)\n",
        "            Ys.append(y_idx)\n",
        "        self.indices = list(zip(Xs, Ys))\n",
        "\n",
        "        # ---------- 计算或接收 mean/std ----------\n",
        "        if mean is None or std is None:\n",
        "            # 按 (T,H,W) 维度求各通道统计量\n",
        "            mean_np = self.data.mean(axis=(0, 1, 2), keepdims=True)  # (1,1,1,C)\n",
        "            std_np  = self.data.std(axis=(0, 1, 2), keepdims=True) + 1e-6\n",
        "\n",
        "            mean_t = torch.from_numpy(mean_np).permute(0, 3, 1, 2).float()  # (1,C,1,1)\n",
        "            std_t  = torch.from_numpy(std_np ).permute(0, 3, 1, 2).float()  # (1,C,1,1)\n",
        "        else:\n",
        "            # 统一成 (1,C,1,1)\n",
        "            mean_t = mean\n",
        "            std_t  = std\n",
        "\n",
        "            if mean_t.ndim == 1:\n",
        "                # (C,) -> (1,C,1,1)\n",
        "                mean_t = mean_t.view(1, -1, 1, 1)\n",
        "            elif mean_t.ndim == 3 and mean_t.shape[0] == len(variables):\n",
        "                # (C,H,W) -> (1,C,H,W)\n",
        "                mean_t = mean_t.unsqueeze(0)\n",
        "            elif mean_t.ndim == 4 and mean_t.shape[0] != 1:\n",
        "                # (C,1,1,1) -> (1,C,1,1)\n",
        "                mean_t = mean_t.permute(1, 0, 2, 3).contiguous()\n",
        "\n",
        "            if std_t.ndim == 1:\n",
        "                std_t = std_t.view(1, -1, 1, 1)\n",
        "            elif std_t.ndim == 3 and std_t.shape[0] == len(variables):\n",
        "                std_t = std_t.unsqueeze(0)\n",
        "            elif std_t.ndim == 4 and std_t.shape[0] != 1:\n",
        "                std_t = std_t.permute(1, 0, 2, 3).contiguous()\n",
        "\n",
        "            mean_t = mean_t.float()\n",
        "            std_t  = std_t.float()\n",
        "\n",
        "        self.mean = mean_t  # (1,C,1,1)\n",
        "        self.std  = std_t   # (1,C,1,1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        x_idx, y_idx = self.indices[idx]\n",
        "        x = self.data[x_idx]  # (Tin, H, W, C)\n",
        "        y = self.data[y_idx]  # (Tout, H, W, C)\n",
        "\n",
        "        # ->  (T,C,H,W)\n",
        "        x = torch.from_numpy(x).permute(0, 3, 1, 2).float()\n",
        "        y = torch.from_numpy(y).permute(0, 3, 1, 2).float()\n",
        "\n",
        "        if self.normalize:\n",
        "            x = (x - self.mean) / self.std\n",
        "            y = (y - self.mean) / self.std\n",
        "\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "PkVziGKc8Oze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1) train：自动计算 mean/std\n",
        "ds_train = ERA5XYDataset6h(\n",
        "    np_train,\n",
        "    variables,\n",
        "    x_len=8,\n",
        "    y_len=4,\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        "    precip_to_mm=True,   # m -> mm\n",
        "    precip_log1p=True,\n",
        ")\n",
        "\n",
        "# 2) val / test 复用 train 的 mean/std\n",
        "ds_val = ERA5XYDataset6h(\n",
        "    np_val,\n",
        "    variables,\n",
        "    x_len=8,\n",
        "    y_len=4,\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        "    mean=ds_train.mean,\n",
        "    std=ds_train.std,\n",
        "    precip_to_mm=True,\n",
        "    precip_log1p=True,\n",
        ")\n",
        "\n",
        "ds_test = ERA5XYDataset6h(\n",
        "    np_test,\n",
        "    variables,\n",
        "    x_len=8,\n",
        "    y_len=4,\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        "    mean=ds_train.mean,\n",
        "    std=ds_train.std,\n",
        "    precip_to_mm=True,\n",
        "    precip_log1p=True,\n",
        ")\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True,  num_workers=0)\n",
        "val_loader   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "test_loader  = DataLoader(ds_test,  batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "print(f\"Train samples: {len(ds_train)} | Val: {len(ds_val)} | Test: {len(ds_test)}\")\n",
        "\n",
        "x_in, y_out = next(iter(train_loader))\n",
        "print(\"x_in:\", x_in.shape)   # (B, Tin, C, H, W)\n",
        "print(\"y_out:\", y_out.shape) # (B, Tout, C, H, W)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpqSE5cmAghh",
        "outputId": "bf6a7a54-77df-48d3-eb3e-89d22564d3ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 2913 | Val: 1449 | Test: 1449\n",
            "x_in: torch.Size([8, 8, 5, 121, 240])\n",
            "y_out: torch.Size([8, 4, 5, 121, 240])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model"
      ],
      "metadata": {
        "id": "clynP5e2WO28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime\n",
        "from typing import List, Tuple, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torch.nn.functional as F\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ============================================================\n",
        "# =============== 0) 变量名（channels） =======================\n",
        "# ============================================================\n",
        "\n",
        "VARIABLES = variables\n",
        "\n",
        "# ============================================================\n",
        "# =============== 1) 配置（Config） ===========================\n",
        "# ============================================================\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    # ---- 数据 ----\n",
        "    # data_dir: str = \"./\"\n",
        "    # z_name: str = \"Z_2020_seq24.npy\"\n",
        "    # meta_name: str = \"Z_2020_seq24_meta.npz\"\n",
        "    # stats_name: str = \"Z_2020_norm_stats_2020.npz\"\n",
        "\n",
        "    # ---- 训练 ----\n",
        "    batch_size: int = 2\n",
        "    lr: float = 1e-3\n",
        "    max_epochs: int = 50\n",
        "    num_workers: int = 0\n",
        "    grad_clip: float = 1.0\n",
        "\n",
        "    # ---- Teacher Forcing ----\n",
        "    enable_tf_ratio: bool = True\n",
        "    teacher_forcing_start: float = 0.7\n",
        "    teacher_forcing_end: float = 0.2\n",
        "\n",
        "    # ---- 架构 ----\n",
        "    hidden_dim: int = 32\n",
        "    enc_cell_type: str = \"convlstm\"   # convrnn | convgru | convlstm\n",
        "    dec_cell_type: str = \"convlstm\"   # convrnn | convgru | convlstm\n",
        "    n_enc_layers: int = 1\n",
        "    n_dec_layers: int = 1\n",
        "    kernel_size: int = 3\n",
        "    layernorm: bool = True\n",
        "    peephole: bool = False            # 仅对 LSTM 有效\n",
        "    unet_head: bool = False\n",
        "\n",
        "    # ---- 可视化 ----\n",
        "    out_root: str = \"./runs\"          # 根目录\n",
        "    viz_every_n_epochs: int = 10       # 每隔 n 个 epoch 可视化一次（train + eval）\n",
        "    viz_use_last_t: bool = True        # True: 用最后一帧；False: 随机一帧\n",
        "    viz_channel: Optional[int] = None  # None: 随机通道；非 None：指定通道\n",
        "    save_all_channels_png: bool = False # True：画所有通道；False：只画一个通道\n",
        "\n",
        "# ============================================================\n",
        "# =============== 2) 数据（Dataset） =========================\n",
        "# ============================================================\n",
        "class ERA5ZInOutDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Z 文件形状: (N, T, C, H, W)\n",
        "    返回: (x_in, y_out) = (前 2 天, 后 1 天)  —— 以 meta 的 steps_per_day 为准\n",
        "    \"\"\"\n",
        "    def __init__(self, data_dir, z_name, meta_name, stats_name, normalize=True, dtype=torch.float32):\n",
        "        data_dir = Path(data_dir)\n",
        "        self.Z_path = data_dir / z_name\n",
        "        self.meta_path = data_dir / meta_name\n",
        "        self.stats_path = data_dir / stats_name\n",
        "        self.normalize = normalize\n",
        "        self.dtype = dtype\n",
        "\n",
        "        self.Z = np.load(self.Z_path, mmap_mode=\"r\")\n",
        "        self.N, self.T, self.C, self.H, self.W = self.Z.shape\n",
        "\n",
        "        meta = np.load(self.meta_path)\n",
        "        self.window_len = int(meta[\"window_len\"][0])\n",
        "        self.steps_per_day = int(meta[\"steps_per_day\"][0])\n",
        "        self.input_len = 2 * self.steps_per_day\n",
        "        self.target_len = 1 * self.steps_per_day\n",
        "\n",
        "        stats = np.load(self.stats_path)\n",
        "        mean = stats[\"mean\"]\n",
        "        std = stats[\"std\"]\n",
        "        self.mean = torch.from_numpy(mean).view(1, self.C, 1, 1)\n",
        "        self.std = torch.from_numpy(std).view(1, self.C, 1, 1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.N\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(np.array(self.Z[idx], copy=True)).to(self.dtype)\n",
        "        if self.normalize:\n",
        "            x = (x - self.mean) / self.std\n",
        "        return x[:self.input_len], x[self.input_len:self.input_len + self.target_len]  # (Tin,Tout)\n",
        "\n",
        "# ============================================================\n",
        "# =============== 3) 公共工具（Utils） =======================\n",
        "# ============================================================\n",
        "def ensure_dir(p: Path):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def make_run_dir(cfg: TrainConfig) -> Path:\n",
        "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    run_name = f\"enc_{cfg.enc_cell_type}_dec_{cfg.dec_cell_type}_{ts}\"\n",
        "    run_dir = Path(cfg.out_root) / run_name\n",
        "    ensure_dir(run_dir / \"checkpoints\")\n",
        "    ensure_dir(run_dir / \"figs\")\n",
        "    ensure_dir(run_dir / \"vis\")\n",
        "    # 保存配置\n",
        "    with open(run_dir / \"config.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(asdict(cfg), f, ensure_ascii=False, indent=2)\n",
        "    return run_dir\n",
        "\n",
        "def per_channel_mse(pred, target):\n",
        "    # pred/target: (B, T, C, H, W)\n",
        "    return ((pred - target) ** 2).mean(dim=(0, 1, 3, 4))\n",
        "\n",
        "def denorm(x_chw: torch.Tensor, mean_c11: torch.Tensor, std_c11: torch.Tensor):\n",
        "    \"\"\"\n",
        "    x_chw: (C,H,W) 在任意设备\n",
        "    mean_c11/std_c11: (1,C,1,1) 或 (C,1,1,1)，会自动搬到 x_chw.device\n",
        "    \"\"\"\n",
        "    # 确保 mean/std 在同一设备\n",
        "    mean_c11 = mean_c11.to(x_chw.device)\n",
        "    std_c11  = std_c11.to(x_chw.device)\n",
        "    return x_chw * std_c11.squeeze(0) + mean_c11.squeeze(0)\n",
        "\n",
        "\n",
        "def plot_loss_curves(history, out_dir: Path):\n",
        "    ensure_dir(out_dir)\n",
        "    epochs = [h[\"epoch\"] for h in history]\n",
        "    train_loss = [h[\"train_loss\"] for h in history]\n",
        "    val_loss = [h[\"val_loss\"] for h in history]\n",
        "\n",
        "    # 总体\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(epochs, train_loss, label=\"train MSE\")\n",
        "    plt.plot(epochs, val_loss, label=\"val MSE\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"MSE\")\n",
        "    plt.title(\"Overall Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_dir / \"overall_loss.png\", dpi=180)\n",
        "    plt.close()\n",
        "\n",
        "    # 分通道\n",
        "    if history and history[0][\"train_c_loss\"]:\n",
        "        C = len(history[0][\"train_c_loss\"])\n",
        "        plt.figure(figsize=(7,5))\n",
        "        for c in range(C):\n",
        "            # 用变量名当 legend，如果 VARIABLES 不够长就退回 c 索引\n",
        "            if c < len(VARIABLES):\n",
        "                vname = VARIABLES[c]\n",
        "            else:\n",
        "                vname = f\"var_{c}\"\n",
        "\n",
        "            plt.plot(\n",
        "                epochs,\n",
        "                [h[\"train_c_loss\"][c] for h in history],\n",
        "                \"-\",\n",
        "                label=f\"train {vname}\",\n",
        "            )\n",
        "            plt.plot(\n",
        "                epochs,\n",
        "                [h[\"val_c_loss\"][c] for h in history],\n",
        "                \"--\",\n",
        "                label=f\"val {vname}\",\n",
        "            )\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"MSE (per channel)\")\n",
        "        plt.title(\"Per-Channel Loss\")\n",
        "        plt.legend(ncol=2)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(out_dir / \"per_channel_loss.png\", dpi=180)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def _choose_t_and_c(Tout: int, C: int, use_last_t: bool, c_fixed: Optional[int]) -> Tuple[int, int]:\n",
        "    t_idx = (Tout - 1) if use_last_t else int(torch.randint(0, Tout, (1,)).item())\n",
        "    if c_fixed is None:\n",
        "        c_idx = int(torch.randint(0, C, (1,)).item())\n",
        "    else:\n",
        "        c_idx = int(max(0, min(C - 1, c_fixed)))\n",
        "    return t_idx, c_idx\n",
        "\n",
        "def _save_heatmaps(gt_chw: np.ndarray,\n",
        "                   pd_chw: np.ndarray,\n",
        "                   save_prefix: Path,\n",
        "                   draw_all_channels: bool,\n",
        "                   c_idx: int,\n",
        "                   var_names: Optional[List[str]] = None):\n",
        "    \"\"\"\n",
        "    gt_chw/pd_chw: (C,H,W) in physical value (already denormalized)\n",
        "\n",
        "    一张图，两行：\n",
        "      - 第一行：GT\n",
        "      - 第二行：Pred\n",
        "    每一列对应一个通道（变量）\n",
        "    \"\"\"\n",
        "    ensure_dir(save_prefix.parent)\n",
        "\n",
        "    if draw_all_channels:\n",
        "        channels = list(range(gt_chw.shape[0]))\n",
        "    else:\n",
        "        channels = [c_idx]\n",
        "\n",
        "    n_ch = len(channels)\n",
        "\n",
        "    fig, axes = plt.subplots(2, n_ch, figsize=(4 * n_ch, 6), squeeze=False)\n",
        "\n",
        "    for j, c in enumerate(channels):\n",
        "        if var_names is not None and c < len(var_names):\n",
        "            name = var_names[c]\n",
        "        else:\n",
        "            name = f\"c={c}\"\n",
        "\n",
        "        # 上：GT\n",
        "        ax_gt = axes[0, j]\n",
        "        im_gt = ax_gt.imshow(gt_chw[c], origin=\"lower\")\n",
        "        ax_gt.set_title(f\"GT | {name}\", fontsize=9)\n",
        "        ax_gt.axis(\"off\")\n",
        "        fig.colorbar(im_gt, ax=ax_gt, fraction=0.046, pad=0.04)\n",
        "\n",
        "        # 下：Pred\n",
        "        ax_pd = axes[1, j]\n",
        "        im_pd = ax_pd.imshow(pd_chw[c], origin=\"lower\")\n",
        "        ax_pd.set_title(f\"Pred | {name}\", fontsize=9)\n",
        "        ax_pd.axis(\"off\")\n",
        "        fig.colorbar(im_pd, ax=ax_pd, fraction=0.046, pad=0.04)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    fig.savefig(save_prefix.with_suffix(\".png\"), dpi=160)\n",
        "    plt.close(fig)\n",
        "\n",
        "@torch.no_grad()\n",
        "def visualize_once(model: nn.Module,\n",
        "                   x_in: torch.Tensor, y_out: torch.Tensor,\n",
        "                   mean: torch.Tensor, std: torch.Tensor,\n",
        "                   save_prefix: Path,\n",
        "                   use_last_t: bool,\n",
        "                   viz_channel: Optional[int],\n",
        "                   draw_all_channels: bool):\n",
        "    \"\"\"\n",
        "    对 batch 里第一条样本，TF=0 自由解码，挑选一个时间步画图。\n",
        "    画法：一张图，两行（GT / Pred），每列一个通道。\n",
        "    \"\"\"\n",
        "    model_was_training = model.training\n",
        "    model.eval()\n",
        "\n",
        "    x1 = x_in[:1]                           # (1, Tin, C, H, W)\n",
        "    Tout = y_out.shape[1]\n",
        "    pred1 = model(x1, y_len=Tout, teacher_forcing_ratio=0.0, targets=None)  # (1, Tout, C, H, W)\n",
        "\n",
        "    t_idx, c_idx = _choose_t_and_c(Tout, x1.shape[2], use_last_t, viz_channel)\n",
        "    gt_chw = y_out[0, t_idx]                # (C,H,W)\n",
        "    pd_chw = pred1[0, t_idx]                # (C,H,W)\n",
        "\n",
        "    gt_phys = denorm(gt_chw.cpu(), mean, std).numpy()\n",
        "    pd_phys = denorm(pd_chw.cpu(), mean, std).numpy()\n",
        "\n",
        "    _save_heatmaps(gt_phys, pd_phys, save_prefix,\n",
        "                   draw_all_channels, c_idx,\n",
        "                   var_names=VARIABLES)\n",
        "\n",
        "    if model_was_training:\n",
        "        model.train()\n",
        "\n",
        "# ============================================================\n",
        "# =============== 4) 模型（Model） ===========================\n",
        "# ============================================================\n",
        "def layer_norm_2d(num_channels: int) -> nn.Module:\n",
        "    return nn.GroupNorm(1, num_channels)\n",
        "\n",
        "class ConvRNNCell(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3,\n",
        "                 bias: bool = True, layernorm: bool = False):\n",
        "        super().__init__()\n",
        "        p = kernel_size // 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.conv = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        self.ln = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.tanh(self.ln(self.conv(torch.cat([x, h_prev], dim=1))))\n",
        "\n",
        "    def init_hidden(self, B, H, W, device=None, dtype=None):\n",
        "        return torch.zeros(B, self.hidden_dim, H, W, device=device, dtype=dtype)\n",
        "\n",
        "class ConvGRUCell(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3,\n",
        "                 bias: bool = True, layernorm: bool = False):\n",
        "        super().__init__()\n",
        "        p = kernel_size // 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.z = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        self.r = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        self.h = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        self.ln_z = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_r = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_h = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
        "        xh = torch.cat([x, h_prev], dim=1)\n",
        "        z = torch.sigmoid(self.ln_z(self.z(xh)))\n",
        "        r = torch.sigmoid(self.ln_r(self.r(xh)))\n",
        "        xrh = torch.cat([x, r * h_prev], dim=1)\n",
        "        h_tilde = torch.tanh(self.ln_h(self.h(xrh)))\n",
        "        return (1 - z) * h_prev + z * h_tilde\n",
        "\n",
        "    def init_hidden(self, B, H, W, device=None, dtype=None):\n",
        "        return torch.zeros(B, self.hidden_dim, H, W, device=device, dtype=dtype)\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3,\n",
        "                 bias: bool = True, layernorm: bool = False, peephole: bool = False):\n",
        "        super().__init__()\n",
        "        p = kernel_size // 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.peephole = peephole\n",
        "        self.conv = nn.Conv2d(input_dim + hidden_dim, 4 * hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        self.ln_i = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_f = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_o = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_g = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        if peephole:\n",
        "            self.Wci = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "            self.Wcf = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "            self.Wco = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor, c_prev: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        gates = self.conv(torch.cat([x, h_prev], dim=1))\n",
        "        i, f, o, g = torch.split(gates, self.hidden_dim, dim=1)\n",
        "        i = self.ln_i(i); f = self.ln_f(f); o = self.ln_o(o); g = self.ln_g(g)\n",
        "        if self.peephole:\n",
        "            i = torch.sigmoid(i + self.Wci * c_prev)\n",
        "            f = torch.sigmoid(f + self.Wcf * c_prev)\n",
        "        else:\n",
        "            i = torch.sigmoid(i); f = torch.sigmoid(f)\n",
        "        g = torch.tanh(g)\n",
        "        c = f * c_prev + i * g\n",
        "        o = torch.sigmoid(o + self.Wco * c) if self.peephole else torch.sigmoid(o)\n",
        "        h = o * torch.tanh(c)\n",
        "        return h, c\n",
        "\n",
        "    def init_hidden(self, B, H, W, device=None, dtype=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        h = torch.zeros(B, self.hidden_dim, H, W, device=device, dtype=dtype)\n",
        "        c = torch.zeros(B, self.hidden_dim, H, W, device=device, dtype=dtype)\n",
        "        return h, c\n",
        "\n",
        "# --- 轻量 U-Net 头 ---\n",
        "class ResidualDoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, norm='gn'):\n",
        "        super().__init__()\n",
        "        Norm = (lambda c: nn.GroupNorm(1, c)) if norm=='gn' else (lambda c: nn.BatchNorm2d(c))\n",
        "        self.conv1 = nn.Conv2d(in_ch,  out_ch, 3, padding=1, bias=False)\n",
        "        self.n1    = Norm(out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
        "        self.n2    = Norm(out_ch)\n",
        "        self.act   = nn.ReLU(inplace=True)\n",
        "        self.proj  = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.proj(x)\n",
        "        out = self.act(self.n1(self.conv1(x)))\n",
        "        out = self.n2(self.conv2(out))\n",
        "        out = self.act(out + identity)\n",
        "        return out\n",
        "\n",
        "def _pad_to_multiple(x: torch.Tensor, multiple: int) -> Tuple[torch.Tensor, Tuple[int,int]]:\n",
        "    \"\"\"\n",
        "    把特征图 pad 到 H、W 都是 multiple 的倍数。\n",
        "    返回 (x_padded, (pad_h, pad_w))，方便最后裁剪回原尺寸。\n",
        "    \"\"\"\n",
        "    _, _, H, W = x.shape\n",
        "    pad_h = (-H) % multiple\n",
        "    pad_w = (-W) % multiple\n",
        "    if pad_h or pad_w:\n",
        "        # F.pad 的顺序是 (left, right, top, bottom)\n",
        "        x = F.pad(x, (0, pad_w, 0, pad_h), mode=\"constant\", value=0)\n",
        "    return x, (pad_h, pad_w)\n",
        "\n",
        "class UNetHead(nn.Module):\n",
        "    \"\"\"\n",
        "    尺寸安全版 U-Net 头（levels=2 下/上采样两次）。\n",
        "    - 进入时把输入 pad 到 4 的倍数，退出时裁回原始 H、W\n",
        "    - 其他结构与原轻量 U-Net 相同\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch: int, out_ch: int, base: int = 64, levels: int = 2):\n",
        "        super().__init__()\n",
        "        assert levels == 2, \"当前实现假设两层下采样（可按需扩展）\"\n",
        "        b = min(base, max(32, in_ch))\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = ResidualDoubleConv(in_ch, b)\n",
        "        self.pool1 = nn.MaxPool2d(2)              # H/2, W/2\n",
        "        self.enc2 = ResidualDoubleConv(b, b * 2)\n",
        "        self.pool2 = nn.MaxPool2d(2)              # H/4, W/4\n",
        "\n",
        "        # Bottleneck\n",
        "        self.mid = ResidualDoubleConv(b * 2, b * 4)\n",
        "\n",
        "        # Decoder\n",
        "        self.up2  = nn.ConvTranspose2d(b * 4, b * 2, 2, stride=2)  # ×2\n",
        "        self.dec2 = ResidualDoubleConv(b * 4, b * 2)\n",
        "        self.up1  = nn.ConvTranspose2d(b * 2, b, 2, stride=2)      # ×2\n",
        "        self.dec1 = ResidualDoubleConv(b * 2, b)\n",
        "\n",
        "        # Output\n",
        "        self.out = nn.Conv2d(b, out_ch, 1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _match_and_cat(skip: torch.Tensor, up: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        由于上/下采样后可能有 1 个像素的差异，这里把 skip 做中心裁剪以匹配 up 的空间尺寸。\n",
        "        \"\"\"\n",
        "        _, _, Hs, Ws = skip.shape\n",
        "        _, _, Hu, Wu = up.shape\n",
        "        dh = Hs - Hu\n",
        "        dw = Ws - Wu\n",
        "        if dh or dw:\n",
        "            top = dh // 2\n",
        "            left = dw // 2\n",
        "            skip = skip[:, :, top:top+Hu, left:left+Wu]\n",
        "        return torch.cat([up, skip], dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        # 1) pad 到 4 的倍数，保证两次池化/反卷积后尺寸严格对齐\n",
        "        x, (pad_h, pad_w) = _pad_to_multiple(x, multiple=4)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)              # H,   W\n",
        "        e2 = self.enc2(self.pool1(e1)) # H/2, W/2\n",
        "\n",
        "        # Mid\n",
        "        mid = self.mid(self.pool2(e2)) # H/4, W/4\n",
        "\n",
        "        # Decoder\n",
        "        u2  = self.up2(mid)            # H/2, W/2\n",
        "        d2  = self.dec2(self._match_and_cat(e2, u2))\n",
        "\n",
        "        u1  = self.up1(d2)             # H,   W\n",
        "        d1  = self.dec1(self._match_and_cat(e1, u1))\n",
        "\n",
        "        out = self.out(d1)\n",
        "\n",
        "        # 2) 裁回原始 H、W（把右侧/下侧多出来的 pad 去掉）\n",
        "        if pad_h or pad_w:\n",
        "            out = out[:, :, :H, :W]\n",
        "        return out\n",
        "\n",
        "CellType = Union[ConvRNNCell, ConvGRUCell, ConvLSTMCell]\n",
        "\n",
        "def make_cell(cell_type: str, in_ch: int, hid_ch: int, kernel_size: int,\n",
        "              layernorm: bool, peephole: bool) -> CellType:\n",
        "    t = cell_type.lower()\n",
        "    if t == \"convrnn\":\n",
        "        return ConvRNNCell(in_ch, hid_ch, kernel_size, layernorm=layernorm)\n",
        "    elif t == \"convgru\":\n",
        "        return ConvGRUCell(in_ch, hid_ch, kernel_size, layernorm=layernorm)\n",
        "    elif t == \"convlstm\":\n",
        "        return ConvLSTMCell(in_ch, hid_ch, kernel_size, layernorm=layernorm, peephole=peephole)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown cell_type: {cell_type}\")\n",
        "\n",
        "class RecurrentStack(nn.Module):\n",
        "    def __init__(self, cell_type: str, input_dim: int, hidden_dims: List[int],\n",
        "                 kernel_size: int = 3, layernorm: bool = False, peephole: bool = False):\n",
        "        super().__init__()\n",
        "        self.cell_type = cell_type.lower()\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.layers = nn.ModuleList()\n",
        "        ch_in = input_dim\n",
        "        for hid in hidden_dims:\n",
        "            self.layers.append(make_cell(self.cell_type, ch_in, hid, kernel_size, layernorm, peephole))\n",
        "            ch_in = hid\n",
        "\n",
        "    def init_state(self, B, H, W, device=None, dtype=None):\n",
        "        states = []\n",
        "        for cell in self.layers:\n",
        "            states.append(cell.init_hidden(B, H, W, device=device, dtype=dtype))\n",
        "        return states\n",
        "\n",
        "    def forward(self, x, states):\n",
        "        new_states = []\n",
        "        h_in = x\n",
        "        for layer, state in zip(self.layers, states):\n",
        "            if isinstance(layer, ConvLSTMCell):\n",
        "                h_prev, c_prev = state\n",
        "                h, c = layer(h_in, h_prev, c_prev)\n",
        "                new_states.append((h, c))\n",
        "                h_in = h\n",
        "            else:\n",
        "                h_prev = state\n",
        "                h = layer(h_in, h_prev)\n",
        "                new_states.append(h)\n",
        "                h_in = h\n",
        "        return h_in, new_states\n",
        "\n",
        "class ConvSeq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 enc_cell_type: str = \"convlstm\",\n",
        "                 dec_cell_type: str = \"convlstm\",\n",
        "                 hidden_dims_enc: List[int] = [32],\n",
        "                 hidden_dims_dec: List[int] = [32],\n",
        "                 kernel_size: int = 3,\n",
        "                 layernorm: bool = False,\n",
        "                 peephole: bool = False,\n",
        "                 unet_head: bool = False):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.enc = RecurrentStack(enc_cell_type, input_dim, hidden_dims_enc,\n",
        "                                  kernel_size=kernel_size, layernorm=layernorm, peephole=peephole)\n",
        "        self.dec = RecurrentStack(dec_cell_type, input_dim, hidden_dims_dec,\n",
        "                                  kernel_size=kernel_size, layernorm=layernorm, peephole=peephole)\n",
        "        dec_top = hidden_dims_dec[-1]\n",
        "        self.head = UNetHead(dec_top, input_dim) if unet_head else nn.Conv2d(dec_top, input_dim, 1)\n",
        "\n",
        "    def forward(self, x_in: torch.Tensor, y_len: int, teacher_forcing_ratio: float = 0.5,\n",
        "                targets: Optional[torch.Tensor] = None):\n",
        "        B, Tin, C, H, W = x_in.shape\n",
        "        device, dtype = x_in.device, x_in.dtype\n",
        "\n",
        "        # Encode\n",
        "        enc_states = self.enc.init_state(B, H, W, device=device, dtype=dtype)\n",
        "        h = None\n",
        "        for t in range(Tin):\n",
        "            h, enc_states = self.enc(x_in[:, t], enc_states)\n",
        "\n",
        "        # Bridge: enc -> dec\n",
        "        dec_states = []\n",
        "        for enc_state, dec_cell in zip(enc_states, self.dec.layers):\n",
        "            if isinstance(dec_cell, ConvLSTMCell):\n",
        "                if isinstance(enc_state, tuple):\n",
        "                    h0, c0 = enc_state\n",
        "                else:\n",
        "                    h0 = enc_state\n",
        "                    c0 = torch.zeros_like(h0)\n",
        "                dec_states.append((h0, c0))\n",
        "            else:\n",
        "                h0 = enc_state[0] if isinstance(enc_state, tuple) else enc_state\n",
        "                dec_states.append(h0)\n",
        "\n",
        "        # Decode\n",
        "        y = []\n",
        "        dec_in = x_in[:, -1]\n",
        "        for t in range(y_len):\n",
        "            top_h, dec_states = self.dec(dec_in, dec_states)\n",
        "            out = self.head(top_h)\n",
        "            y.append(out.unsqueeze(1))\n",
        "            use_tf = (targets is not None) and (torch.rand((), device=device).item() < teacher_forcing_ratio) and (t < targets.shape[1])\n",
        "            dec_in = targets[:, t] if use_tf else out.detach()\n",
        "        return torch.cat(y, dim=1)\n",
        "\n",
        "# ============================================================\n",
        "# =============== 5) 训练（Train/Eval/Viz） ==================\n",
        "# ============================================================\n",
        "def get_datasets(cfg: TrainConfig):\n",
        "    full_ds = ERA5ZInOutDataset(\n",
        "        data_dir=cfg.data_dir,\n",
        "        z_name=cfg.z_name,\n",
        "        meta_name=cfg.meta_name,\n",
        "        stats_name=cfg.stats_name,\n",
        "        normalize=True,\n",
        "    )\n",
        "    n_total = len(full_ds)\n",
        "    n_train = int(0.8 * n_total)\n",
        "    n_val = n_total - n_train\n",
        "    train_ds, val_ds = random_split(full_ds, [n_train, n_val])\n",
        "    print(f\"数据集总数: {n_total} | 训练集: {n_train} | 验证集: {n_val}\")\n",
        "    return train_ds, val_ds\n",
        "\n",
        "def _tf_ratio(cfg: TrainConfig, epoch: int) -> float:\n",
        "    if cfg.enable_tf_ratio == False:\n",
        "        return 1\n",
        "    else:\n",
        "        if cfg.max_epochs <= 1:\n",
        "            return cfg.teacher_forcing_end\n",
        "        t = epoch / (cfg.max_epochs - 1)\n",
        "        return (1 - t) * cfg.teacher_forcing_start + t * cfg.teacher_forcing_end\n",
        "\n",
        "def _build_model(cfg: TrainConfig, C: int, device: torch.device) -> nn.Module:\n",
        "    hid_enc = [cfg.hidden_dim] * cfg.n_enc_layers\n",
        "    hid_dec = [cfg.hidden_dim] * cfg.n_dec_layers\n",
        "    model = ConvSeq2Seq(\n",
        "        input_dim=C,\n",
        "        enc_cell_type=cfg.enc_cell_type,\n",
        "        dec_cell_type=cfg.dec_cell_type,\n",
        "        hidden_dims_enc=hid_enc,\n",
        "        hidden_dims_dec=hid_dec,\n",
        "        kernel_size=cfg.kernel_size,\n",
        "        layernorm=cfg.layernorm,\n",
        "        peephole=cfg.peephole,\n",
        "        unet_head=cfg.unet_head,\n",
        "    ).to(device)\n",
        "    return model\n",
        "\n",
        "def _save_history_artifacts(run_dir: Path, cfg: TrainConfig, history):\n",
        "    # JSON\n",
        "    with open(run_dir / \"history.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\n",
        "            \"config\": asdict(cfg),\n",
        "            \"history\": history,\n",
        "        }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # CSV\n",
        "    if history:\n",
        "        C = len(history[0][\"train_c_loss\"])\n",
        "        fieldnames = [\n",
        "            \"epoch\",\n",
        "            \"train_loss\", \"val_loss\",\n",
        "            \"train_rmse\", \"val_rmse\",\n",
        "            \"train_mae\", \"val_mae\",\n",
        "            \"train_bias\", \"val_bias\",\n",
        "        ] + [f\"train_c{c}\" for c in range(C)] + [f\"val_c{c}\" for c in range(C)]\n",
        "\n",
        "        with open(run_dir / \"history.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "            writer.writeheader()\n",
        "            for h in history:\n",
        "                row = {\n",
        "                    \"epoch\": h[\"epoch\"],\n",
        "                    \"train_loss\": h[\"train_loss\"],\n",
        "                    \"val_loss\": h[\"val_loss\"],\n",
        "                    \"train_rmse\": h.get(\"train_rmse\", float(\"nan\")),\n",
        "                    \"val_rmse\": h.get(\"val_rmse\", float(\"nan\")),\n",
        "                    \"train_mae\": h.get(\"train_mae\", float(\"nan\")),\n",
        "                    \"val_mae\": h.get(\"val_mae\", float(\"nan\")),\n",
        "                    \"train_bias\": h.get(\"train_bias\", float(\"nan\")),\n",
        "                    \"val_bias\": h.get(\"val_bias\", float(\"nan\")),\n",
        "                }\n",
        "                for c in range(C):\n",
        "                    row[f\"train_c{c}\"] = h[\"train_c_loss\"][c]\n",
        "                    row[f\"val_c{c}\"] = h[\"val_c_loss\"][c]\n",
        "                writer.writerow(row)\n",
        "\n",
        "        # NPZ\n",
        "        np.savez_compressed(\n",
        "            run_dir / \"history.npz\",\n",
        "            epoch=np.array([h[\"epoch\"] for h in history], dtype=np.int32),\n",
        "            train_loss=np.array([h[\"train_loss\"] for h in history], dtype=np.float64),\n",
        "            val_loss=np.array([h[\"val_loss\"] for h in history], dtype=np.float64),\n",
        "            train_rmse=np.array([h.get(\"train_rmse\", np.nan) for h in history], dtype=np.float64),\n",
        "            val_rmse=np.array([h.get(\"val_rmse\", np.nan) for h in history], dtype=np.float64),\n",
        "            train_mae=np.array([h.get(\"train_mae\", np.nan) for h in history], dtype=np.float64),\n",
        "            val_mae=np.array([h.get(\"val_mae\", np.nan) for h in history], dtype=np.float64),\n",
        "            train_bias=np.array([h.get(\"train_bias\", np.nan) for h in history], dtype=np.float64),\n",
        "            val_bias=np.array([h.get(\"val_bias\", np.nan) for h in history], dtype=np.float64),\n",
        "            train_c_loss=np.stack([np.array(h[\"train_c_loss\"], dtype=np.float64) for h in history], axis=0),\n",
        "            val_c_loss=np.stack([np.array(h[\"val_c_loss\"], dtype=np.float64) for h in history], axis=0),\n",
        "        )\n",
        "\n",
        "\n",
        "def train(cfg: TrainConfig,\n",
        "          train_loader: DataLoader,\n",
        "          val_loader: DataLoader,\n",
        "          mean_c11: torch.Tensor,\n",
        "          std_c11: torch.Tensor):\n",
        "    \"\"\"\n",
        "    版本：不在内部创建 Dataset/DataLoader，\n",
        "          一切数据都由外部准备好，然后传进来。\n",
        "\n",
        "    参数：\n",
        "      - cfg: 训练配置\n",
        "      - train_loader, val_loader: 外部构建好的 DataLoader\n",
        "        * 要求 batch 输出是 (x_in, y_out)，\n",
        "          形状分别为 (B, Tin, C, H, W) / (B, Tout, C, H, W)\n",
        "      - mean_c11, std_c11: 形状 (1, C, 1, 1)，用于反归一化可视化\n",
        "    \"\"\"\n",
        "    # ---- 设备与输出目录 ----\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    run_dir = make_run_dir(cfg)\n",
        "    ckpt_dir = run_dir / \"checkpoints\"\n",
        "    figs_dir = run_dir / \"figs\"\n",
        "    vis_dir = run_dir / \"vis\"\n",
        "\n",
        "    pin = torch.cuda.is_available()\n",
        "\n",
        "    # ---- 通道数 C ----\n",
        "    # 从 mean/std 推出即可：mean_c11: (1,C,1,1)\n",
        "    C = mean_c11.shape[1]\n",
        "\n",
        "    # ---- 模型/优化器 ----\n",
        "    model = _build_model(cfg, C, device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # ---- 训练循环 ----\n",
        "    history = []\n",
        "    best_val = float(\"inf\")\n",
        "\n",
        "    for epoch in range(cfg.max_epochs):\n",
        "        model.train()\n",
        "        tf = _tf_ratio(cfg, epoch)\n",
        "\n",
        "        tr_loss_sum = 0.0\n",
        "        tr_c_loss_sum = None\n",
        "        tr_mae_sum = 0.0\n",
        "        tr_bias_sum = 0.0\n",
        "\n",
        "        for x_in, y_out in train_loader:\n",
        "            x_in = x_in.to(device, non_blocking=True)\n",
        "            y_out = y_out.to(device, non_blocking=True)\n",
        "\n",
        "            pred = model(\n",
        "                x_in,\n",
        "                y_len=y_out.shape[1],\n",
        "                teacher_forcing_ratio=tf,\n",
        "                targets=y_out,\n",
        "            )\n",
        "            loss = criterion(pred, y_out)\n",
        "            diff = pred - y_out\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # per-channel MSE（标准化空间）\n",
        "                c_loss_batch = per_channel_mse(pred, y_out)\n",
        "                if tr_c_loss_sum is None:\n",
        "                    tr_c_loss_sum = c_loss_batch * x_in.size(0)\n",
        "                else:\n",
        "                    tr_c_loss_sum += c_loss_batch * x_in.size(0)\n",
        "\n",
        "                # overall MAE & Bias（按 sample 数加权）\n",
        "                mae_batch = diff.abs().mean().item()\n",
        "                bias_batch = diff.mean().item()\n",
        "                tr_mae_sum += mae_batch * x_in.size(0)\n",
        "                tr_bias_sum += bias_batch * x_in.size(0)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            tr_loss_sum += loss.item() * x_in.size(0)\n",
        "\n",
        "        # ---- 聚合 train 指标 ----\n",
        "        n_train = len(train_loader.dataset)\n",
        "        tr_loss = tr_loss_sum / n_train\n",
        "        tr_c_loss = (tr_c_loss_sum / n_train).detach().cpu().tolist() if tr_c_loss_sum is not None else []\n",
        "        tr_mae = tr_mae_sum / n_train\n",
        "        tr_bias = tr_bias_sum / n_train\n",
        "        tr_rmse = tr_loss ** 0.5\n",
        "\n",
        "        # ---- 验证 ----\n",
        "        model.eval()\n",
        "        val_loss_sum = 0.0\n",
        "        val_c_loss_sum = None\n",
        "        val_mae_sum = 0.0\n",
        "        val_bias_sum = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_in, y_out in val_loader:\n",
        "                x_in = x_in.to(device, non_blocking=True)\n",
        "                y_out = y_out.to(device, non_blocking=True)\n",
        "                pred = model(\n",
        "                    x_in,\n",
        "                    y_len=y_out.shape[1],\n",
        "                    teacher_forcing_ratio=0.0,\n",
        "                    targets=None,\n",
        "                )\n",
        "                loss = criterion(pred, y_out)\n",
        "                val_loss_sum += loss.item() * x_in.size(0)\n",
        "\n",
        "                diff = pred - y_out\n",
        "                c_loss_batch = per_channel_mse(pred, y_out)\n",
        "                if val_c_loss_sum is None:\n",
        "                    val_c_loss_sum = c_loss_batch * x_in.size(0)\n",
        "                else:\n",
        "                    val_c_loss_sum += c_loss_batch * x_in.size(0)\n",
        "\n",
        "                mae_batch = diff.abs().mean().item()\n",
        "                bias_batch = diff.mean().item()\n",
        "                val_mae_sum += mae_batch * x_in.size(0)\n",
        "                val_bias_sum += bias_batch * x_in.size(0)\n",
        "\n",
        "        n_val = len(val_loader.dataset)\n",
        "        val_loss = val_loss_sum / n_val\n",
        "        val_c_loss = (val_c_loss_sum / n_val).detach().cpu().tolist() if val_c_loss_sum is not None else []\n",
        "        val_mae = val_mae_sum / n_val\n",
        "        val_bias = val_bias_sum / n_val\n",
        "        val_rmse = val_loss ** 0.5\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch+1}/{cfg.max_epochs}] \"\n",
        "            f\"TF={tf:.2f} | \"\n",
        "            f\"train MSE={tr_loss:.6f} RMSE={tr_rmse:.6f} MAE={tr_mae:.6f} | \"\n",
        "            f\"val MSE={val_loss:.6f} RMSE={val_rmse:.6f} MAE={val_mae:.6f}\"\n",
        "        )\n",
        "\n",
        "        history.append({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": float(tr_loss),\n",
        "            \"val_loss\": float(val_loss),\n",
        "            \"train_rmse\": float(tr_rmse),\n",
        "            \"val_rmse\": float(val_rmse),\n",
        "            \"train_mae\": float(tr_mae),\n",
        "            \"val_mae\": float(val_mae),\n",
        "            \"train_bias\": float(tr_bias),\n",
        "            \"val_bias\": float(val_bias),\n",
        "            \"train_c_loss\": [float(x) for x in tr_c_loss],\n",
        "            \"val_c_loss\": [float(x) for x in val_c_loss],\n",
        "        })\n",
        "\n",
        "        # ---- 可视化（train & eval，每隔 n 个 epoch）----\n",
        "        if cfg.viz_every_n_epochs and ((epoch + 1) % cfg.viz_every_n_epochs == 0):\n",
        "            # 从原始 dataset 中随机取一条可视化\n",
        "            train_batch = next(iter(DataLoader(train_loader.dataset, batch_size=1, shuffle=True, pin_memory=pin)))\n",
        "            eval_batch  = next(iter(DataLoader(val_loader.dataset,   batch_size=1, shuffle=True, pin_memory=pin)))\n",
        "            tx, ty = train_batch[0].to(device), train_batch[1].to(device)\n",
        "            ex, ey = eval_batch[0].to(device),  eval_batch[1].to(device)\n",
        "            epoch_dir = vis_dir / f\"epoch_{epoch+1:04d}\"\n",
        "\n",
        "            visualize_once(\n",
        "                model, tx, ty, mean_c11, std_c11,\n",
        "                save_prefix=epoch_dir / \"train_sample\",\n",
        "                use_last_t=cfg.viz_use_last_t,\n",
        "                viz_channel=cfg.viz_channel,\n",
        "                draw_all_channels=cfg.save_all_channels_png,\n",
        "            )\n",
        "            visualize_once(\n",
        "                model, ex, ey, mean_c11, std_c11,\n",
        "                save_prefix=epoch_dir / \"eval_sample\",\n",
        "                use_last_t=cfg.viz_use_last_t,\n",
        "                viz_channel=cfg.viz_channel,\n",
        "                draw_all_channels=cfg.save_all_channels_png,\n",
        "            )\n",
        "\n",
        "        # ---- 保存 checkpoint ----\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            torch.save(model.state_dict(), ckpt_dir / \"best.pt\")\n",
        "            print(f\"  >> Saved best model (val MSE={best_val:.6f})\")\n",
        "        torch.save(model.state_dict(), ckpt_dir / \"last.pt\")\n",
        "\n",
        "    # ---- 训练结束：落盘历史 + 曲线 ----\n",
        "    _save_history_artifacts(run_dir, cfg, history)\n",
        "    plot_loss_curves(history, figs_dir)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "\n",
        "# def train(cfg: TrainConfig):\n",
        "#     # ---- 设备与输出目录 ----\n",
        "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#     run_dir = make_run_dir(cfg)\n",
        "#     ckpt_dir = run_dir / \"checkpoints\"\n",
        "#     figs_dir = run_dir / \"figs\"\n",
        "#     vis_dir = run_dir / \"vis\"\n",
        "\n",
        "#     # ---- 数据 ----\n",
        "#     train_ds, val_ds = get_datasets(cfg)\n",
        "#     mean_c11 = train_ds.dataset.mean\n",
        "#     std_c11  = train_ds.dataset.std\n",
        "#     pin = torch.cuda.is_available()\n",
        "#     train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,\n",
        "#                               num_workers=cfg.num_workers, pin_memory=pin)\n",
        "#     val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False,\n",
        "#                             num_workers=cfg.num_workers, pin_memory=pin)\n",
        "\n",
        "#     # ---- 模型/优化器 ----\n",
        "#     C = train_ds.dataset.C\n",
        "#     model = _build_model(cfg, C, device)\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr)\n",
        "#     criterion = nn.MSELoss()\n",
        "\n",
        "#     # ---- 训练循环 ----\n",
        "#     history = []\n",
        "#     best_val = float(\"inf\")\n",
        "\n",
        "#     for epoch in range(cfg.max_epochs):\n",
        "#         model.train()\n",
        "#         tf = _tf_ratio(cfg, epoch)\n",
        "\n",
        "#         tr_loss_sum = 0.0\n",
        "#         tr_c_loss_sum = None\n",
        "#         tr_mae_sum = 0.0\n",
        "#         tr_bias_sum = 0.0\n",
        "\n",
        "#         for x_in, y_out in train_loader:\n",
        "#             x_in = x_in.to(device, non_blocking=True)\n",
        "#             y_out = y_out.to(device, non_blocking=True)\n",
        "\n",
        "#             pred = model(x_in, y_len=y_out.shape[1], teacher_forcing_ratio=tf, targets=y_out)\n",
        "#             loss = criterion(pred, y_out)\n",
        "\n",
        "#             diff = pred - y_out\n",
        "\n",
        "#             with torch.no_grad():\n",
        "#                 # per-channel MSE\n",
        "#                 c_loss_batch = per_channel_mse(pred, y_out)\n",
        "#                 if tr_c_loss_sum is None:\n",
        "#                     tr_c_loss_sum = c_loss_batch * x_in.size(0)\n",
        "#                 else:\n",
        "#                     tr_c_loss_sum += c_loss_batch * x_in.size(0)\n",
        "\n",
        "#                 # overall MAE & Bias（按 sample 数加权）\n",
        "#                 mae_batch = diff.abs().mean().item()\n",
        "#                 bias_batch = diff.mean().item()\n",
        "#                 tr_mae_sum += mae_batch * x_in.size(0)\n",
        "#                 tr_bias_sum += bias_batch * x_in.size(0)\n",
        "\n",
        "#             optimizer.zero_grad(set_to_none=True)\n",
        "#             loss.backward()\n",
        "#             nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
        "#             optimizer.step()\n",
        "\n",
        "#             tr_loss_sum += loss.item() * x_in.size(0)\n",
        "\n",
        "#         tr_loss = tr_loss_sum / len(train_loader.dataset)\n",
        "#         tr_c_loss = (tr_c_loss_sum / len(train_loader.dataset)).detach().cpu().tolist() if tr_c_loss_sum is not None else []\n",
        "#         tr_mae = tr_mae_sum / len(train_loader.dataset)\n",
        "#         tr_bias = tr_bias_sum / len(train_loader.dataset)\n",
        "#         tr_rmse = tr_loss ** 0.5\n",
        "\n",
        "#         # ---- 验证 ----\n",
        "#         model.eval()\n",
        "#         val_loss_sum = 0.0\n",
        "#         val_c_loss_sum = None\n",
        "#         val_mae_sum = 0.0\n",
        "#         val_bias_sum = 0.0\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for x_in, y_out in val_loader:\n",
        "#                 x_in = x_in.to(device, non_blocking=True)\n",
        "#                 y_out = y_out.to(device, non_blocking=True)\n",
        "#                 pred = model(x_in, y_len=y_out.shape[1], teacher_forcing_ratio=0.0, targets=None)\n",
        "#                 loss = criterion(pred, y_out)\n",
        "#                 val_loss_sum += loss.item() * x_in.size(0)\n",
        "\n",
        "#                 diff = pred - y_out\n",
        "\n",
        "#                 c_loss_batch = per_channel_mse(pred, y_out)\n",
        "#                 if val_c_loss_sum is None:\n",
        "#                     val_c_loss_sum = c_loss_batch * x_in.size(0)\n",
        "#                 else:\n",
        "#                     val_c_loss_sum += c_loss_batch * x_in.size(0)\n",
        "\n",
        "#                 mae_batch = diff.abs().mean().item()\n",
        "#                 bias_batch = diff.mean().item()\n",
        "#                 val_mae_sum += mae_batch * x_in.size(0)\n",
        "#                 val_bias_sum += bias_batch * x_in.size(0)\n",
        "\n",
        "#         val_loss = val_loss_sum / len(val_loader.dataset)\n",
        "#         val_c_loss = (val_c_loss_sum / len(val_loader.dataset)).detach().cpu().tolist() if val_c_loss_sum is not None else []\n",
        "#         val_mae = val_mae_sum / len(val_loader.dataset)\n",
        "#         val_bias = val_bias_sum / len(val_loader.dataset)\n",
        "#         val_rmse = val_loss ** 0.5\n",
        "\n",
        "#         print(\n",
        "#             f\"[Epoch {epoch+1}/{cfg.max_epochs}] \"\n",
        "#             f\"TF={tf:.2f} | \"\n",
        "#             f\"train MSE={tr_loss:.6f} RMSE={tr_rmse:.6f} MAE={tr_mae:.6f} | \"\n",
        "#             f\"val MSE={val_loss:.6f} RMSE={val_rmse:.6f} MAE={val_mae:.6f}\"\n",
        "#         )\n",
        "\n",
        "#         history.append({\n",
        "#             \"epoch\": epoch + 1,\n",
        "#             \"train_loss\": float(tr_loss),\n",
        "#             \"val_loss\": float(val_loss),\n",
        "#             \"train_rmse\": float(tr_rmse),\n",
        "#             \"val_rmse\": float(val_rmse),\n",
        "#             \"train_mae\": float(tr_mae),\n",
        "#             \"val_mae\": float(val_mae),\n",
        "#             \"train_bias\": float(tr_bias),\n",
        "#             \"val_bias\": float(val_bias),\n",
        "#             \"train_c_loss\": [float(x) for x in tr_c_loss],\n",
        "#             \"val_c_loss\": [float(x) for x in val_c_loss],\n",
        "#         })\n",
        "\n",
        "#         # ---- 可视化（train & eval，每隔 n 个 epoch）----\n",
        "#         if cfg.viz_every_n_epochs and ((epoch + 1) % cfg.viz_every_n_epochs == 0):\n",
        "#             # 取一个小 batch\n",
        "#             train_batch = next(iter(DataLoader(train_ds, batch_size=1, shuffle=True)))\n",
        "#             eval_batch  = next(iter(DataLoader(val_ds,   batch_size=1, shuffle=True)))\n",
        "#             tx, ty = train_batch[0].to(device), train_batch[1].to(device)\n",
        "#             ex, ey = eval_batch[0].to(device),  eval_batch[1].to(device)\n",
        "#             epoch_dir = vis_dir / f\"epoch_{epoch+1:04d}\"\n",
        "#             # train 可视化\n",
        "#             visualize_once(\n",
        "#                 model, tx, ty, mean_c11, std_c11,\n",
        "#                 save_prefix=epoch_dir / \"train_sample\",\n",
        "#                 use_last_t=cfg.viz_use_last_t,\n",
        "#                 viz_channel=cfg.viz_channel,\n",
        "#                 draw_all_channels=cfg.save_all_channels_png\n",
        "#             )\n",
        "#             # eval 可视化\n",
        "#             visualize_once(\n",
        "#                 model, ex, ey, mean_c11, std_c11,\n",
        "#                 save_prefix=epoch_dir / \"eval_sample\",\n",
        "#                 use_last_t=cfg.viz_use_last_t,\n",
        "#                 viz_channel=cfg.viz_channel,\n",
        "#                 draw_all_channels=cfg.save_all_channels_png\n",
        "#             )\n",
        "\n",
        "#         # ---- 保存 checkpoint ----\n",
        "#         if val_loss < best_val:\n",
        "#             best_val = val_loss\n",
        "#             torch.save(model.state_dict(), ckpt_dir / \"best.pt\")\n",
        "#             print(f\"  >> Saved best model (val MSE={best_val:.6f})\")\n",
        "#         torch.save(model.state_dict(), ckpt_dir / \"last.pt\")\n",
        "\n",
        "#     # ---- 训练结束：落盘历史 + 曲线 ----\n",
        "#     _save_history_artifacts(run_dir, cfg, history)\n",
        "#     plot_loss_curves(history, figs_dir)\n",
        "\n",
        "#     return model, history\n",
        "\n",
        "# ============================================================\n",
        "# =============== 6) 入口（Main） ============================\n",
        "# ============================================================\n",
        "# if __name__ == \"__main__\":\n",
        "#     cfg = TrainConfig(\n",
        "#         data_dir=\"./\",\n",
        "#         max_epochs=100,\n",
        "#         batch_size=2,\n",
        "#         enc_cell_type=\"convgru\",\n",
        "#         dec_cell_type=\"convgru\",\n",
        "#         n_enc_layers=1,\n",
        "#         n_dec_layers=1,\n",
        "#         enable_tf_ratio=False,\n",
        "#         layernorm=True,\n",
        "#         peephole=False,\n",
        "#         unet_head=True,\n",
        "#         out_root=\"./runs_w_unet\",\n",
        "#         viz_every_n_epochs=10,     # 每 10 个 epoch 可视化一次（train+eval）\n",
        "#         viz_use_last_t=True,       # 可切换 False 以随机时间步\n",
        "#         viz_channel=None,          # None=随机通道；也可设 0/1/2...\n",
        "#         save_all_channels_png=True\n",
        "#     )\n",
        "#     model, history = train(cfg)\n"
      ],
      "metadata": {
        "id": "-2CwijK3BHkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### metrics"
      ],
      "metadata": {
        "id": "JrNuvmPvbJsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### weighting"
      ],
      "metadata": {
        "id": "pR3WlFN7cjal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lat_centers(num_lat: int, device=None) -> torch.Tensor:\n",
        "    j = torch.arange(num_lat, device=device, dtype=torch.float32)\n",
        "    dphi = 180.0 / float(num_lat - 1)\n",
        "    phi_center = 90.0 - j * dphi\n",
        "    return phi_center  # degrees\n",
        "\n",
        "\n",
        "def latitude_area_weights(num_lat: int, device=None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute w(i) ∝ sin(theta_u) - sin(theta_l), normalized to sum to 1.\n",
        "    \"\"\"\n",
        "    phi_center = lat_centers(num_lat, device=device)\n",
        "    dphi = 180.0 / float(num_lat - 1)\n",
        "\n",
        "    phi_upper_deg = torch.clamp(phi_center + 0.5 * dphi, max=90.0)\n",
        "    phi_lower_deg = torch.clamp(phi_center - 0.5 * dphi, min=-90.0)\n",
        "\n",
        "    phi_upper = torch.deg2rad(phi_upper_deg)\n",
        "    phi_lower = torch.deg2rad(phi_lower_deg)\n",
        "\n",
        "    w_raw = torch.sin(phi_upper) - torch.sin(phi_lower)  # [H]\n",
        "    w = w_raw / w_raw.sum()\n",
        "    return w  # [H]"
      ],
      "metadata": {
        "id": "BJHe6bJ5bLh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### RMSE"
      ],
      "metadata": {
        "id": "_TJWy01LcpxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_rmse_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute latitude-area-weighted RMSE per channel.\n",
        "\n",
        "    Args:\n",
        "        pred, target: tensors of shape [B, C, H, W]\n",
        "                      (batch, channels, latitude, longitude)\n",
        "\n",
        "    Returns:\n",
        "        rmse: tensor of shape [B, C]\n",
        "              (one RMSE per channel for each batch sample)\n",
        "    \"\"\"\n",
        "    assert pred.shape == target.shape, \"pred and target must have same shape\"\n",
        "    assert pred.dim() == 4, \"expected shape [B, C, H, W]\"\n",
        "\n",
        "    B, C, H, W = pred.shape\n",
        "    device = pred.device\n",
        "\n",
        "    err2 = (pred - target) ** 2  # [B, C, H, W]\n",
        "\n",
        "    # latitude weights w_i (sum to 1)\n",
        "    w_lat = latitude_area_weights(H, device=device)     # [H]\n",
        "    w_lat = w_lat.view(1, 1, H, 1)                      # [1,1,H,1]\n",
        "\n",
        "    # mean over longitude, then weighted sum over latitude\n",
        "    # mean over W: [B, C, H]\n",
        "    err2_mean_lon = err2.mean(dim=-1)                   # [B, C, H]\n",
        "\n",
        "    # weighted sum over H (since sum_i w_i = 1)\n",
        "    mse = (w_lat.squeeze(-1) * err2_mean_lon).sum(dim=-1)  # [B, C]\n",
        "\n",
        "    rmse = torch.sqrt(mse)\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "8C8J36JzcnMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ACC"
      ],
      "metadata": {
        "id": "7bWHIqKScrr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_acc_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Latitude-area-weighted ACC (anomaly correlation / pattern correlation)\n",
        "    per channel.\n",
        "\n",
        "    pred, target: [B, C, H, W]  (batch, channels, lat, lon)\n",
        "\n",
        "    Returns:\n",
        "        acc: [B, C]\n",
        "    \"\"\"\n",
        "    assert pred.shape == target.shape\n",
        "    assert pred.dim() == 4\n",
        "\n",
        "    B, C, H, W = pred.shape\n",
        "    device = pred.device\n",
        "\n",
        "    # latitude area weights w(j) based on sin(theta_u) - sin(theta_l)\n",
        "    w_lat = latitude_area_weights(H, device=device)   # [H]\n",
        "    w = w_lat.view(1, 1, H, 1)                        # [1, 1, H, 1] for broadcasting\n",
        "\n",
        "    # numerator: weighted dot product\n",
        "    num = torch.sum(w * pred * target, dim=(-1, -2))  # [B, C]\n",
        "\n",
        "    # denominator: product of weighted norms\n",
        "    denom = torch.sqrt(\n",
        "        torch.sum(w * pred * pred, dim=(-1, -2)) *\n",
        "        torch.sum(w * target * target, dim=(-1, -2)) + 1e-12\n",
        "    )  # [B, C]\n",
        "\n",
        "    acc = num / denom\n",
        "    return acc"
      ],
      "metadata": {
        "id": "nZzju4cKcu4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### MAE"
      ],
      "metadata": {
        "id": "c9YN1YzOcygU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_mae_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Latitude-area-weighted MAE per channel.\n",
        "\n",
        "    Args:\n",
        "        pred, target: [B, C, H, W]  (batch, channels, lat, lon)\n",
        "\n",
        "    Returns:\n",
        "        mae: [B, C]  (MAE for each batch sample and channel)\n",
        "    \"\"\"\n",
        "    assert pred.shape == target.shape, \"pred and target must have same shape\"\n",
        "    assert pred.dim() == 4, \"expected shape [B, C, H, W]\"\n",
        "\n",
        "    B, C, H, W = pred.shape\n",
        "    device = pred.device\n",
        "\n",
        "    err_abs = torch.abs(pred - target)          # [B, C, H, W]\n",
        "\n",
        "    # latitude weights w_i (sum to 1)\n",
        "    w_lat = latitude_area_weights(H, device=device)  # [H]\n",
        "    w_lat = w_lat.view(1, 1, H)                      # [1, 1, H]\n",
        "\n",
        "    # mean over longitude (uniform grid)\n",
        "    err_abs_mean_lon = err_abs.mean(dim=-1)         # [B, C, H]\n",
        "\n",
        "    # weighted sum over latitude\n",
        "    mae = (w_lat * err_abs_mean_lon).sum(dim=-1)    # [B, C]\n",
        "\n",
        "    return mae"
      ],
      "metadata": {
        "id": "FQlXchTkcwIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### RMSB"
      ],
      "metadata": {
        "id": "keY5L0dSc059"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_rmsb_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute globally averaged root mean squared bias (RMSB) per channel.\n",
        "\n",
        "    Args:\n",
        "        pred, target: tensors of shape [T, C, H, W]\n",
        "                      T = time, C = channels/variables,\n",
        "                      H = latitude, W = longitude.\n",
        "\n",
        "    Returns:\n",
        "        rmsb: tensor of shape [C]  (RMSB for each channel)\n",
        "    \"\"\"\n",
        "    assert pred.shape == target.shape, \"pred and target must have same shape\"\n",
        "    assert pred.dim() == 4, \"expected shape [T, C, H, W]\"\n",
        "\n",
        "    T, C, H, W = pred.shape\n",
        "    device = pred.device\n",
        "\n",
        "    # 1) Bias_{i,j} per channel: average over time\n",
        "    #    Bias[c, i, j] = (1/T) Σ_t (pred - target)\n",
        "    bias = torch.mean(pred - target, dim=0)      # [C, H, W]\n",
        "\n",
        "    # 2) Latitude area weights w(i)\n",
        "    w_lat = latitude_area_weights(H, device=device)  # [H]\n",
        "    w = w_lat.view(1, H, 1)                          # [1, H, 1] for broadcasting\n",
        "\n",
        "    # 3) Weighted mean of squared bias over lat & lon\n",
        "    #    Here we do: Σ_i Σ_j w(i) * Bias^2 / W\n",
        "    #    (w(i) is normalized to sum to 1, so this is\n",
        "    #     consistent with area weighting + mean over lon.)\n",
        "    msb = torch.mean(w * bias**2, dim=(-1, -2))  # [C]\n",
        "\n",
        "    # 4) Root mean squared bias\n",
        "    rmsb = torch.sqrt(msb)                       # [C]\n",
        "\n",
        "    return rmsb\n"
      ],
      "metadata": {
        "id": "yH8LUerFc3Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_rmsb_channels(pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute globally averaged root mean squared bias (RMSB) per channel.\n",
        "\n",
        "    Args:\n",
        "        pred, target: tensors of shape [T, C, H, W]\n",
        "                      T = time, C = channels/variables,\n",
        "                      H = latitude, W = longitude.\n",
        "\n",
        "    Returns:\n",
        "        rmsb: tensor of shape [C]  (RMSB for each channel)\n",
        "    \"\"\"\n",
        "    assert pred.shape == target.shape, \"pred and target must have same shape\"\n",
        "    assert pred.dim() == 4, \"expected shape [T, C, H, W]\"\n",
        "\n",
        "    T, C, H, W = pred.shape\n",
        "    device = pred.device\n",
        "\n",
        "    # 1) Bias_{i,j} per channel: average over time\n",
        "    #    Bias[c, i, j] = (1/T) Σ_t (pred - target)\n",
        "    bias = torch.mean(pred - target, dim=0)      # [C, H, W]\n",
        "\n",
        "    # 2) Latitude area weights w(i)\n",
        "    w_lat = latitude_area_weights(H, device=device)  # [H]\n",
        "    w = w_lat.view(1, H, 1)                          # [1, H, 1] for broadcasting\n",
        "\n",
        "    # 3) Weighted mean of squared bias over lat & lon\n",
        "    #    Here we do: Σ_i Σ_j w(i) * Bias^2 / W\n",
        "    #    (w(i) is normalized to sum to 1, so this is\n",
        "    #     consistent with area weighting + mean over lon.)\n",
        "    msb = torch.mean(w * bias**2, dim=(-1, -2))  # [C]\n",
        "\n",
        "    # 4) Root mean squared bias\n",
        "    rmsb = torch.sqrt(msb)                       # [C]\n",
        "\n",
        "    return rmsb\n"
      ],
      "metadata": {
        "id": "LxgILtEPc4fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### evaluation"
      ],
      "metadata": {
        "id": "sp_0qNUxaecE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# =========================\n",
        "# 0. mean/std 处理 & 反归一化\n",
        "# =========================\n",
        "\n",
        "def get_mean_std_c11(ds_train):\n",
        "    \"\"\"\n",
        "    把 ds_train.mean/std 统一整理成 (1, C, 1, 1) 形状，方便反归一化。\n",
        "    \"\"\"\n",
        "    mean = ds_train.mean\n",
        "    std  = ds_train.std\n",
        "\n",
        "    if mean.ndim != 4 or std.ndim != 4:\n",
        "        raise ValueError(f\"Unexpected mean/std shape: mean={mean.shape}, std={std.shape}\")\n",
        "\n",
        "    # 常见两种： (C,1,1,1) 或 (1,C,1,1)\n",
        "    if mean.shape[0] == 1:          # (1,C,1,1)\n",
        "        mean_c11 = mean.clone()\n",
        "        std_c11  = std.clone()\n",
        "    elif mean.shape[1] == 1:        # (C,1,1,1)\n",
        "        mean_c11 = mean.permute(1, 0, 2, 3).contiguous()  # -> (1,C,1,1)\n",
        "        std_c11  = std.permute(1, 0, 2, 3).contiguous()\n",
        "    else:\n",
        "        raise ValueError(f\"Cannot infer channel dim from mean shape {mean.shape}\")\n",
        "\n",
        "    return mean_c11, std_c11\n",
        "\n",
        "\n",
        "def denorm_all_channels(norm_tensor, mean_c11, std_c11):\n",
        "    \"\"\"\n",
        "    norm_tensor: (..., C, H, W) 或 (B,T,C,H,W)\n",
        "    mean_c11/std_c11: (1,C,1,1)\n",
        "    返回：物理单位下的张量。\n",
        "    \"\"\"\n",
        "    while mean_c11.ndim < norm_tensor.ndim:\n",
        "        mean_c11 = mean_c11.unsqueeze(0)  # 在前面补 batch/time 维度\n",
        "        std_c11  = std_c11.unsqueeze(0)\n",
        "    return norm_tensor * std_c11 + mean_c11\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 1. 构建模型 & 加载 checkpoint\n",
        "# =========================\n",
        "\n",
        "def build_model_for_eval(cfg, n_channels: int, device: torch.device):\n",
        "    \"\"\"\n",
        "    用 TrainConfig 和通道数 C 来 new 一个 ConvSeq2Seq。\n",
        "    不依赖你之前的 _build_model。\n",
        "    \"\"\"\n",
        "    hid_enc = [cfg.hidden_dim] * cfg.n_enc_layers\n",
        "    hid_dec = [cfg.hidden_dim] * cfg.n_dec_layers\n",
        "\n",
        "    model = ConvSeq2Seq(\n",
        "        input_dim=n_channels,\n",
        "        enc_cell_type=cfg.enc_cell_type,\n",
        "        dec_cell_type=cfg.dec_cell_type,\n",
        "        hidden_dims_enc=hid_enc,\n",
        "        hidden_dims_dec=hid_dec,\n",
        "        kernel_size=cfg.kernel_size,\n",
        "        layernorm=cfg.layernorm,\n",
        "        peephole=cfg.peephole,\n",
        "        unet_head=cfg.unet_head,\n",
        "    ).to(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_model_from_checkpoint(ckpt_path: str, cfg, n_channels: int, device: torch.device):\n",
        "    \"\"\"\n",
        "    构建好模型并从 checkpoint 加载权重。\n",
        "    \"\"\"\n",
        "    model = build_model_for_eval(cfg, n_channels, device)\n",
        "    state = torch.load(ckpt_path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"[INFO] Loaded checkpoint: {ckpt_path}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 2. lead-time RMSE（单变量）\n",
        "# =========================\n",
        "\n",
        "def compute_lead_rmse_curve_for_var(\n",
        "    model: torch.nn.Module,\n",
        "    data_loader,\n",
        "    mean_c11: torch.Tensor,\n",
        "    std_c11: torch.Tensor,\n",
        "    var_idx: int,\n",
        "    time_step_hours: int,\n",
        "    max_lead_hours: int,\n",
        "    device: torch.device,\n",
        "    precip_idx: int | None = None,\n",
        "    precip_is_log1p_mm: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    对某个变量计算「纬向加权 RMSE vs lead time」曲线（物理单位）。\n",
        "\n",
        "    - data_loader 输出 (x_in, y_out_norm)，标准化空间，形状 (B, Tin/Tout, C, H, W)\n",
        "    - 用 mean_c11/std_c11 反归一化回物理单位\n",
        "    - 如果 precip_idx 不为 None 且 precip_is_log1p_mm=True，则该通道从 log1p(mm) -> mm\n",
        "    - 真正能算到的最大 lead 步数 = min(y_len, max_lead_hours / time_step_hours)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    mean_c11 = mean_c11.to(device)\n",
        "    std_c11  = std_c11.to(device)\n",
        "\n",
        "    # 探测 y_len\n",
        "    with torch.no_grad():\n",
        "        x0, y0 = next(iter(data_loader))\n",
        "        Tout = y0.shape[1]\n",
        "\n",
        "    max_steps = min(Tout, max_lead_hours // time_step_hours)\n",
        "    if max_steps <= 0:\n",
        "        raise ValueError(\"max_lead_hours 太小或者 y_len 太短，导致没有可用的 lead 步数。\")\n",
        "\n",
        "    rmse_sum = torch.zeros(max_steps, device=device)\n",
        "    n_samp   = torch.zeros(max_steps, device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_in, y_out_norm in data_loader:\n",
        "            x_in = x_in.to(device)\n",
        "            y_out_norm = y_out_norm.to(device)\n",
        "            B = x_in.size(0)\n",
        "\n",
        "            # 自由解码\n",
        "            pred_norm = model(\n",
        "                x_in,\n",
        "                y_len=y_out_norm.shape[1],\n",
        "                teacher_forcing_ratio=0.0,\n",
        "                targets=None,\n",
        "            )  # (B, Tout, C, H, W)\n",
        "\n",
        "            # 反归一化到物理单位（所有变量）\n",
        "            pred = denorm_all_channels(pred_norm, mean_c11, std_c11)  # (B,T,C,H,W)\n",
        "            y    = denorm_all_channels(y_out_norm, mean_c11, std_c11)\n",
        "\n",
        "            # 降水通道：log1p(mm) -> mm\n",
        "            if precip_idx is not None and precip_is_log1p_mm:\n",
        "                tp_pred_log = pred[:, :, precip_idx, :, :]\n",
        "                tp_y_log    = y[:, :, precip_idx, :, :]\n",
        "\n",
        "                tp_pred_mm = torch.expm1(tp_pred_log).clamp(min=0.0)\n",
        "                tp_y_mm    = torch.expm1(tp_y_log).clamp(min=0.0)\n",
        "\n",
        "                pred[:, :, precip_idx, :, :] = tp_pred_mm\n",
        "                y[:,   :, precip_idx, :, :] = tp_y_mm\n",
        "\n",
        "            # 每个 lead t 算 RMSE\n",
        "            for t in range(max_steps):\n",
        "                pred_t = pred[:, t, :, :, :]   # (B,C,H,W)\n",
        "                y_t    = y[:,   t, :, :, :]    # (B,C,H,W)\n",
        "\n",
        "                rmse_bc = weighted_rmse_channels(pred_t, y_t)  # (B,C)\n",
        "                rmse_b  = rmse_bc[:, var_idx]                  # (B,)\n",
        "\n",
        "                rmse_sum[t] += rmse_b.sum()\n",
        "                n_samp[t]   += B\n",
        "\n",
        "    rmse_lead  = (rmse_sum / n_samp).cpu().numpy()              # (max_steps,)\n",
        "    lead_hours = np.arange(1, max_steps + 1) * time_step_hours  # [Δt, 2Δt, ..., max_lead]\n",
        "\n",
        "    return lead_hours, rmse_lead\n",
        "\n",
        "\n",
        "def save_lead_rmse_npz(\n",
        "    out_path: str,\n",
        "    lead_hours: np.ndarray,\n",
        "    rmse_lead: np.ndarray,\n",
        "    var_name: str,\n",
        "    ckpt_path: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    把 lead-time RMSE 曲线存成 npz，方便以后复用。\n",
        "    \"\"\"\n",
        "    out_path = Path(out_path)\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    np.savez_compressed(\n",
        "        out_path,\n",
        "        lead_hours=lead_hours,\n",
        "        rmse_lead=rmse_lead,\n",
        "        var_name=np.array(var_name),\n",
        "        ckpt_path=np.array(ckpt_path),\n",
        "    )\n",
        "    print(f\"[INFO] Saved lead RMSE curve to: {out_path}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 3. 全局 metrics（表格用）\n",
        "# =========================\n",
        "\n",
        "def compute_global_metrics_for_all_vars(\n",
        "    model: torch.nn.Module,\n",
        "    data_loader,\n",
        "    mean_c11: torch.Tensor,\n",
        "    std_c11: torch.Tensor,\n",
        "    device: torch.device,\n",
        "    precip_idx: int | None = None,\n",
        "    precip_is_log1p_mm: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    返回每个变量的 global RMSE/MAE/ACC/RMSB（物理单位下）。\n",
        "    使用你提供的 weighted_rmse_channels / weighted_mae_channels /\n",
        "    weighted_acc_channels / weighted_rmsb_channels。\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    mean_c11 = mean_c11.to(device)\n",
        "    std_c11  = std_c11.to(device)\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_in, y_out_norm in data_loader:\n",
        "            x_in = x_in.to(device)\n",
        "            y_out_norm = y_out_norm.to(device)\n",
        "\n",
        "            pred_norm = model(\n",
        "                x_in,\n",
        "                y_len=y_out_norm.shape[1],\n",
        "                teacher_forcing_ratio=0.0,\n",
        "                targets=None,\n",
        "            )\n",
        "\n",
        "            pred = denorm_all_channels(pred_norm, mean_c11, std_c11)  # (B,T,C,H,W)\n",
        "            y    = denorm_all_channels(y_out_norm, mean_c11, std_c11)\n",
        "\n",
        "            if precip_idx is not None and precip_is_log1p_mm:\n",
        "                tp_pred_log = pred[:, :, precip_idx, :, :]\n",
        "                tp_y_log    = y[:, :, precip_idx, :, :]\n",
        "\n",
        "                tp_pred_mm = torch.expm1(tp_pred_log).clamp(min=0.0)\n",
        "                tp_y_mm    = torch.expm1(tp_y_log).clamp(min=0.0)\n",
        "\n",
        "                pred[:, :, precip_idx, :, :] = tp_pred_mm\n",
        "                y[:,   :, precip_idx, :, :] = tp_y_mm\n",
        "\n",
        "            B, T, Cc, H, W = pred.shape\n",
        "            preds.append(pred.view(B * T, Cc, H, W))\n",
        "            trues.append(y.view(B * T, Cc, H, W))\n",
        "\n",
        "    pred_all = torch.cat(preds, dim=0)  # (N, C, H, W)\n",
        "    true_all = torch.cat(trues, dim=0)  # (N, C, H, W)\n",
        "\n",
        "    # 这些函数都预期 [B,C,H,W]\n",
        "    rmse_bt = weighted_rmse_channels(pred_all, true_all)  # (N,C)\n",
        "    mae_bt  = weighted_mae_channels(pred_all, true_all)   # (N,C)\n",
        "    acc_bt  = weighted_acc_channels(pred_all, true_all)   # (N,C)\n",
        "\n",
        "    rmse_global = rmse_bt.mean(dim=0).cpu().numpy()  # (C,)\n",
        "    mae_global  = mae_bt.mean(dim=0).cpu().numpy()   # (C,)\n",
        "    acc_global  = acc_bt.mean(dim=0).cpu().numpy()   # (C,)\n",
        "\n",
        "    rmsb_global = weighted_rmsb_channels(pred_all, true_all).cpu().numpy()  # (C,)\n",
        "\n",
        "    return {\n",
        "        \"rmse\": rmse_global,\n",
        "        \"mae\":  mae_global,\n",
        "        \"acc\":  acc_global,\n",
        "        \"rmsb\": rmsb_global,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "GL3kBQPQagqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "def load_model_from_checkpoint_auto_cfg(\n",
        "    ckpt_path: str,\n",
        "    C: int,\n",
        "    device: torch.device,\n",
        ") -> tuple[ConvSeq2Seq, TrainConfig]:\n",
        "    \"\"\"\n",
        "    从 checkpoint 路径自动：\n",
        "      1) 找到 run_dir = ckpt_path/../..\n",
        "      2) 读取 run_dir/config.json -> TrainConfig\n",
        "      3) 用 cfg + C 构建模型\n",
        "      4) 加载 state_dict\n",
        "\n",
        "    返回: (model, cfg)\n",
        "    \"\"\"\n",
        "    ckpt_path = Path(ckpt_path)\n",
        "    run_dir = ckpt_path.parents[1]              # .../enc_xxx/\n",
        "    cfg_path = run_dir / \"config.json\"\n",
        "\n",
        "    with open(cfg_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        cfg_dict = json.load(f)\n",
        "\n",
        "    cfg = TrainConfig(**cfg_dict)\n",
        "\n",
        "    # 根据 C 和 cfg 构建模型\n",
        "    model = _build_model(cfg, C, device)        # 用你之前的 _build_model\n",
        "    state = torch.load(ckpt_path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"[INFO] Loaded checkpoint: {ckpt_path}\")\n",
        "    print(f\"[INFO] Loaded config from: {cfg_path}\")\n",
        "\n",
        "    return model, cfg\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "VAR_UNITS = {\n",
        "    \"2m_temperature\": \"K\",\n",
        "    \"10m_u_component_of_wind\": \"m/s\",\n",
        "    \"10m_v_component_of_wind\": \"m/s\",\n",
        "    \"mean_sea_level_pressure\": \"Pa\",\n",
        "    \"total_precipitation\": \"mm/6h\",      # 你现在的设定：6h 累积 mm\n",
        "    \"total_precipitation_6hr\": \"mm/6h\",  # 防止你变量名用这个\n",
        "}\n",
        "\n",
        "\n",
        "def get_mean_std_c11(ds_train):\n",
        "    \"\"\"\n",
        "    ds_train.mean / std: (C,1,1) or (C,1,1,1)? 按你之前的写法：\n",
        "        ds_train.mean: (C, 1, 1)\n",
        "    你现在是 (C,1,1,1)，下面稍微保险点做一下兼容。\n",
        "    \"\"\"\n",
        "    mean = ds_train.mean  # (C,1,1,1)\n",
        "    std  = ds_train.std   # (C,1,1,1)\n",
        "    # 变成 (1,C,1,1)\n",
        "    if mean.ndim == 4 and mean.shape[0] == 1:\n",
        "        mean_c11 = mean\n",
        "        std_c11  = std\n",
        "    elif mean.ndim == 4 and mean.shape[1] == 1:\n",
        "        # (C,1,1,1) -> (1,C,1,1)\n",
        "        mean_c11 = mean.permute(1,0,2,3).contiguous()\n",
        "        std_c11  = std.permute(1,0,2,3).contiguous()\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected mean/std shape: {mean.shape}\")\n",
        "    return mean_c11, std_c11\n",
        "\n",
        "\n",
        "def evaluate_checkpoint_and_save_all_metrics(\n",
        "    ds_train,\n",
        "    test_loader,\n",
        "    variables,\n",
        "    ckpt_path: str,\n",
        "    # 可选：专门用于 lead-time（比如 y_len=8）\n",
        "    test_loader_lead=None,\n",
        "    time_step_hours: int = 6,\n",
        "    max_lead_hours: int = 48,\n",
        "    precip_var_name: str = \"total_precipitation\",\n",
        "    precip_is_log1p_mm: bool = True,\n",
        "    show_plots: bool = False,\n",
        "    # 可视化参数\n",
        "    num_vis_samples: int = 4,\n",
        "    viz_use_last_t: bool = True,\n",
        "    viz_channel: int | None = None,\n",
        "    viz_all_channels: bool = False,\n",
        "):\n",
        "    \"\"\"\n",
        "    对单个 checkpoint 做完整评估（使用 config.json 自动加载 config）：\n",
        "\n",
        "      - 从 ds_train 读取 mean/std\n",
        "      - 用 mean/std 推出 C，并构建+加载模型\n",
        "      - 对每个变量：计算 lead-time RMSE (用 test_loader_lead 或 test_loader)\n",
        "      - 在 test_loader 上计算全局 RMSE/MAE/ACC/RMSB\n",
        "      - 在 test_loader 上画若干可视化样本\n",
        "\n",
        "    所有输出放在:\n",
        "      run_dir = ckpt_path/../..\n",
        "      metrics_dir = run_dir / \"metrics\"\n",
        "    \"\"\"\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # ---------- 路径 & 目录 ----------\n",
        "    ckpt_path = Path(ckpt_path)\n",
        "    run_dir = ckpt_path.parents[1]\n",
        "    metrics_dir = run_dir / \"metrics\"\n",
        "    metrics_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"[INFO] metrics will be saved to: {metrics_dir}\")\n",
        "\n",
        "    # ---------- 1) mean/std & 通道数 C ----------\n",
        "    mean_c11, std_c11 = get_mean_std_c11(ds_train)\n",
        "    print(\"mean_c11:\", mean_c11.shape, \"std_c11:\", std_c11.shape)\n",
        "    C = mean_c11.shape[1]\n",
        "    print(f\"[INFO] inferred C from mean/std: C={C}\")\n",
        "\n",
        "    # ---------- 2) 自动从 config.json + ckpt 恢复模型 ----------\n",
        "    model, cfg = load_model_from_checkpoint_auto_cfg(\n",
        "        ckpt_path=str(ckpt_path),\n",
        "        C=C,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # ---------- 3) 降水 index ----------\n",
        "    precip_idx = None\n",
        "    if precip_var_name in variables:\n",
        "        precip_idx = variables.index(precip_var_name)\n",
        "        print(f\"[INFO] Precipitation variable: '{precip_var_name}' at index {precip_idx}\")\n",
        "    else:\n",
        "        print(f\"[INFO] Precipitation variable '{precip_var_name}' not found; \"\n",
        "              f\"precip-specific postprocessing will be skipped.\")\n",
        "        precip_is_log1p_mm = False\n",
        "\n",
        "    # ---------- 4) 每个变量的 lead-time RMSE ----------\n",
        "    dl_for_lead = test_loader_lead if test_loader_lead is not None else test_loader\n",
        "    per_var_lead = {}\n",
        "\n",
        "    for var_name in variables:\n",
        "        var_idx = variables.index(var_name)\n",
        "        print(f\"\\n[Lead RMSE] Evaluating variable: {var_name} (idx={var_idx})\")\n",
        "\n",
        "        lead_hours, rmse_lead = compute_lead_rmse_curve_for_var(\n",
        "            model=model,\n",
        "            data_loader=dl_for_lead,\n",
        "            mean_c11=mean_c11,\n",
        "            std_c11=std_c11,\n",
        "            var_idx=var_idx,\n",
        "            time_step_hours=time_step_hours,\n",
        "            max_lead_hours=max_lead_hours,\n",
        "            device=device,\n",
        "            precip_idx=precip_idx,\n",
        "            precip_is_log1p_mm=precip_is_log1p_mm,\n",
        "        )\n",
        "\n",
        "        print(\"  lead_hours:\", lead_hours)\n",
        "        print(\"  rmse_lead:\", rmse_lead)\n",
        "\n",
        "        per_var_lead[var_name] = (lead_hours, rmse_lead)\n",
        "\n",
        "        # 保存 npz\n",
        "        out_npz = metrics_dir / f\"lead_rmse_{var_name}_up_to_{max_lead_hours}h.npz\"\n",
        "        save_lead_rmse_npz(str(out_npz), lead_hours, rmse_lead, var_name, str(ckpt_path))\n",
        "\n",
        "        # 画图\n",
        "        unit = VAR_UNITS.get(var_name, \"\")\n",
        "        ylabel = f\"Weighted RMSE ({unit})\" if unit else \"Weighted RMSE\"\n",
        "\n",
        "        plt.figure(figsize=(5, 4))\n",
        "        plt.plot(lead_hours / 24.0, rmse_lead, marker=\"o\")\n",
        "        plt.xlabel(\"Lead time (days)\")\n",
        "        plt.ylabel(ylabel)\n",
        "        plt.title(f\"{var_name} – RMSE vs Lead Time (Test)\")\n",
        "        plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        out_png = metrics_dir / f\"lead_rmse_{var_name}_up_to_{max_lead_hours}h.png\"\n",
        "        plt.savefig(out_png, dpi=160)\n",
        "        print(f\"  [saved figure] {out_png}\")\n",
        "\n",
        "        if show_plots:\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.close()\n",
        "\n",
        "    # ---------- 5) 全局 metrics（在 test_loader 上，通常 y_len=4） ----------\n",
        "    print(\"\\n[Global metrics per variable on test set]\")\n",
        "    metrics_all = compute_global_metrics_for_all_vars(\n",
        "        model=model,\n",
        "        data_loader=test_loader,\n",
        "        mean_c11=mean_c11,\n",
        "        std_c11=std_c11,\n",
        "        device=device,\n",
        "        precip_idx=precip_idx,\n",
        "        precip_is_log1p_mm=precip_is_log1p_mm,\n",
        "    )\n",
        "\n",
        "    for c, vname in enumerate(variables):\n",
        "        unit = VAR_UNITS.get(vname, \"\")\n",
        "        unit_str = f\" ({unit})\" if unit else \"\"\n",
        "        print(\n",
        "            f\"{vname:30s}{unit_str:12s} | \"\n",
        "            f\"RMSE={metrics_all['rmse'][c]:.4g}  \"\n",
        "            f\"MAE={metrics_all['mae'][c]:.4g}  \"\n",
        "            f\"ACC={metrics_all['acc'][c]:.4f}  \"\n",
        "            f\"RMSB={metrics_all['rmsb'][c]:.4g}\"\n",
        "        )\n",
        "\n",
        "    global_npz = metrics_dir / \"global_metrics_all_vars.npz\"\n",
        "    np.savez_compressed(\n",
        "        global_npz,\n",
        "        variables=np.array(variables),\n",
        "        rmse=metrics_all[\"rmse\"],\n",
        "        mae=metrics_all[\"mae\"],\n",
        "        acc=metrics_all[\"acc\"],\n",
        "        rmsb=metrics_all[\"rmsb\"],\n",
        "        ckpt_path=np.array(str(ckpt_path)),\n",
        "    )\n",
        "    print(f\"\\n[INFO] Saved global metrics to: {global_npz}\")\n",
        "\n",
        "    # ---------- 6) 可视化若干 test 样本 ----------\n",
        "    vis_dir = metrics_dir / \"vis\"\n",
        "    vis_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"[INFO] Saving visualization samples to: {vis_dir}\")\n",
        "\n",
        "    pin = torch.cuda.is_available()\n",
        "    vis_loader = DataLoader(\n",
        "        test_loader.dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        pin_memory=pin,\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        count = 0\n",
        "        for x_in, y_out in vis_loader:\n",
        "            x_in = x_in.to(device, non_blocking=True)\n",
        "            y_out = y_out.to(device, non_blocking=True)\n",
        "\n",
        "            save_prefix = vis_dir / f\"test_sample_{count:03d}\"\n",
        "            visualize_once(\n",
        "                model=model,\n",
        "                x_in=x_in,\n",
        "                y_out=y_out,\n",
        "                mean=mean_c11.to(device),\n",
        "                std=std_c11.to(device),\n",
        "                save_prefix=save_prefix,\n",
        "                use_last_t=viz_use_last_t,\n",
        "                viz_channel=viz_channel,\n",
        "                draw_all_channels=viz_all_channels,\n",
        "            )\n",
        "            print(f\"  [vis] saved {save_prefix}.png\")\n",
        "\n",
        "            count += 1\n",
        "            if count >= num_vis_samples:\n",
        "                break\n",
        "\n",
        "    return model, metrics_all, per_var_lead\n"
      ],
      "metadata": {
        "id": "g_VpDMj4jBkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### convgru+unet"
      ],
      "metadata": {
        "id": "NVt8wuHXGKBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size = 8\n",
        "\n",
        "# train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True,  num_workers=4, pin_memory=True)\n",
        "# val_loader   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# mean_c11 = ds_train.mean.permute(1, 0, 2, 3).contiguous()  # (1,C,1,1)\n",
        "# std_c11  = ds_train.std.permute(1, 0, 2, 3).contiguous()   # (1,C,1,1)\n",
        "\n",
        "mean_c11 = ds_train.mean   # (1,C,1,1)\n",
        "std_c11  = ds_train.std    # (1,C,1,1)\n",
        "\n",
        "convgru_unet_cfg = TrainConfig(\n",
        "    batch_size=batch_size,\n",
        "    lr=1e-4,\n",
        "    max_epochs=50,\n",
        "    enc_cell_type=\"convgru\",\n",
        "    dec_cell_type=\"convgru\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=False,\n",
        "    unet_head=True,\n",
        "    out_root=\"./6hr_runs_w_unet\",\n",
        "    viz_every_n_epochs=10,\n",
        "    viz_use_last_t=True,\n",
        "    viz_channel=None,\n",
        "    save_all_channels_png=True,\n",
        ")\n",
        "\n",
        "convgru_unet_model, convgru_unet_history = train(convgru_unet_cfg, train_loader, val_loader, mean_c11, std_c11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6eYqRssYfQU",
        "outputId": "7e4e3f01-14a8-442a-b437-b2b88ee1c276",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] TF=1.00 | train MSE=0.238816 RMSE=0.488688 MAE=0.287056 | val MSE=0.276706 RMSE=0.526028 MAE=0.297245\n",
            "  >> Saved best model (val MSE=0.276706)\n",
            "[Epoch 2/50] TF=1.00 | train MSE=0.119056 RMSE=0.345045 MAE=0.195205 | val MSE=0.252701 RMSE=0.502694 MAE=0.275095\n",
            "  >> Saved best model (val MSE=0.252701)\n",
            "[Epoch 3/50] TF=1.00 | train MSE=0.106208 RMSE=0.325896 MAE=0.181229 | val MSE=0.228772 RMSE=0.478301 MAE=0.256214\n",
            "  >> Saved best model (val MSE=0.228772)\n",
            "[Epoch 4/50] TF=1.00 | train MSE=0.098800 RMSE=0.314324 MAE=0.172879 | val MSE=0.225265 RMSE=0.474620 MAE=0.256235\n",
            "  >> Saved best model (val MSE=0.225265)\n",
            "[Epoch 5/50] TF=1.00 | train MSE=0.093532 RMSE=0.305829 MAE=0.166710 | val MSE=0.216599 RMSE=0.465402 MAE=0.246261\n",
            "  >> Saved best model (val MSE=0.216599)\n",
            "[Epoch 6/50] TF=1.00 | train MSE=0.089842 RMSE=0.299736 MAE=0.162112 | val MSE=0.205940 RMSE=0.453807 MAE=0.238630\n",
            "  >> Saved best model (val MSE=0.205940)\n",
            "[Epoch 7/50] TF=1.00 | train MSE=0.086444 RMSE=0.294014 MAE=0.157899 | val MSE=0.205245 RMSE=0.453039 MAE=0.238885\n",
            "  >> Saved best model (val MSE=0.205245)\n",
            "[Epoch 8/50] TF=1.00 | train MSE=0.084380 RMSE=0.290482 MAE=0.155467 | val MSE=0.203124 RMSE=0.450693 MAE=0.237947\n",
            "  >> Saved best model (val MSE=0.203124)\n",
            "[Epoch 9/50] TF=1.00 | train MSE=0.082261 RMSE=0.286811 MAE=0.152646 | val MSE=0.229969 RMSE=0.479551 MAE=0.259549\n",
            "[Epoch 10/50] TF=1.00 | train MSE=0.080850 RMSE=0.284341 MAE=0.150968 | val MSE=0.190147 RMSE=0.436058 MAE=0.227180\n",
            "  >> Saved best model (val MSE=0.190147)\n",
            "[Epoch 11/50] TF=1.00 | train MSE=0.079010 RMSE=0.281088 MAE=0.148496 | val MSE=0.189818 RMSE=0.435681 MAE=0.226590\n",
            "  >> Saved best model (val MSE=0.189818)\n",
            "[Epoch 12/50] TF=1.00 | train MSE=0.077398 RMSE=0.278204 MAE=0.146272 | val MSE=0.188631 RMSE=0.434316 MAE=0.224279\n",
            "  >> Saved best model (val MSE=0.188631)\n",
            "[Epoch 13/50] TF=1.00 | train MSE=0.076398 RMSE=0.276401 MAE=0.145047 | val MSE=0.182475 RMSE=0.427171 MAE=0.218468\n",
            "  >> Saved best model (val MSE=0.182475)\n",
            "[Epoch 14/50] TF=1.00 | train MSE=0.075386 RMSE=0.274565 MAE=0.143680 | val MSE=0.178402 RMSE=0.422377 MAE=0.219057\n",
            "  >> Saved best model (val MSE=0.178402)\n",
            "[Epoch 15/50] TF=1.00 | train MSE=0.074299 RMSE=0.272578 MAE=0.142123 | val MSE=0.181566 RMSE=0.426106 MAE=0.219277\n",
            "[Epoch 16/50] TF=1.00 | train MSE=0.073810 RMSE=0.271680 MAE=0.141588 | val MSE=0.187657 RMSE=0.433195 MAE=0.225906\n",
            "[Epoch 17/50] TF=1.00 | train MSE=0.072804 RMSE=0.269822 MAE=0.140095 | val MSE=0.194891 RMSE=0.441465 MAE=0.229429\n",
            "[Epoch 18/50] TF=1.00 | train MSE=0.072070 RMSE=0.268458 MAE=0.139106 | val MSE=0.173433 RMSE=0.416453 MAE=0.211138\n",
            "  >> Saved best model (val MSE=0.173433)\n",
            "[Epoch 19/50] TF=1.00 | train MSE=0.071865 RMSE=0.268077 MAE=0.139020 | val MSE=0.179473 RMSE=0.423643 MAE=0.218891\n",
            "[Epoch 20/50] TF=1.00 | train MSE=0.070943 RMSE=0.266350 MAE=0.137628 | val MSE=0.173514 RMSE=0.416550 MAE=0.215397\n",
            "[Epoch 21/50] TF=1.00 | train MSE=0.070226 RMSE=0.265002 MAE=0.136609 | val MSE=0.188030 RMSE=0.433624 MAE=0.219700\n",
            "[Epoch 22/50] TF=1.00 | train MSE=0.069655 RMSE=0.263923 MAE=0.135812 | val MSE=0.171636 RMSE=0.414289 MAE=0.213965\n",
            "  >> Saved best model (val MSE=0.171636)\n",
            "[Epoch 23/50] TF=1.00 | train MSE=0.069566 RMSE=0.263753 MAE=0.135875 | val MSE=0.170795 RMSE=0.413274 MAE=0.212775\n",
            "  >> Saved best model (val MSE=0.170795)\n",
            "[Epoch 24/50] TF=1.00 | train MSE=0.068863 RMSE=0.262418 MAE=0.134894 | val MSE=0.177686 RMSE=0.421528 MAE=0.217696\n",
            "[Epoch 25/50] TF=1.00 | train MSE=0.068337 RMSE=0.261414 MAE=0.134135 | val MSE=0.170614 RMSE=0.413055 MAE=0.207354\n",
            "  >> Saved best model (val MSE=0.170614)\n",
            "[Epoch 26/50] TF=1.00 | train MSE=0.067839 RMSE=0.260458 MAE=0.133368 | val MSE=0.168890 RMSE=0.410963 MAE=0.212491\n",
            "  >> Saved best model (val MSE=0.168890)\n",
            "[Epoch 27/50] TF=1.00 | train MSE=0.067513 RMSE=0.259832 MAE=0.132989 | val MSE=0.174006 RMSE=0.417140 MAE=0.216681\n",
            "[Epoch 28/50] TF=1.00 | train MSE=0.066985 RMSE=0.258815 MAE=0.132273 | val MSE=0.164958 RMSE=0.406150 MAE=0.206472\n",
            "  >> Saved best model (val MSE=0.164958)\n",
            "[Epoch 29/50] TF=1.00 | train MSE=0.066965 RMSE=0.258776 MAE=0.132335 | val MSE=0.166409 RMSE=0.407932 MAE=0.205514\n",
            "[Epoch 30/50] TF=1.00 | train MSE=0.066422 RMSE=0.257724 MAE=0.131554 | val MSE=0.162569 RMSE=0.403199 MAE=0.203981\n",
            "  >> Saved best model (val MSE=0.162569)\n",
            "[Epoch 31/50] TF=1.00 | train MSE=0.066166 RMSE=0.257228 MAE=0.131266 | val MSE=0.170032 RMSE=0.412350 MAE=0.208354\n",
            "[Epoch 32/50] TF=1.00 | train MSE=0.065649 RMSE=0.256220 MAE=0.130496 | val MSE=0.161446 RMSE=0.401803 MAE=0.205136\n",
            "  >> Saved best model (val MSE=0.161446)\n",
            "[Epoch 33/50] TF=1.00 | train MSE=0.065315 RMSE=0.255568 MAE=0.130043 | val MSE=0.163596 RMSE=0.404471 MAE=0.203263\n",
            "[Epoch 34/50] TF=1.00 | train MSE=0.065421 RMSE=0.255775 MAE=0.130360 | val MSE=0.175144 RMSE=0.418502 MAE=0.211364\n",
            "[Epoch 35/50] TF=1.00 | train MSE=0.064901 RMSE=0.254757 MAE=0.129545 | val MSE=0.165517 RMSE=0.406837 MAE=0.204294\n",
            "[Epoch 36/50] TF=1.00 | train MSE=0.064723 RMSE=0.254408 MAE=0.129348 | val MSE=0.165944 RMSE=0.407362 MAE=0.205997\n",
            "[Epoch 37/50] TF=1.00 | train MSE=0.064766 RMSE=0.254491 MAE=0.129440 | val MSE=0.164176 RMSE=0.405186 MAE=0.203666\n",
            "[Epoch 38/50] TF=1.00 | train MSE=0.063938 RMSE=0.252860 MAE=0.128181 | val MSE=0.162233 RMSE=0.402782 MAE=0.204459\n",
            "[Epoch 39/50] TF=1.00 | train MSE=0.064155 RMSE=0.253288 MAE=0.128724 | val MSE=0.166663 RMSE=0.408243 MAE=0.205746\n",
            "[Epoch 40/50] TF=1.00 | train MSE=0.063497 RMSE=0.251986 MAE=0.127603 | val MSE=0.161980 RMSE=0.402467 MAE=0.202041\n",
            "[Epoch 41/50] TF=1.00 | train MSE=0.063278 RMSE=0.251552 MAE=0.127299 | val MSE=0.158160 RMSE=0.397694 MAE=0.199951\n",
            "  >> Saved best model (val MSE=0.158160)\n",
            "[Epoch 42/50] TF=1.00 | train MSE=0.063341 RMSE=0.251677 MAE=0.127563 | val MSE=0.156665 RMSE=0.395810 MAE=0.198516\n",
            "  >> Saved best model (val MSE=0.156665)\n",
            "[Epoch 43/50] TF=1.00 | train MSE=0.062955 RMSE=0.250908 MAE=0.126896 | val MSE=0.160377 RMSE=0.400470 MAE=0.202607\n",
            "[Epoch 44/50] TF=1.00 | train MSE=0.062648 RMSE=0.250295 MAE=0.126458 | val MSE=0.157498 RMSE=0.396860 MAE=0.199998\n",
            "[Epoch 45/50] TF=1.00 | train MSE=0.062698 RMSE=0.250396 MAE=0.126617 | val MSE=0.159516 RMSE=0.399394 MAE=0.199281\n",
            "[Epoch 46/50] TF=1.00 | train MSE=0.062310 RMSE=0.249619 MAE=0.126051 | val MSE=0.157683 RMSE=0.397093 MAE=0.198670\n",
            "[Epoch 47/50] TF=1.00 | train MSE=0.062094 RMSE=0.249186 MAE=0.125748 | val MSE=0.158984 RMSE=0.398728 MAE=0.199866\n",
            "[Epoch 48/50] TF=1.00 | train MSE=0.062097 RMSE=0.249193 MAE=0.125823 | val MSE=0.157887 RMSE=0.397350 MAE=0.198000\n",
            "[Epoch 49/50] TF=1.00 | train MSE=0.061716 RMSE=0.248428 MAE=0.125243 | val MSE=0.169274 RMSE=0.411429 MAE=0.211084\n",
            "[Epoch 50/50] TF=1.00 | train MSE=0.061945 RMSE=0.248887 MAE=0.125612 | val MSE=0.156704 RMSE=0.395858 MAE=0.197636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds_test_lead = ERA5XYDataset6h(\n",
        "    np_test,\n",
        "    variables,\n",
        "    x_len=8,\n",
        "    y_len=8,   # ← 48h lead\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        "    mean=ds_train.mean,\n",
        "    std=ds_train.std,\n",
        "    precip_to_mm=True,\n",
        "    precip_log1p=True,\n",
        ")\n",
        "\n",
        "test_loader_lead = DataLoader(ds_test_lead, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "ckpt_path = \"./6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/checkpoints/best.pt\"\n",
        "\n",
        "model, metrics_all, per_var_lead = evaluate_checkpoint_and_save_all_metrics(\n",
        "    ds_train=ds_train,\n",
        "    test_loader=test_loader,\n",
        "    variables=variables,\n",
        "    ckpt_path=ckpt_path,\n",
        "    test_loader_lead=test_loader_lead,\n",
        "    time_step_hours=6,\n",
        "    max_lead_hours=48,\n",
        "    precip_var_name=\"total_precipitation_6hr\",  # precip variable name\n",
        "    precip_is_log1p_mm=True,\n",
        "    show_plots=True,\n",
        "    num_vis_samples=4,\n",
        "    viz_use_last_t=True,\n",
        "    viz_channel=None,\n",
        "    viz_all_channels=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcL5iN2iVxzo",
        "outputId": "dfefacb8-d537-4e22-f6b9-2fb8235a4073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] metrics will be saved to: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics\n",
            "mean_c11: torch.Size([1, 5, 1, 1]) std_c11: torch.Size([1, 5, 1, 1])\n",
            "[INFO] inferred C from mean/std: C=5\n",
            "[INFO] Loaded checkpoint: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/checkpoints/best.pt\n",
            "[INFO] Loaded config from: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/config.json\n",
            "[INFO] Precipitation variable: 'total_precipitation_6hr' at index 4\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 2m_temperature (idx=0)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [3.0689409 3.4653127 4.102208  4.503538  5.014202  5.5162764 5.9194713\n",
            " 6.244851 ]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_2m_temperature_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_2m_temperature_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 10m_u_component_of_wind (idx=1)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.0487138 1.4979849 1.919223  2.3116899 2.716897  3.0753102 3.3928177\n",
            " 3.6607068]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_10m_u_component_of_wind_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_10m_u_component_of_wind_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 10m_v_component_of_wind (idx=2)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.0771401 1.532665  1.9600941 2.3585372 2.756033  3.1092675 3.4175851\n",
            " 3.6841621]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_10m_v_component_of_wind_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_10m_v_component_of_wind_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: mean_sea_level_pressure (idx=3)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [ 923.23865 1088.7267  1282.683   1353.3936  1451.925   1570.8419\n",
            " 1670.441   1734.8428 ]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_mean_sea_level_pressure_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_mean_sea_level_pressure_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: total_precipitation_6hr (idx=4)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.1053963 1.4081893 1.5915632 1.7008507 1.7945596 1.8726566 1.9286499\n",
            " 1.9671086]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_total_precipitation_6hr_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/lead_rmse_total_precipitation_6hr_up_to_48h.png\n",
            "\n",
            "[Global metrics per variable on test set]\n",
            "2m_temperature                 (K)         | RMSE=3.785  MAE=3.013  ACC=0.9999  RMSB=0.1962\n",
            "10m_u_component_of_wind        (m/s)       | RMSE=1.694  MAE=1.215  ACC=0.9476  RMSB=0.02793\n",
            "10m_v_component_of_wind        (m/s)       | RMSE=1.732  MAE=1.24  ACC=0.9151  RMSB=0.02422\n",
            "mean_sea_level_pressure        (Pa)        | RMSE=1162  MAE=953.5  ACC=1.0000  RMSB=66.06\n",
            "total_precipitation_6hr        (mm/6h)     | RMSE=1.451  MAE=0.4743  ACC=0.7348  RMSB=0.02123\n",
            "\n",
            "[INFO] Saved global metrics to: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/global_metrics_all_vars.npz\n",
            "[INFO] Saving visualization samples to: 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/vis\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/vis/test_sample_000.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/vis/test_sample_001.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/vis/test_sample_002.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convgru_dec_convgru_20251211-201151/metrics/vis/test_sample_003.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### convrnn+unet"
      ],
      "metadata": {
        "id": "6k57LhgDkiXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_c11 = ds_train.mean   # (1,C,1,1)\n",
        "std_c11  = ds_train.std    # (1,C,1,1)\n",
        "\n",
        "convrnn_unet_cfg = TrainConfig(\n",
        "    batch_size=batch_size,\n",
        "    lr=1e-4,\n",
        "    max_epochs=50,\n",
        "    enc_cell_type=\"convrnn\",\n",
        "    dec_cell_type=\"convrnn\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=False,\n",
        "    unet_head=True,\n",
        "    out_root=\"./6hr_runs_w_unet\",\n",
        "    viz_every_n_epochs=10,\n",
        "    viz_use_last_t=True,\n",
        "    viz_channel=None,\n",
        "    save_all_channels_png=True,\n",
        ")\n",
        "\n",
        "convrnn_unet_model, convrnn_unet_history = train(convrnn_unet_cfg, train_loader, val_loader, mean_c11, std_c11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nFqFFMIgkklO",
        "outputId": "3ccc24bb-ef7c-4a22-efe5-8b3fafe46d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] TF=1.00 | train MSE=0.281140 RMSE=0.530227 MAE=0.312187 | val MSE=0.291788 RMSE=0.540174 MAE=0.309980\n",
            "  >> Saved best model (val MSE=0.291788)\n",
            "[Epoch 2/50] TF=1.00 | train MSE=0.119460 RMSE=0.345629 MAE=0.195249 | val MSE=0.255836 RMSE=0.505802 MAE=0.273868\n",
            "  >> Saved best model (val MSE=0.255836)\n",
            "[Epoch 3/50] TF=1.00 | train MSE=0.106599 RMSE=0.326495 MAE=0.181494 | val MSE=0.247663 RMSE=0.497658 MAE=0.273260\n",
            "  >> Saved best model (val MSE=0.247663)\n",
            "[Epoch 4/50] TF=1.00 | train MSE=0.099382 RMSE=0.315250 MAE=0.173570 | val MSE=0.225322 RMSE=0.474681 MAE=0.251960\n",
            "  >> Saved best model (val MSE=0.225322)\n",
            "[Epoch 5/50] TF=1.00 | train MSE=0.094478 RMSE=0.307372 MAE=0.167790 | val MSE=0.219990 RMSE=0.469031 MAE=0.249418\n",
            "  >> Saved best model (val MSE=0.219990)\n",
            "[Epoch 6/50] TF=1.00 | train MSE=0.090704 RMSE=0.301172 MAE=0.163401 | val MSE=0.213486 RMSE=0.462045 MAE=0.244796\n",
            "  >> Saved best model (val MSE=0.213486)\n",
            "[Epoch 7/50] TF=1.00 | train MSE=0.087887 RMSE=0.296458 MAE=0.159768 | val MSE=0.208056 RMSE=0.456132 MAE=0.239035\n",
            "  >> Saved best model (val MSE=0.208056)\n",
            "[Epoch 8/50] TF=1.00 | train MSE=0.085538 RMSE=0.292468 MAE=0.156764 | val MSE=0.202122 RMSE=0.449580 MAE=0.236681\n",
            "  >> Saved best model (val MSE=0.202122)\n",
            "[Epoch 9/50] TF=1.00 | train MSE=0.083628 RMSE=0.289186 MAE=0.154123 | val MSE=0.205194 RMSE=0.452984 MAE=0.238031\n",
            "[Epoch 10/50] TF=1.00 | train MSE=0.081796 RMSE=0.286000 MAE=0.151715 | val MSE=0.202442 RMSE=0.449935 MAE=0.239430\n",
            "[Epoch 11/50] TF=1.00 | train MSE=0.080409 RMSE=0.283565 MAE=0.149899 | val MSE=0.196578 RMSE=0.443371 MAE=0.231935\n",
            "  >> Saved best model (val MSE=0.196578)\n",
            "[Epoch 12/50] TF=1.00 | train MSE=0.079266 RMSE=0.281542 MAE=0.148285 | val MSE=0.188548 RMSE=0.434221 MAE=0.225653\n",
            "  >> Saved best model (val MSE=0.188548)\n",
            "[Epoch 13/50] TF=1.00 | train MSE=0.078192 RMSE=0.279629 MAE=0.146899 | val MSE=0.193794 RMSE=0.440221 MAE=0.227794\n",
            "[Epoch 14/50] TF=1.00 | train MSE=0.077142 RMSE=0.277745 MAE=0.145408 | val MSE=0.194586 RMSE=0.441119 MAE=0.230047\n",
            "[Epoch 15/50] TF=1.00 | train MSE=0.075927 RMSE=0.275548 MAE=0.143683 | val MSE=0.188067 RMSE=0.433667 MAE=0.233284\n",
            "  >> Saved best model (val MSE=0.188067)\n",
            "[Epoch 16/50] TF=1.00 | train MSE=0.075295 RMSE=0.274400 MAE=0.142974 | val MSE=0.191658 RMSE=0.437787 MAE=0.227731\n",
            "[Epoch 17/50] TF=1.00 | train MSE=0.074236 RMSE=0.272462 MAE=0.141317 | val MSE=0.185056 RMSE=0.430182 MAE=0.227361\n",
            "  >> Saved best model (val MSE=0.185056)\n",
            "[Epoch 18/50] TF=1.00 | train MSE=0.073809 RMSE=0.271678 MAE=0.140946 | val MSE=0.188426 RMSE=0.434081 MAE=0.238018\n",
            "[Epoch 19/50] TF=1.00 | train MSE=0.073285 RMSE=0.270713 MAE=0.140329 | val MSE=0.177817 RMSE=0.421684 MAE=0.213377\n",
            "  >> Saved best model (val MSE=0.177817)\n",
            "[Epoch 20/50] TF=1.00 | train MSE=0.072399 RMSE=0.269070 MAE=0.138852 | val MSE=0.179626 RMSE=0.423823 MAE=0.221187\n",
            "[Epoch 21/50] TF=1.00 | train MSE=0.071972 RMSE=0.268276 MAE=0.138362 | val MSE=0.182414 RMSE=0.427099 MAE=0.218515\n",
            "[Epoch 22/50] TF=1.00 | train MSE=0.071397 RMSE=0.267202 MAE=0.137528 | val MSE=0.179731 RMSE=0.423947 MAE=0.219116\n",
            "[Epoch 23/50] TF=1.00 | train MSE=0.071134 RMSE=0.266710 MAE=0.137326 | val MSE=0.185673 RMSE=0.430898 MAE=0.225390\n",
            "[Epoch 24/50] TF=1.00 | train MSE=0.070177 RMSE=0.264910 MAE=0.135823 | val MSE=0.208425 RMSE=0.456536 MAE=0.242099\n",
            "[Epoch 25/50] TF=1.00 | train MSE=0.069906 RMSE=0.264398 MAE=0.135510 | val MSE=0.179798 RMSE=0.424026 MAE=0.224448\n",
            "[Epoch 26/50] TF=1.00 | train MSE=0.069558 RMSE=0.263738 MAE=0.135073 | val MSE=0.174354 RMSE=0.417557 MAE=0.211455\n",
            "  >> Saved best model (val MSE=0.174354)\n",
            "[Epoch 27/50] TF=1.00 | train MSE=0.069173 RMSE=0.263008 MAE=0.134524 | val MSE=0.187572 RMSE=0.433096 MAE=0.220830\n",
            "[Epoch 28/50] TF=1.00 | train MSE=0.069032 RMSE=0.262739 MAE=0.134534 | val MSE=0.179264 RMSE=0.423396 MAE=0.216092\n",
            "[Epoch 29/50] TF=1.00 | train MSE=0.068419 RMSE=0.261570 MAE=0.133576 | val MSE=0.179098 RMSE=0.423200 MAE=0.215280\n",
            "[Epoch 30/50] TF=1.00 | train MSE=0.068345 RMSE=0.261430 MAE=0.133592 | val MSE=0.172671 RMSE=0.415537 MAE=0.209860\n",
            "  >> Saved best model (val MSE=0.172671)\n",
            "[Epoch 31/50] TF=1.00 | train MSE=0.067592 RMSE=0.259984 MAE=0.132349 | val MSE=0.176125 RMSE=0.419672 MAE=0.213538\n",
            "[Epoch 32/50] TF=1.00 | train MSE=0.067280 RMSE=0.259383 MAE=0.131974 | val MSE=0.169085 RMSE=0.411200 MAE=0.208501\n",
            "  >> Saved best model (val MSE=0.169085)\n",
            "[Epoch 33/50] TF=1.00 | train MSE=0.067041 RMSE=0.258924 MAE=0.131702 | val MSE=0.168274 RMSE=0.410212 MAE=0.210088\n",
            "  >> Saved best model (val MSE=0.168274)\n",
            "[Epoch 34/50] TF=1.00 | train MSE=0.066896 RMSE=0.258643 MAE=0.131497 | val MSE=0.172685 RMSE=0.415554 MAE=0.208405\n",
            "[Epoch 35/50] TF=1.00 | train MSE=0.066466 RMSE=0.257811 MAE=0.130916 | val MSE=0.166099 RMSE=0.407553 MAE=0.204821\n",
            "  >> Saved best model (val MSE=0.166099)\n",
            "[Epoch 36/50] TF=1.00 | train MSE=0.066305 RMSE=0.257497 MAE=0.130738 | val MSE=0.191798 RMSE=0.437947 MAE=0.236693\n",
            "[Epoch 37/50] TF=1.00 | train MSE=0.066224 RMSE=0.257340 MAE=0.130702 | val MSE=0.173008 RMSE=0.415943 MAE=0.215012\n",
            "[Epoch 38/50] TF=1.00 | train MSE=0.066066 RMSE=0.257034 MAE=0.130747 | val MSE=0.166679 RMSE=0.408264 MAE=0.206468\n",
            "[Epoch 39/50] TF=1.00 | train MSE=0.065377 RMSE=0.255690 MAE=0.129459 | val MSE=0.166286 RMSE=0.407782 MAE=0.209167\n",
            "[Epoch 40/50] TF=1.00 | train MSE=0.065171 RMSE=0.255285 MAE=0.129219 | val MSE=0.168642 RMSE=0.410661 MAE=0.208390\n",
            "[Epoch 41/50] TF=1.00 | train MSE=0.065284 RMSE=0.255506 MAE=0.129490 | val MSE=0.164746 RMSE=0.405889 MAE=0.204512\n",
            "  >> Saved best model (val MSE=0.164746)\n",
            "[Epoch 42/50] TF=1.00 | train MSE=0.064790 RMSE=0.254539 MAE=0.128736 | val MSE=0.167702 RMSE=0.409514 MAE=0.217815\n",
            "[Epoch 43/50] TF=1.00 | train MSE=0.064866 RMSE=0.254689 MAE=0.129014 | val MSE=0.163557 RMSE=0.404422 MAE=0.202632\n",
            "  >> Saved best model (val MSE=0.163557)\n",
            "[Epoch 44/50] TF=1.00 | train MSE=0.064382 RMSE=0.253736 MAE=0.128207 | val MSE=0.165277 RMSE=0.406543 MAE=0.209848\n",
            "[Epoch 45/50] TF=1.00 | train MSE=0.064136 RMSE=0.253251 MAE=0.127902 | val MSE=0.161917 RMSE=0.402389 MAE=0.205580\n",
            "  >> Saved best model (val MSE=0.161917)\n",
            "[Epoch 46/50] TF=1.00 | train MSE=0.064100 RMSE=0.253180 MAE=0.127913 | val MSE=0.169728 RMSE=0.411980 MAE=0.217999\n",
            "[Epoch 47/50] TF=1.00 | train MSE=0.063784 RMSE=0.252556 MAE=0.127442 | val MSE=0.163537 RMSE=0.404397 MAE=0.201272\n",
            "[Epoch 48/50] TF=1.00 | train MSE=0.063938 RMSE=0.252860 MAE=0.127894 | val MSE=0.166733 RMSE=0.408330 MAE=0.203488\n",
            "[Epoch 49/50] TF=1.00 | train MSE=0.063375 RMSE=0.251744 MAE=0.126884 | val MSE=0.163997 RMSE=0.404965 MAE=0.207193\n",
            "[Epoch 50/50] TF=1.00 | train MSE=0.063204 RMSE=0.251404 MAE=0.126658 | val MSE=0.161231 RMSE=0.401536 MAE=0.202389\n",
            "  >> Saved best model (val MSE=0.161231)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds_test_lead = ERA5XYDataset6h(\n",
        "    np_test,\n",
        "    variables,\n",
        "    x_len=8,\n",
        "    y_len=8,   # ← 48h lead\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        "    mean=ds_train.mean,\n",
        "    std=ds_train.std,\n",
        "    precip_to_mm=True,\n",
        "    precip_log1p=True,\n",
        ")\n",
        "\n",
        "test_loader_lead = DataLoader(ds_test_lead, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "ckpt_path = \"./6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/checkpoints/best.pt\"\n",
        "\n",
        "model, metrics_all, per_var_lead = evaluate_checkpoint_and_save_all_metrics(\n",
        "    ds_train=ds_train,\n",
        "    test_loader=test_loader,           # y_len=4\n",
        "    variables=variables,\n",
        "    ckpt_path=ckpt_path,\n",
        "    test_loader_lead=test_loader_lead, # y_len=8, 专门用来画 lead curve 到 48h\n",
        "    time_step_hours=6,\n",
        "    max_lead_hours=48,\n",
        "    precip_var_name=\"total_precipitation_6hr\",  # precip variable name\n",
        "    precip_is_log1p_mm=True,\n",
        "    show_plots=True,\n",
        "    num_vis_samples=4,\n",
        "    viz_use_last_t=True,\n",
        "    viz_channel=None,\n",
        "    viz_all_channels=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQIcoWC-lHXm",
        "outputId": "4e19bdcf-e83b-48b1-81b8-0b7c2c4c4856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] metrics will be saved to: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics\n",
            "mean_c11: torch.Size([1, 5, 1, 1]) std_c11: torch.Size([1, 5, 1, 1])\n",
            "[INFO] inferred C from mean/std: C=5\n",
            "[INFO] Loaded checkpoint: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/checkpoints/best.pt\n",
            "[INFO] Loaded config from: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/config.json\n",
            "[INFO] Precipitation variable: 'total_precipitation_6hr' at index 4\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 2m_temperature (idx=0)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [ 2.8656409  3.618819   4.9545426  6.397257   8.179749  10.033303\n",
            " 11.980595  14.096959 ]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_2m_temperature_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_2m_temperature_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 10m_u_component_of_wind (idx=1)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.0514733 1.5368191 1.9795988 2.3869708 2.7880867 3.1498682 3.457501\n",
            " 3.7221007]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_10m_u_component_of_wind_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_10m_u_component_of_wind_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 10m_v_component_of_wind (idx=2)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.0743713 1.5452948 1.9876012 2.4016442 2.8126464 3.1714547 3.4799829\n",
            " 3.7320445]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_10m_v_component_of_wind_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_10m_v_component_of_wind_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: mean_sea_level_pressure (idx=3)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [ 915.2112  918.8153 1084.7089 1286.382  1556.015  1814.3569 2107.55\n",
            " 2452.241 ]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_mean_sea_level_pressure_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_mean_sea_level_pressure_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: total_precipitation_6hr (idx=4)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.1167688 1.4059391 1.5980412 1.7255638 1.8261172 1.904448  1.9638628\n",
            " 2.0037687]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_total_precipitation_6hr_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/lead_rmse_total_precipitation_6hr_up_to_48h.png\n",
            "\n",
            "[Global metrics per variable on test set]\n",
            "2m_temperature                 (K)         | RMSE=4.46  MAE=3.623  ACC=0.9999  RMSB=0.2654\n",
            "10m_u_component_of_wind        (m/s)       | RMSE=1.739  MAE=1.265  ACC=0.9438  RMSB=0.04225\n",
            "10m_v_component_of_wind        (m/s)       | RMSE=1.752  MAE=1.255  ACC=0.9130  RMSB=0.0259\n",
            "mean_sea_level_pressure        (Pa)        | RMSE=1052  MAE=853  ACC=1.0000  RMSB=48.71\n",
            "total_precipitation_6hr        (mm/6h)     | RMSE=1.461  MAE=0.4816  ACC=0.7261  RMSB=0.01937\n",
            "\n",
            "[INFO] Saved global metrics to: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/global_metrics_all_vars.npz\n",
            "[INFO] Saving visualization samples to: 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/vis\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/vis/test_sample_000.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/vis/test_sample_001.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/vis/test_sample_002.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convrnn_dec_convrnn_20251211-224107/metrics/vis/test_sample_003.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### convlstm+unet"
      ],
      "metadata": {
        "id": "8BNo5KamlGtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_c11 = ds_train.mean   # (1,C,1,1)\n",
        "std_c11  = ds_train.std    # (1,C,1,1)\n",
        "\n",
        "convlstm_unet_cfg = TrainConfig(\n",
        "    batch_size=batch_size,\n",
        "    lr=1e-4,\n",
        "    max_epochs=50,\n",
        "    enc_cell_type=\"convlstm\",\n",
        "    dec_cell_type=\"convlstm\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=True,\n",
        "    unet_head=True,\n",
        "    out_root=\"./6hr_runs_w_unet\",\n",
        "    viz_every_n_epochs=10,\n",
        "    viz_use_last_t=True,\n",
        "    viz_channel=None,\n",
        "    save_all_channels_png=True,\n",
        ")\n",
        "\n",
        "convlstm_unet_model, convlstm_unet_history = train(convlstm_unet_cfg, train_loader, val_loader, mean_c11, std_c11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ae8YJQu-2kAy",
        "outputId": "b2c1c824-f7b7-4306-90d1-7cc78aca1f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] TF=1.00 | train MSE=0.227249 RMSE=0.476707 MAE=0.274590 | val MSE=0.286049 RMSE=0.534835 MAE=0.298742\n",
            "  >> Saved best model (val MSE=0.286049)\n",
            "[Epoch 2/50] TF=1.00 | train MSE=0.119544 RMSE=0.345751 MAE=0.195258 | val MSE=0.248512 RMSE=0.498510 MAE=0.272848\n",
            "  >> Saved best model (val MSE=0.248512)\n",
            "[Epoch 3/50] TF=1.00 | train MSE=0.108063 RMSE=0.328729 MAE=0.183283 | val MSE=0.234223 RMSE=0.483966 MAE=0.264053\n",
            "  >> Saved best model (val MSE=0.234223)\n",
            "[Epoch 4/50] TF=1.00 | train MSE=0.100857 RMSE=0.317580 MAE=0.175436 | val MSE=0.224128 RMSE=0.473421 MAE=0.260847\n",
            "  >> Saved best model (val MSE=0.224128)\n",
            "[Epoch 5/50] TF=1.00 | train MSE=0.095586 RMSE=0.309171 MAE=0.169130 | val MSE=0.221233 RMSE=0.470354 MAE=0.250080\n",
            "  >> Saved best model (val MSE=0.221233)\n",
            "[Epoch 6/50] TF=1.00 | train MSE=0.090663 RMSE=0.301104 MAE=0.162876 | val MSE=0.209751 RMSE=0.457986 MAE=0.239560\n",
            "  >> Saved best model (val MSE=0.209751)\n",
            "[Epoch 7/50] TF=1.00 | train MSE=0.087529 RMSE=0.295853 MAE=0.159134 | val MSE=0.222206 RMSE=0.471388 MAE=0.254523\n",
            "[Epoch 8/50] TF=1.00 | train MSE=0.085057 RMSE=0.291646 MAE=0.155981 | val MSE=0.197641 RMSE=0.444569 MAE=0.232610\n",
            "  >> Saved best model (val MSE=0.197641)\n",
            "[Epoch 9/50] TF=1.00 | train MSE=0.083050 RMSE=0.288184 MAE=0.153561 | val MSE=0.204811 RMSE=0.452561 MAE=0.242920\n",
            "[Epoch 10/50] TF=1.00 | train MSE=0.081153 RMSE=0.284873 MAE=0.151066 | val MSE=0.225240 RMSE=0.474595 MAE=0.249253\n",
            "[Epoch 11/50] TF=1.00 | train MSE=0.079342 RMSE=0.281678 MAE=0.148638 | val MSE=0.185732 RMSE=0.430967 MAE=0.223990\n",
            "  >> Saved best model (val MSE=0.185732)\n",
            "[Epoch 12/50] TF=1.00 | train MSE=0.077976 RMSE=0.279242 MAE=0.146902 | val MSE=0.183667 RMSE=0.428563 MAE=0.226847\n",
            "  >> Saved best model (val MSE=0.183667)\n",
            "[Epoch 13/50] TF=1.00 | train MSE=0.076793 RMSE=0.277115 MAE=0.145377 | val MSE=0.181427 RMSE=0.425943 MAE=0.223167\n",
            "  >> Saved best model (val MSE=0.181427)\n",
            "[Epoch 14/50] TF=1.00 | train MSE=0.075776 RMSE=0.275274 MAE=0.144134 | val MSE=0.191984 RMSE=0.438160 MAE=0.226521\n",
            "[Epoch 15/50] TF=1.00 | train MSE=0.074931 RMSE=0.273736 MAE=0.143018 | val MSE=0.189826 RMSE=0.435691 MAE=0.225405\n",
            "[Epoch 16/50] TF=1.00 | train MSE=0.074158 RMSE=0.272320 MAE=0.141999 | val MSE=0.179939 RMSE=0.424192 MAE=0.217616\n",
            "  >> Saved best model (val MSE=0.179939)\n",
            "[Epoch 17/50] TF=1.00 | train MSE=0.072932 RMSE=0.270060 MAE=0.140225 | val MSE=0.191901 RMSE=0.438065 MAE=0.235316\n",
            "[Epoch 18/50] TF=1.00 | train MSE=0.072713 RMSE=0.269653 MAE=0.140061 | val MSE=0.175472 RMSE=0.418893 MAE=0.217829\n",
            "  >> Saved best model (val MSE=0.175472)\n",
            "[Epoch 19/50] TF=1.00 | train MSE=0.071505 RMSE=0.267404 MAE=0.138284 | val MSE=0.185787 RMSE=0.431030 MAE=0.222568\n",
            "[Epoch 20/50] TF=1.00 | train MSE=0.071295 RMSE=0.267010 MAE=0.138097 | val MSE=0.173568 RMSE=0.416615 MAE=0.211294\n",
            "  >> Saved best model (val MSE=0.173568)\n",
            "[Epoch 21/50] TF=1.00 | train MSE=0.070627 RMSE=0.265758 MAE=0.137033 | val MSE=0.171947 RMSE=0.414665 MAE=0.210099\n",
            "  >> Saved best model (val MSE=0.171947)\n",
            "[Epoch 22/50] TF=1.00 | train MSE=0.070310 RMSE=0.265161 MAE=0.136862 | val MSE=0.174884 RMSE=0.418191 MAE=0.217223\n",
            "[Epoch 23/50] TF=1.00 | train MSE=0.069133 RMSE=0.262931 MAE=0.134964 | val MSE=0.170921 RMSE=0.413426 MAE=0.211307\n",
            "  >> Saved best model (val MSE=0.170921)\n",
            "[Epoch 24/50] TF=1.00 | train MSE=0.068764 RMSE=0.262228 MAE=0.134556 | val MSE=0.168869 RMSE=0.410937 MAE=0.207940\n",
            "  >> Saved best model (val MSE=0.168869)\n",
            "[Epoch 25/50] TF=1.00 | train MSE=0.068407 RMSE=0.261548 MAE=0.134075 | val MSE=0.169205 RMSE=0.411345 MAE=0.209407\n",
            "[Epoch 26/50] TF=1.00 | train MSE=0.067936 RMSE=0.260646 MAE=0.133392 | val MSE=0.166636 RMSE=0.408211 MAE=0.208819\n",
            "  >> Saved best model (val MSE=0.166636)\n",
            "[Epoch 27/50] TF=1.00 | train MSE=0.067331 RMSE=0.259481 MAE=0.132500 | val MSE=0.171704 RMSE=0.414372 MAE=0.213196\n",
            "[Epoch 28/50] TF=1.00 | train MSE=0.067174 RMSE=0.259180 MAE=0.132308 | val MSE=0.167884 RMSE=0.409737 MAE=0.207326\n",
            "[Epoch 29/50] TF=1.00 | train MSE=0.067230 RMSE=0.259288 MAE=0.132493 | val MSE=0.186300 RMSE=0.431625 MAE=0.220119\n",
            "[Epoch 30/50] TF=1.00 | train MSE=0.066464 RMSE=0.257806 MAE=0.131442 | val MSE=0.165070 RMSE=0.406289 MAE=0.208809\n",
            "  >> Saved best model (val MSE=0.165070)\n",
            "[Epoch 31/50] TF=1.00 | train MSE=0.066164 RMSE=0.257223 MAE=0.130932 | val MSE=0.168553 RMSE=0.410552 MAE=0.208586\n",
            "[Epoch 32/50] TF=1.00 | train MSE=0.065756 RMSE=0.256430 MAE=0.130374 | val MSE=0.171983 RMSE=0.414708 MAE=0.213001\n",
            "[Epoch 33/50] TF=1.00 | train MSE=0.065459 RMSE=0.255849 MAE=0.129938 | val MSE=0.168563 RMSE=0.410564 MAE=0.208556\n",
            "[Epoch 34/50] TF=1.00 | train MSE=0.065306 RMSE=0.255550 MAE=0.129775 | val MSE=0.163864 RMSE=0.404801 MAE=0.204306\n",
            "  >> Saved best model (val MSE=0.163864)\n",
            "[Epoch 35/50] TF=1.00 | train MSE=0.065437 RMSE=0.255807 MAE=0.130106 | val MSE=0.161656 RMSE=0.402064 MAE=0.200763\n",
            "  >> Saved best model (val MSE=0.161656)\n",
            "[Epoch 36/50] TF=1.00 | train MSE=0.064826 RMSE=0.254610 MAE=0.129092 | val MSE=0.159223 RMSE=0.399027 MAE=0.199495\n",
            "  >> Saved best model (val MSE=0.159223)\n",
            "[Epoch 37/50] TF=1.00 | train MSE=0.064872 RMSE=0.254700 MAE=0.129266 | val MSE=0.166273 RMSE=0.407765 MAE=0.209231\n",
            "[Epoch 38/50] TF=1.00 | train MSE=0.064576 RMSE=0.254117 MAE=0.129088 | val MSE=0.164942 RMSE=0.406130 MAE=0.203451\n",
            "[Epoch 39/50] TF=1.00 | train MSE=0.063841 RMSE=0.252667 MAE=0.127777 | val MSE=0.164074 RMSE=0.405061 MAE=0.203105\n",
            "[Epoch 40/50] TF=1.00 | train MSE=0.063877 RMSE=0.252738 MAE=0.127842 | val MSE=0.160388 RMSE=0.400485 MAE=0.199321\n",
            "[Epoch 41/50] TF=1.00 | train MSE=0.063576 RMSE=0.252142 MAE=0.127430 | val MSE=0.161860 RMSE=0.402318 MAE=0.202193\n",
            "[Epoch 42/50] TF=1.00 | train MSE=0.063803 RMSE=0.252592 MAE=0.127914 | val MSE=0.161944 RMSE=0.402422 MAE=0.201227\n",
            "[Epoch 43/50] TF=1.00 | train MSE=0.062988 RMSE=0.250974 MAE=0.126680 | val MSE=0.160131 RMSE=0.400163 MAE=0.201826\n",
            "[Epoch 44/50] TF=1.00 | train MSE=0.063362 RMSE=0.251718 MAE=0.127394 | val MSE=0.159287 RMSE=0.399107 MAE=0.201654\n",
            "[Epoch 45/50] TF=1.00 | train MSE=0.062658 RMSE=0.250315 MAE=0.126173 | val MSE=0.170415 RMSE=0.412814 MAE=0.209498\n",
            "[Epoch 46/50] TF=1.00 | train MSE=0.062543 RMSE=0.250086 MAE=0.126121 | val MSE=0.162218 RMSE=0.402763 MAE=0.205494\n",
            "[Epoch 47/50] TF=1.00 | train MSE=0.062413 RMSE=0.249827 MAE=0.125903 | val MSE=0.160078 RMSE=0.400098 MAE=0.202925\n",
            "[Epoch 48/50] TF=1.00 | train MSE=0.062547 RMSE=0.250093 MAE=0.126311 | val MSE=0.163265 RMSE=0.404061 MAE=0.201205\n",
            "[Epoch 49/50] TF=1.00 | train MSE=0.062152 RMSE=0.249303 MAE=0.125597 | val MSE=0.189148 RMSE=0.434911 MAE=0.228095\n",
            "[Epoch 50/50] TF=1.00 | train MSE=0.062266 RMSE=0.249531 MAE=0.126059 | val MSE=0.161042 RMSE=0.401301 MAE=0.200647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds_test_lead = ERA5XYDataset6h(\n",
        "    np_test,\n",
        "    variables,\n",
        "    x_len=8,\n",
        "    y_len=8,\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        "    mean=ds_train.mean,\n",
        "    std=ds_train.std,\n",
        "    precip_to_mm=True,\n",
        "    precip_log1p=True,\n",
        ")\n",
        "\n",
        "test_loader_lead = DataLoader(ds_test_lead, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "ckpt_path = \"./6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/checkpoints/best.pt\"\n",
        "\n",
        "model, metrics_all, per_var_lead = evaluate_checkpoint_and_save_all_metrics(\n",
        "    ds_train=ds_train,\n",
        "    test_loader=test_loader,\n",
        "    variables=variables,\n",
        "    ckpt_path=ckpt_path,\n",
        "    test_loader_lead=test_loader_lead,\n",
        "    time_step_hours=6,\n",
        "    max_lead_hours=48,\n",
        "    precip_var_name=\"total_precipitation_6hr\",  # precip variable name\n",
        "    precip_is_log1p_mm=True,\n",
        "    show_plots=True,\n",
        "    num_vis_samples=4,\n",
        "    viz_use_last_t=True,\n",
        "    viz_channel=None,\n",
        "    viz_all_channels=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rQhDcG2K4MR",
        "outputId": "f6dc9173-e895-4093-f203-e9ea41605e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] metrics will be saved to: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics\n",
            "mean_c11: torch.Size([1, 5, 1, 1]) std_c11: torch.Size([1, 5, 1, 1])\n",
            "[INFO] inferred C from mean/std: C=5\n",
            "[INFO] Loaded checkpoint: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/checkpoints/best.pt\n",
            "[INFO] Loaded config from: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/config.json\n",
            "[INFO] Precipitation variable: 'total_precipitation_6hr' at index 4\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 2m_temperature (idx=0)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [3.3467786 3.442735  3.6127858 3.8097866 4.1958666 4.5095086 4.7991867\n",
            " 5.1101294]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_2m_temperature_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_2m_temperature_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 10m_u_component_of_wind (idx=1)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.0547565 1.512449  1.934912  2.3252294 2.7312298 3.1083386 3.4573374\n",
            " 3.7897725]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_10m_u_component_of_wind_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_10m_u_component_of_wind_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 10m_v_component_of_wind (idx=2)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.090381  1.5648178 2.0026548 2.406306  2.81299   3.1720378 3.4898715\n",
            " 3.7669432]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_10m_v_component_of_wind_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_10m_v_component_of_wind_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: mean_sea_level_pressure (idx=3)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [ 928.00726  967.5918  1081.0713  1133.9309  1231.7576  1276.8401\n",
            " 1250.5308  1176.5728 ]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_mean_sea_level_pressure_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_mean_sea_level_pressure_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: total_precipitation_6hr (idx=4)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.1096648 1.400648  1.5857689 1.70417   1.8007529 1.8773936 1.9388745\n",
            " 1.9907181]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_total_precipitation_6hr_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/lead_rmse_total_precipitation_6hr_up_to_48h.png\n",
            "\n",
            "[Global metrics per variable on test set]\n",
            "2m_temperature                 (K)         | RMSE=3.553  MAE=2.701  ACC=0.9999  RMSB=0.1373\n",
            "10m_u_component_of_wind        (m/s)       | RMSE=1.707  MAE=1.224  ACC=0.9466  RMSB=0.02416\n",
            "10m_v_component_of_wind        (m/s)       | RMSE=1.766  MAE=1.269  ACC=0.9127  RMSB=0.02647\n",
            "mean_sea_level_pressure        (Pa)        | RMSE=1028  MAE=825.5  ACC=1.0000  RMSB=47.12\n",
            "total_precipitation_6hr        (mm/6h)     | RMSE=1.45  MAE=0.4803  ACC=0.7315  RMSB=0.01862\n",
            "\n",
            "[INFO] Saved global metrics to: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/global_metrics_all_vars.npz\n",
            "[INFO] Saving visualization samples to: 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/vis\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/vis/test_sample_000.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/vis/test_sample_001.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/vis/test_sample_002.png\n",
            "  [vis] saved 6hr_runs_w_unet/enc_convlstm_dec_convlstm_20251211-235905/metrics/vis/test_sample_003.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### convlstm"
      ],
      "metadata": {
        "id": "29Mhh7lULBnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean_c11 = ds_train.mean   # (1,C,1,1)\n",
        "std_c11  = ds_train.std    # (1,C,1,1)\n",
        "\n",
        "convlstm_cfg = TrainConfig(\n",
        "    batch_size=batch_size,\n",
        "    lr=1e-4,\n",
        "    max_epochs=50,\n",
        "    enc_cell_type=\"convlstm\",\n",
        "    dec_cell_type=\"convlstm\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=True,\n",
        "    unet_head=True,\n",
        "    out_root=\"./6hr_runs_wo_unet\",\n",
        "    viz_every_n_epochs=10,\n",
        "    viz_use_last_t=True,\n",
        "    viz_channel=None,\n",
        "    save_all_channels_png=True,\n",
        ")\n",
        "\n",
        "convlstm_model, convlstm_history = train(convlstm_cfg, train_loader, val_loader, mean_c11, std_c11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "djXRnSh2LNK3",
        "outputId": "85e2c8b0-77f4-44c5-883c-4bdf51d86172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] TF=1.00 | train MSE=0.228475 RMSE=0.477990 MAE=0.281111 | val MSE=0.314984 RMSE=0.561235 MAE=0.324257\n",
            "  >> Saved best model (val MSE=0.314984)\n",
            "[Epoch 2/50] TF=1.00 | train MSE=0.117849 RMSE=0.343292 MAE=0.194564 | val MSE=0.256682 RMSE=0.506638 MAE=0.276039\n",
            "  >> Saved best model (val MSE=0.256682)\n",
            "[Epoch 3/50] TF=1.00 | train MSE=0.105678 RMSE=0.325082 MAE=0.181489 | val MSE=0.224008 RMSE=0.473295 MAE=0.257198\n",
            "  >> Saved best model (val MSE=0.224008)\n",
            "[Epoch 4/50] TF=1.00 | train MSE=0.098340 RMSE=0.313591 MAE=0.172938 | val MSE=0.235235 RMSE=0.485010 MAE=0.265437\n",
            "[Epoch 5/50] TF=1.00 | train MSE=0.093363 RMSE=0.305553 MAE=0.167033 | val MSE=0.212260 RMSE=0.460717 MAE=0.243675\n",
            "  >> Saved best model (val MSE=0.212260)\n",
            "[Epoch 6/50] TF=1.00 | train MSE=0.089316 RMSE=0.298858 MAE=0.161940 | val MSE=0.205542 RMSE=0.453367 MAE=0.238440\n",
            "  >> Saved best model (val MSE=0.205542)\n",
            "[Epoch 7/50] TF=1.00 | train MSE=0.086304 RMSE=0.293775 MAE=0.158283 | val MSE=0.204193 RMSE=0.451877 MAE=0.236046\n",
            "  >> Saved best model (val MSE=0.204193)\n",
            "[Epoch 8/50] TF=1.00 | train MSE=0.083950 RMSE=0.289741 MAE=0.155183 | val MSE=0.210889 RMSE=0.459226 MAE=0.243560\n",
            "[Epoch 9/50] TF=1.00 | train MSE=0.081922 RMSE=0.286220 MAE=0.152546 | val MSE=0.194385 RMSE=0.440891 MAE=0.230980\n",
            "  >> Saved best model (val MSE=0.194385)\n",
            "[Epoch 10/50] TF=1.00 | train MSE=0.080310 RMSE=0.283390 MAE=0.150462 | val MSE=0.194329 RMSE=0.440828 MAE=0.230872\n",
            "  >> Saved best model (val MSE=0.194329)\n",
            "[Epoch 11/50] TF=1.00 | train MSE=0.079024 RMSE=0.281111 MAE=0.148680 | val MSE=0.185248 RMSE=0.430405 MAE=0.227094\n",
            "  >> Saved best model (val MSE=0.185248)\n",
            "[Epoch 12/50] TF=1.00 | train MSE=0.077476 RMSE=0.278344 MAE=0.146553 | val MSE=0.184385 RMSE=0.429401 MAE=0.221786\n",
            "  >> Saved best model (val MSE=0.184385)\n",
            "[Epoch 13/50] TF=1.00 | train MSE=0.076545 RMSE=0.276668 MAE=0.145334 | val MSE=0.182002 RMSE=0.426617 MAE=0.220575\n",
            "  >> Saved best model (val MSE=0.182002)\n",
            "[Epoch 14/50] TF=1.00 | train MSE=0.075648 RMSE=0.275041 MAE=0.144156 | val MSE=0.185328 RMSE=0.430498 MAE=0.219871\n",
            "[Epoch 15/50] TF=1.00 | train MSE=0.074673 RMSE=0.273264 MAE=0.142748 | val MSE=0.177247 RMSE=0.421007 MAE=0.215414\n",
            "  >> Saved best model (val MSE=0.177247)\n",
            "[Epoch 16/50] TF=1.00 | train MSE=0.074387 RMSE=0.272739 MAE=0.142490 | val MSE=0.186897 RMSE=0.432316 MAE=0.222215\n",
            "[Epoch 17/50] TF=1.00 | train MSE=0.073238 RMSE=0.270625 MAE=0.140792 | val MSE=0.175351 RMSE=0.418750 MAE=0.212933\n",
            "  >> Saved best model (val MSE=0.175351)\n",
            "[Epoch 18/50] TF=1.00 | train MSE=0.072254 RMSE=0.268800 MAE=0.139339 | val MSE=0.184298 RMSE=0.429300 MAE=0.220060\n",
            "[Epoch 19/50] TF=1.00 | train MSE=0.071414 RMSE=0.267233 MAE=0.138162 | val MSE=0.171731 RMSE=0.414404 MAE=0.214507\n",
            "  >> Saved best model (val MSE=0.171731)\n",
            "[Epoch 20/50] TF=1.00 | train MSE=0.071174 RMSE=0.266785 MAE=0.137921 | val MSE=0.172704 RMSE=0.415577 MAE=0.212557\n",
            "[Epoch 21/50] TF=1.00 | train MSE=0.070419 RMSE=0.265366 MAE=0.136810 | val MSE=0.172874 RMSE=0.415782 MAE=0.210235\n",
            "[Epoch 22/50] TF=1.00 | train MSE=0.070175 RMSE=0.264905 MAE=0.136573 | val MSE=0.169065 RMSE=0.411176 MAE=0.209089\n",
            "  >> Saved best model (val MSE=0.169065)\n",
            "[Epoch 23/50] TF=1.00 | train MSE=0.069503 RMSE=0.263634 MAE=0.135552 | val MSE=0.173138 RMSE=0.416098 MAE=0.212539\n",
            "[Epoch 24/50] TF=1.00 | train MSE=0.068953 RMSE=0.262588 MAE=0.134763 | val MSE=0.175472 RMSE=0.418894 MAE=0.214448\n",
            "[Epoch 25/50] TF=1.00 | train MSE=0.068558 RMSE=0.261835 MAE=0.134245 | val MSE=0.175301 RMSE=0.418690 MAE=0.211151\n",
            "[Epoch 26/50] TF=1.00 | train MSE=0.068449 RMSE=0.261628 MAE=0.134188 | val MSE=0.166871 RMSE=0.408498 MAE=0.208603\n",
            "  >> Saved best model (val MSE=0.166871)\n",
            "[Epoch 27/50] TF=1.00 | train MSE=0.067832 RMSE=0.260446 MAE=0.133193 | val MSE=0.163967 RMSE=0.404928 MAE=0.203938\n",
            "  >> Saved best model (val MSE=0.163967)\n",
            "[Epoch 28/50] TF=1.00 | train MSE=0.067451 RMSE=0.259712 MAE=0.132687 | val MSE=0.167156 RMSE=0.408848 MAE=0.205648\n",
            "[Epoch 29/50] TF=1.00 | train MSE=0.067187 RMSE=0.259204 MAE=0.132309 | val MSE=0.164263 RMSE=0.405294 MAE=0.202773\n",
            "[Epoch 30/50] TF=1.00 | train MSE=0.066982 RMSE=0.258810 MAE=0.132138 | val MSE=0.165316 RMSE=0.406590 MAE=0.203714\n",
            "[Epoch 31/50] TF=1.00 | train MSE=0.066359 RMSE=0.257602 MAE=0.131198 | val MSE=0.172821 RMSE=0.415718 MAE=0.208531\n",
            "[Epoch 32/50] TF=1.00 | train MSE=0.066473 RMSE=0.257823 MAE=0.131456 | val MSE=0.163543 RMSE=0.404405 MAE=0.202746\n",
            "  >> Saved best model (val MSE=0.163543)\n",
            "[Epoch 33/50] TF=1.00 | train MSE=0.065621 RMSE=0.256166 MAE=0.130189 | val MSE=0.164935 RMSE=0.406122 MAE=0.202817\n",
            "[Epoch 34/50] TF=1.00 | train MSE=0.065633 RMSE=0.256188 MAE=0.130286 | val MSE=0.165330 RMSE=0.406608 MAE=0.206090\n",
            "[Epoch 35/50] TF=1.00 | train MSE=0.065072 RMSE=0.255092 MAE=0.129398 | val MSE=0.163697 RMSE=0.404595 MAE=0.202912\n",
            "[Epoch 36/50] TF=1.00 | train MSE=0.065116 RMSE=0.255178 MAE=0.129575 | val MSE=0.170237 RMSE=0.412598 MAE=0.209751\n",
            "[Epoch 37/50] TF=1.00 | train MSE=0.064668 RMSE=0.254298 MAE=0.128946 | val MSE=0.165013 RMSE=0.406217 MAE=0.203614\n",
            "[Epoch 38/50] TF=1.00 | train MSE=0.064754 RMSE=0.254468 MAE=0.129131 | val MSE=0.164049 RMSE=0.405030 MAE=0.203194\n",
            "[Epoch 39/50] TF=1.00 | train MSE=0.064155 RMSE=0.253288 MAE=0.128178 | val MSE=0.167269 RMSE=0.408986 MAE=0.205072\n",
            "[Epoch 40/50] TF=1.00 | train MSE=0.063837 RMSE=0.252660 MAE=0.127776 | val MSE=0.159264 RMSE=0.399079 MAE=0.199615\n",
            "  >> Saved best model (val MSE=0.159264)\n",
            "[Epoch 41/50] TF=1.00 | train MSE=0.063872 RMSE=0.252728 MAE=0.127905 | val MSE=0.159588 RMSE=0.399484 MAE=0.198052\n",
            "[Epoch 42/50] TF=1.00 | train MSE=0.063840 RMSE=0.252666 MAE=0.127986 | val MSE=0.164474 RMSE=0.405554 MAE=0.202082\n",
            "[Epoch 43/50] TF=1.00 | train MSE=0.063167 RMSE=0.251330 MAE=0.126843 | val MSE=0.166870 RMSE=0.408497 MAE=0.202853\n",
            "[Epoch 44/50] TF=1.00 | train MSE=0.063126 RMSE=0.251248 MAE=0.126849 | val MSE=0.158621 RMSE=0.398272 MAE=0.200232\n",
            "  >> Saved best model (val MSE=0.158621)\n",
            "[Epoch 45/50] TF=1.00 | train MSE=0.063316 RMSE=0.251627 MAE=0.127271 | val MSE=0.157804 RMSE=0.397245 MAE=0.197188\n",
            "  >> Saved best model (val MSE=0.157804)\n",
            "[Epoch 46/50] TF=1.00 | train MSE=0.063212 RMSE=0.251420 MAE=0.127110 | val MSE=0.158305 RMSE=0.397876 MAE=0.197542\n",
            "[Epoch 47/50] TF=1.00 | train MSE=0.062754 RMSE=0.250507 MAE=0.126382 | val MSE=0.162463 RMSE=0.403067 MAE=0.200314\n",
            "[Epoch 48/50] TF=1.00 | train MSE=0.062261 RMSE=0.249521 MAE=0.125689 | val MSE=0.167510 RMSE=0.409279 MAE=0.204609\n",
            "[Epoch 49/50] TF=1.00 | train MSE=0.062349 RMSE=0.249698 MAE=0.125842 | val MSE=0.161673 RMSE=0.402086 MAE=0.203288\n",
            "[Epoch 50/50] TF=1.00 | train MSE=0.061968 RMSE=0.248933 MAE=0.125308 | val MSE=0.163741 RMSE=0.404649 MAE=0.203285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds_test_lead = ERA5XYDataset6h(\n",
        "    np_test,\n",
        "    variables,\n",
        "    x_len=8,\n",
        "    y_len=8,   # ← 48h lead\n",
        "    stride=1,\n",
        "    normalize=True,\n",
        "    mean=ds_train.mean,\n",
        "    std=ds_train.std,\n",
        "    precip_to_mm=True,\n",
        "    precip_log1p=True,\n",
        ")\n",
        "\n",
        "test_loader_lead = DataLoader(ds_test_lead, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "ckpt_path = \"./6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/checkpoints/best.pt\"\n",
        "\n",
        "model, metrics_all, per_var_lead = evaluate_checkpoint_and_save_all_metrics(\n",
        "    ds_train=ds_train,\n",
        "    test_loader=test_loader,\n",
        "    variables=variables,\n",
        "    ckpt_path=ckpt_path,\n",
        "    test_loader_lead=test_loader_lead,\n",
        "    time_step_hours=6,\n",
        "    max_lead_hours=48,\n",
        "    precip_var_name=\"total_precipitation_6hr\",\n",
        "    precip_is_log1p_mm=True,\n",
        "    show_plots=True,\n",
        "    num_vis_samples=4,\n",
        "    viz_use_last_t=True,\n",
        "    viz_channel=None,\n",
        "    viz_all_channels=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzcPTlG-e1Mq",
        "outputId": "ba429629-ac6f-43b2-c261-e603285df2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] metrics will be saved to: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics\n",
            "mean_c11: torch.Size([1, 5, 1, 1]) std_c11: torch.Size([1, 5, 1, 1])\n",
            "[INFO] inferred C from mean/std: C=5\n",
            "[INFO] Loaded checkpoint: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/checkpoints/best.pt\n",
            "[INFO] Loaded config from: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/config.json\n",
            "[INFO] Precipitation variable: 'total_precipitation_6hr' at index 4\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 2m_temperature (idx=0)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [3.039699  3.5818639 4.0992017 4.5291452 5.1147766 5.53357   6.025065\n",
            " 6.653648 ]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_2m_temperature_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_2m_temperature_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 10m_u_component_of_wind (idx=1)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.0422187 1.4867581 1.9037912 2.2894049 2.680662  3.0236673 3.3258052\n",
            " 3.5807621]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_10m_u_component_of_wind_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_10m_u_component_of_wind_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: 10m_v_component_of_wind (idx=2)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.0763065 1.538483  1.9722867 2.3785753 2.785146  3.1443758 3.4602652\n",
            " 3.7302203]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_10m_v_component_of_wind_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_10m_v_component_of_wind_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: mean_sea_level_pressure (idx=3)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [901.1984  887.1598  916.4424  915.88965 936.9927  949.67706 973.29395\n",
            " 995.94135]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_mean_sea_level_pressure_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_mean_sea_level_pressure_up_to_48h.png\n",
            "\n",
            "[Lead RMSE] Evaluating variable: total_precipitation_6hr (idx=4)\n",
            "  lead_hours: [ 6 12 18 24 30 36 42 48]\n",
            "  rmse_lead: [1.1063603 1.3996186 1.5849006 1.6992997 1.7956837 1.8779563 1.9451723\n",
            " 2.0032804]\n",
            "[INFO] Saved lead RMSE curve to: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_total_precipitation_6hr_up_to_48h.npz\n",
            "  [saved figure] 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/lead_rmse_total_precipitation_6hr_up_to_48h.png\n",
            "\n",
            "[Global metrics per variable on test set]\n",
            "2m_temperature                 (K)         | RMSE=3.813  MAE=2.97  ACC=0.9999  RMSB=0.2035\n",
            "10m_u_component_of_wind        (m/s)       | RMSE=1.68  MAE=1.2  ACC=0.9483  RMSB=0.02224\n",
            "10m_v_component_of_wind        (m/s)       | RMSE=1.741  MAE=1.247  ACC=0.9155  RMSB=0.02513\n",
            "mean_sea_level_pressure        (Pa)        | RMSE=905.4  MAE=694  ACC=1.0000  RMSB=32.49\n",
            "total_precipitation_6hr        (mm/6h)     | RMSE=1.447  MAE=0.4739  ACC=0.7329  RMSB=0.01874\n",
            "\n",
            "[INFO] Saved global metrics to: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/global_metrics_all_vars.npz\n",
            "[INFO] Saving visualization samples to: 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/vis\n",
            "  [vis] saved 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/vis/test_sample_000.png\n",
            "  [vis] saved 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/vis/test_sample_001.png\n",
            "  [vis] saved 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/vis/test_sample_002.png\n",
            "  [vis] saved 6hr_runs_wo_unet/enc_convlstm_dec_convlstm_20251212-013104/metrics/vis/test_sample_003.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dummy"
      ],
      "metadata": {
        "id": "GBwOAd2pc-E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convgru_unet_cfg = TrainConfig(\n",
        "    data_dir=\"./\",\n",
        "    max_epochs=100,\n",
        "    batch_size=2,\n",
        "    enc_cell_type=\"convgru\",\n",
        "    dec_cell_type=\"convgru\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=False,\n",
        "    unet_head=True,\n",
        "    out_root=\"./runs_w_unet\",\n",
        "    viz_every_n_epochs=10,     # 每 10 个 epoch 可视化一次（train+eval）\n",
        "    viz_use_last_t=True,       # 可切换 False 以随机时间步\n",
        "    viz_channel=None,          # None=随机通道；也可设 0/1/2...\n",
        "    save_all_channels_png=True\n",
        ")\n",
        "convgru_unet_model, convgru_unet_history = train(convgru_unet_cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA7nR02rGHJe",
        "outputId": "ce0e9d0c-e481-4671-dfae-f411fda42f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据集总数: 119 | 训练集: 95 | 验证集: 24\n",
            "[Epoch 1/100] TF=1.00 | train MSE=0.175221 RMSE=0.418595 MAE=0.273519 | val MSE=0.305383 RMSE=0.552615 MAE=0.358018\n",
            "  >> Saved best model (val MSE=0.305383)\n",
            "[Epoch 2/100] TF=1.00 | train MSE=0.046581 RMSE=0.215827 MAE=0.146971 | val MSE=0.306194 RMSE=0.553348 MAE=0.352155\n",
            "[Epoch 3/100] TF=1.00 | train MSE=0.035252 RMSE=0.187756 MAE=0.126996 | val MSE=0.247547 RMSE=0.497541 MAE=0.321898\n",
            "  >> Saved best model (val MSE=0.247547)\n",
            "[Epoch 4/100] TF=1.00 | train MSE=0.030717 RMSE=0.175263 MAE=0.118487 | val MSE=0.289808 RMSE=0.538338 MAE=0.342817\n",
            "[Epoch 5/100] TF=1.00 | train MSE=0.028681 RMSE=0.169354 MAE=0.114073 | val MSE=0.255584 RMSE=0.505553 MAE=0.320323\n",
            "[Epoch 6/100] TF=1.00 | train MSE=0.026178 RMSE=0.161796 MAE=0.107988 | val MSE=0.202908 RMSE=0.450453 MAE=0.283811\n",
            "  >> Saved best model (val MSE=0.202908)\n",
            "[Epoch 7/100] TF=1.00 | train MSE=0.024642 RMSE=0.156978 MAE=0.104406 | val MSE=0.193176 RMSE=0.439518 MAE=0.277407\n",
            "  >> Saved best model (val MSE=0.193176)\n",
            "[Epoch 8/100] TF=1.00 | train MSE=0.023706 RMSE=0.153969 MAE=0.102080 | val MSE=0.283989 RMSE=0.532906 MAE=0.326934\n",
            "[Epoch 9/100] TF=1.00 | train MSE=0.023626 RMSE=0.153707 MAE=0.102314 | val MSE=0.189875 RMSE=0.435746 MAE=0.273353\n",
            "  >> Saved best model (val MSE=0.189875)\n",
            "[Epoch 10/100] TF=1.00 | train MSE=0.021922 RMSE=0.148059 MAE=0.097712 | val MSE=0.176559 RMSE=0.420190 MAE=0.273730\n",
            "  >> Saved best model (val MSE=0.176559)\n",
            "[Epoch 11/100] TF=1.00 | train MSE=0.021753 RMSE=0.147487 MAE=0.097812 | val MSE=0.199713 RMSE=0.446893 MAE=0.285324\n",
            "[Epoch 12/100] TF=1.00 | train MSE=0.021002 RMSE=0.144921 MAE=0.095855 | val MSE=0.220708 RMSE=0.469796 MAE=0.296742\n",
            "[Epoch 13/100] TF=1.00 | train MSE=0.020551 RMSE=0.143355 MAE=0.094717 | val MSE=0.166586 RMSE=0.408150 MAE=0.259938\n",
            "  >> Saved best model (val MSE=0.166586)\n",
            "[Epoch 14/100] TF=1.00 | train MSE=0.020033 RMSE=0.141537 MAE=0.092858 | val MSE=0.223873 RMSE=0.473152 MAE=0.301873\n",
            "[Epoch 15/100] TF=1.00 | train MSE=0.019820 RMSE=0.140785 MAE=0.093057 | val MSE=0.195851 RMSE=0.442550 MAE=0.265235\n",
            "[Epoch 16/100] TF=1.00 | train MSE=0.019324 RMSE=0.139012 MAE=0.091580 | val MSE=0.206046 RMSE=0.453922 MAE=0.299219\n",
            "[Epoch 17/100] TF=1.00 | train MSE=0.018949 RMSE=0.137656 MAE=0.090632 | val MSE=0.211828 RMSE=0.460247 MAE=0.295251\n",
            "[Epoch 18/100] TF=1.00 | train MSE=0.018387 RMSE=0.135598 MAE=0.088390 | val MSE=0.143953 RMSE=0.379412 MAE=0.235901\n",
            "  >> Saved best model (val MSE=0.143953)\n",
            "[Epoch 19/100] TF=1.00 | train MSE=0.017699 RMSE=0.133036 MAE=0.085913 | val MSE=0.152612 RMSE=0.390656 MAE=0.242396\n",
            "[Epoch 20/100] TF=1.00 | train MSE=0.018054 RMSE=0.134364 MAE=0.087429 | val MSE=0.141879 RMSE=0.376668 MAE=0.229843\n",
            "  >> Saved best model (val MSE=0.141879)\n",
            "[Epoch 21/100] TF=1.00 | train MSE=0.017672 RMSE=0.132936 MAE=0.087219 | val MSE=0.194808 RMSE=0.441371 MAE=0.283264\n",
            "[Epoch 22/100] TF=1.00 | train MSE=0.017258 RMSE=0.131370 MAE=0.085559 | val MSE=0.156002 RMSE=0.394971 MAE=0.239289\n",
            "[Epoch 23/100] TF=1.00 | train MSE=0.016882 RMSE=0.129933 MAE=0.084063 | val MSE=0.147033 RMSE=0.383448 MAE=0.233074\n",
            "[Epoch 24/100] TF=1.00 | train MSE=0.016507 RMSE=0.128479 MAE=0.082836 | val MSE=0.136967 RMSE=0.370091 MAE=0.226884\n",
            "  >> Saved best model (val MSE=0.136967)\n",
            "[Epoch 25/100] TF=1.00 | train MSE=0.016214 RMSE=0.127333 MAE=0.081607 | val MSE=0.126614 RMSE=0.355828 MAE=0.221487\n",
            "  >> Saved best model (val MSE=0.126614)\n",
            "[Epoch 26/100] TF=1.00 | train MSE=0.016445 RMSE=0.128236 MAE=0.083466 | val MSE=0.194548 RMSE=0.441076 MAE=0.277491\n",
            "[Epoch 27/100] TF=1.00 | train MSE=0.016081 RMSE=0.126811 MAE=0.082098 | val MSE=0.131903 RMSE=0.363184 MAE=0.225146\n",
            "[Epoch 28/100] TF=1.00 | train MSE=0.016148 RMSE=0.127075 MAE=0.082078 | val MSE=0.182173 RMSE=0.426817 MAE=0.278235\n",
            "[Epoch 29/100] TF=1.00 | train MSE=0.015972 RMSE=0.126379 MAE=0.082047 | val MSE=0.141844 RMSE=0.376621 MAE=0.226008\n",
            "[Epoch 30/100] TF=1.00 | train MSE=0.015535 RMSE=0.124638 MAE=0.080531 | val MSE=0.134691 RMSE=0.367002 MAE=0.223605\n",
            "[Epoch 31/100] TF=1.00 | train MSE=0.015246 RMSE=0.123477 MAE=0.079154 | val MSE=0.123618 RMSE=0.351593 MAE=0.220385\n",
            "  >> Saved best model (val MSE=0.123618)\n",
            "[Epoch 32/100] TF=1.00 | train MSE=0.015174 RMSE=0.123184 MAE=0.079182 | val MSE=0.186811 RMSE=0.432217 MAE=0.266182\n",
            "[Epoch 33/100] TF=1.00 | train MSE=0.015112 RMSE=0.122930 MAE=0.079024 | val MSE=0.136882 RMSE=0.369976 MAE=0.230904\n",
            "[Epoch 34/100] TF=1.00 | train MSE=0.014853 RMSE=0.121874 MAE=0.077900 | val MSE=0.146815 RMSE=0.383164 MAE=0.232041\n",
            "[Epoch 35/100] TF=1.00 | train MSE=0.015292 RMSE=0.123662 MAE=0.080367 | val MSE=0.166516 RMSE=0.408064 MAE=0.252036\n",
            "[Epoch 36/100] TF=1.00 | train MSE=0.014766 RMSE=0.121517 MAE=0.077997 | val MSE=0.168449 RMSE=0.410425 MAE=0.243528\n",
            "[Epoch 37/100] TF=1.00 | train MSE=0.014413 RMSE=0.120053 MAE=0.076889 | val MSE=0.189420 RMSE=0.435224 MAE=0.257942\n",
            "[Epoch 38/100] TF=1.00 | train MSE=0.014501 RMSE=0.120419 MAE=0.077259 | val MSE=0.113286 RMSE=0.336580 MAE=0.209749\n",
            "  >> Saved best model (val MSE=0.113286)\n",
            "[Epoch 39/100] TF=1.00 | train MSE=0.014634 RMSE=0.120973 MAE=0.078596 | val MSE=0.116043 RMSE=0.340651 MAE=0.212397\n",
            "[Epoch 40/100] TF=1.00 | train MSE=0.014088 RMSE=0.118691 MAE=0.075595 | val MSE=0.123958 RMSE=0.352076 MAE=0.212516\n",
            "[Epoch 41/100] TF=1.00 | train MSE=0.014006 RMSE=0.118348 MAE=0.075681 | val MSE=0.146184 RMSE=0.382341 MAE=0.226875\n",
            "[Epoch 42/100] TF=1.00 | train MSE=0.014097 RMSE=0.118729 MAE=0.075971 | val MSE=0.145845 RMSE=0.381897 MAE=0.240727\n",
            "[Epoch 43/100] TF=1.00 | train MSE=0.014005 RMSE=0.118343 MAE=0.075730 | val MSE=0.135064 RMSE=0.367510 MAE=0.222185\n",
            "[Epoch 44/100] TF=1.00 | train MSE=0.014122 RMSE=0.118836 MAE=0.076531 | val MSE=0.132271 RMSE=0.363690 MAE=0.219890\n",
            "[Epoch 45/100] TF=1.00 | train MSE=0.013774 RMSE=0.117362 MAE=0.075168 | val MSE=0.103132 RMSE=0.321142 MAE=0.197733\n",
            "  >> Saved best model (val MSE=0.103132)\n",
            "[Epoch 46/100] TF=1.00 | train MSE=0.013684 RMSE=0.116980 MAE=0.075248 | val MSE=0.155551 RMSE=0.394400 MAE=0.232135\n",
            "[Epoch 47/100] TF=1.00 | train MSE=0.013563 RMSE=0.116460 MAE=0.074221 | val MSE=0.107489 RMSE=0.327854 MAE=0.198830\n",
            "[Epoch 48/100] TF=1.00 | train MSE=0.013385 RMSE=0.115695 MAE=0.073583 | val MSE=0.118568 RMSE=0.344337 MAE=0.213710\n",
            "[Epoch 49/100] TF=1.00 | train MSE=0.013641 RMSE=0.116793 MAE=0.075202 | val MSE=0.173773 RMSE=0.416861 MAE=0.249048\n",
            "[Epoch 50/100] TF=1.00 | train MSE=0.013552 RMSE=0.116414 MAE=0.075199 | val MSE=0.131203 RMSE=0.362220 MAE=0.226112\n",
            "[Epoch 51/100] TF=1.00 | train MSE=0.013222 RMSE=0.114988 MAE=0.073602 | val MSE=0.123025 RMSE=0.350749 MAE=0.210182\n",
            "[Epoch 52/100] TF=1.00 | train MSE=0.013567 RMSE=0.116476 MAE=0.074761 | val MSE=0.170885 RMSE=0.413382 MAE=0.256083\n",
            "[Epoch 53/100] TF=1.00 | train MSE=0.013307 RMSE=0.115356 MAE=0.074159 | val MSE=0.125878 RMSE=0.354793 MAE=0.221362\n",
            "[Epoch 54/100] TF=1.00 | train MSE=0.013321 RMSE=0.115416 MAE=0.073895 | val MSE=0.167793 RMSE=0.409626 MAE=0.248492\n",
            "[Epoch 55/100] TF=1.00 | train MSE=0.013322 RMSE=0.115420 MAE=0.073490 | val MSE=0.116101 RMSE=0.340736 MAE=0.208320\n",
            "[Epoch 56/100] TF=1.00 | train MSE=0.012907 RMSE=0.113609 MAE=0.072424 | val MSE=0.103452 RMSE=0.321640 MAE=0.201369\n",
            "[Epoch 57/100] TF=1.00 | train MSE=0.012874 RMSE=0.113465 MAE=0.072731 | val MSE=0.106084 RMSE=0.325706 MAE=0.199612\n",
            "[Epoch 58/100] TF=1.00 | train MSE=0.013043 RMSE=0.114206 MAE=0.073307 | val MSE=0.129710 RMSE=0.360152 MAE=0.211785\n",
            "[Epoch 59/100] TF=1.00 | train MSE=0.012679 RMSE=0.112602 MAE=0.071622 | val MSE=0.127858 RMSE=0.357572 MAE=0.215254\n",
            "[Epoch 60/100] TF=1.00 | train MSE=0.012684 RMSE=0.112621 MAE=0.071611 | val MSE=0.121268 RMSE=0.348236 MAE=0.202751\n",
            "[Epoch 61/100] TF=1.00 | train MSE=0.012530 RMSE=0.111938 MAE=0.070750 | val MSE=0.124926 RMSE=0.353449 MAE=0.222760\n",
            "[Epoch 62/100] TF=1.00 | train MSE=0.012711 RMSE=0.112743 MAE=0.072262 | val MSE=0.141969 RMSE=0.376788 MAE=0.234611\n",
            "[Epoch 63/100] TF=1.00 | train MSE=0.012742 RMSE=0.112880 MAE=0.072255 | val MSE=0.131106 RMSE=0.362085 MAE=0.222551\n",
            "[Epoch 64/100] TF=1.00 | train MSE=0.012858 RMSE=0.113393 MAE=0.072241 | val MSE=0.108559 RMSE=0.329484 MAE=0.199670\n",
            "[Epoch 65/100] TF=1.00 | train MSE=0.012580 RMSE=0.112161 MAE=0.071419 | val MSE=0.153426 RMSE=0.391696 MAE=0.233501\n",
            "[Epoch 66/100] TF=1.00 | train MSE=0.012563 RMSE=0.112085 MAE=0.071247 | val MSE=0.101420 RMSE=0.318466 MAE=0.195120\n",
            "  >> Saved best model (val MSE=0.101420)\n",
            "[Epoch 67/100] TF=1.00 | train MSE=0.012181 RMSE=0.110366 MAE=0.069911 | val MSE=0.092870 RMSE=0.304746 MAE=0.184418\n",
            "  >> Saved best model (val MSE=0.092870)\n",
            "[Epoch 68/100] TF=1.00 | train MSE=0.012033 RMSE=0.109697 MAE=0.069194 | val MSE=0.098149 RMSE=0.313287 MAE=0.193691\n",
            "[Epoch 69/100] TF=1.00 | train MSE=0.012313 RMSE=0.110964 MAE=0.070357 | val MSE=0.136162 RMSE=0.369001 MAE=0.219652\n",
            "[Epoch 70/100] TF=1.00 | train MSE=0.012418 RMSE=0.111434 MAE=0.071315 | val MSE=0.123360 RMSE=0.351226 MAE=0.213744\n",
            "[Epoch 71/100] TF=1.00 | train MSE=0.012281 RMSE=0.110821 MAE=0.070626 | val MSE=0.113646 RMSE=0.337115 MAE=0.197844\n",
            "[Epoch 72/100] TF=1.00 | train MSE=0.012092 RMSE=0.109964 MAE=0.069507 | val MSE=0.094053 RMSE=0.306681 MAE=0.180233\n",
            "[Epoch 73/100] TF=1.00 | train MSE=0.012194 RMSE=0.110428 MAE=0.070191 | val MSE=0.118243 RMSE=0.343865 MAE=0.205726\n",
            "[Epoch 74/100] TF=1.00 | train MSE=0.012328 RMSE=0.111030 MAE=0.071013 | val MSE=0.107901 RMSE=0.328483 MAE=0.200565\n",
            "[Epoch 75/100] TF=1.00 | train MSE=0.012041 RMSE=0.109733 MAE=0.069809 | val MSE=0.109896 RMSE=0.331506 MAE=0.200412\n",
            "[Epoch 76/100] TF=1.00 | train MSE=0.012026 RMSE=0.109665 MAE=0.069764 | val MSE=0.103075 RMSE=0.321052 MAE=0.188778\n",
            "[Epoch 77/100] TF=1.00 | train MSE=0.012472 RMSE=0.111678 MAE=0.071362 | val MSE=0.108659 RMSE=0.329635 MAE=0.212262\n",
            "[Epoch 78/100] TF=1.00 | train MSE=0.011918 RMSE=0.109168 MAE=0.069229 | val MSE=0.108023 RMSE=0.328669 MAE=0.197045\n",
            "[Epoch 79/100] TF=1.00 | train MSE=0.011990 RMSE=0.109498 MAE=0.069755 | val MSE=0.107259 RMSE=0.327504 MAE=0.193471\n",
            "[Epoch 80/100] TF=1.00 | train MSE=0.012049 RMSE=0.109769 MAE=0.070628 | val MSE=0.116004 RMSE=0.340594 MAE=0.209498\n",
            "[Epoch 81/100] TF=1.00 | train MSE=0.011956 RMSE=0.109343 MAE=0.069742 | val MSE=0.104056 RMSE=0.322577 MAE=0.190160\n",
            "[Epoch 82/100] TF=1.00 | train MSE=0.012066 RMSE=0.109845 MAE=0.069634 | val MSE=0.133487 RMSE=0.365359 MAE=0.219393\n",
            "[Epoch 83/100] TF=1.00 | train MSE=0.011858 RMSE=0.108894 MAE=0.069341 | val MSE=0.105718 RMSE=0.325143 MAE=0.201773\n",
            "[Epoch 84/100] TF=1.00 | train MSE=0.011491 RMSE=0.107195 MAE=0.067164 | val MSE=0.112753 RMSE=0.335787 MAE=0.198226\n",
            "[Epoch 85/100] TF=1.00 | train MSE=0.011805 RMSE=0.108652 MAE=0.069017 | val MSE=0.146973 RMSE=0.383370 MAE=0.227251\n",
            "[Epoch 86/100] TF=1.00 | train MSE=0.011784 RMSE=0.108555 MAE=0.069157 | val MSE=0.108421 RMSE=0.329274 MAE=0.194614\n",
            "[Epoch 87/100] TF=1.00 | train MSE=0.011800 RMSE=0.108628 MAE=0.069065 | val MSE=0.114043 RMSE=0.337703 MAE=0.199615\n",
            "[Epoch 88/100] TF=1.00 | train MSE=0.011788 RMSE=0.108573 MAE=0.069120 | val MSE=0.140296 RMSE=0.374561 MAE=0.249161\n",
            "[Epoch 89/100] TF=1.00 | train MSE=0.011656 RMSE=0.107961 MAE=0.068998 | val MSE=0.095962 RMSE=0.309777 MAE=0.192384\n",
            "[Epoch 90/100] TF=1.00 | train MSE=0.011761 RMSE=0.108448 MAE=0.069717 | val MSE=0.099161 RMSE=0.314898 MAE=0.190444\n",
            "[Epoch 91/100] TF=1.00 | train MSE=0.011513 RMSE=0.107296 MAE=0.067529 | val MSE=0.099474 RMSE=0.315395 MAE=0.190860\n",
            "[Epoch 92/100] TF=1.00 | train MSE=0.011407 RMSE=0.106802 MAE=0.067780 | val MSE=0.142068 RMSE=0.376919 MAE=0.215664\n",
            "[Epoch 93/100] TF=1.00 | train MSE=0.011808 RMSE=0.108664 MAE=0.069266 | val MSE=0.108795 RMSE=0.329840 MAE=0.205702\n",
            "[Epoch 94/100] TF=1.00 | train MSE=0.012772 RMSE=0.113015 MAE=0.074218 | val MSE=0.252059 RMSE=0.502055 MAE=0.288833\n",
            "[Epoch 95/100] TF=1.00 | train MSE=0.011687 RMSE=0.108106 MAE=0.068450 | val MSE=0.101129 RMSE=0.318009 MAE=0.188824\n",
            "[Epoch 96/100] TF=1.00 | train MSE=0.011280 RMSE=0.106209 MAE=0.067182 | val MSE=0.092842 RMSE=0.304700 MAE=0.178790\n",
            "  >> Saved best model (val MSE=0.092842)\n",
            "[Epoch 97/100] TF=1.00 | train MSE=0.011280 RMSE=0.106209 MAE=0.066993 | val MSE=0.104043 RMSE=0.322556 MAE=0.190129\n",
            "[Epoch 98/100] TF=1.00 | train MSE=0.011161 RMSE=0.105644 MAE=0.066374 | val MSE=0.115017 RMSE=0.339142 MAE=0.198038\n",
            "[Epoch 99/100] TF=1.00 | train MSE=0.011401 RMSE=0.106775 MAE=0.068150 | val MSE=0.110317 RMSE=0.332140 MAE=0.196870\n",
            "[Epoch 100/100] TF=1.00 | train MSE=0.011080 RMSE=0.105260 MAE=0.066158 | val MSE=0.110861 RMSE=0.332958 MAE=0.197496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### convrnn+unet"
      ],
      "metadata": {
        "id": "EAR4VKbjGV5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convrnn_unet_cfg = TrainConfig(\n",
        "    data_dir=\"./\",\n",
        "    max_epochs=100,\n",
        "    batch_size=2,\n",
        "    enc_cell_type=\"convrnn\",\n",
        "    dec_cell_type=\"convrnn\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=False,\n",
        "    unet_head=True,\n",
        "    out_root=\"./runs_w_unet\",\n",
        "    viz_every_n_epochs=10,     # 每 10 个 epoch 可视化一次（train+eval）\n",
        "    viz_use_last_t=True,       # 可切换 False 以随机时间步\n",
        "    viz_channel=None,          # None=随机通道；也可设 0/1/2...\n",
        "    save_all_channels_png=True\n",
        ")\n",
        "convrnn_unet__model, convrnn_unet_history = train(convrnn_unet_cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnArzTZoGVfe",
        "outputId": "72bebb69-5f06-4cbf-cda3-bda6417b22da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据集总数: 119 | 训练集: 95 | 验证集: 24\n",
            "[Epoch 1/100] TF=1.00 | train MSE=0.198879 RMSE=0.445959 MAE=0.293874 | val MSE=0.309009 RMSE=0.555886 MAE=0.374112\n",
            "  >> Saved best model (val MSE=0.309009)\n",
            "[Epoch 2/100] TF=1.00 | train MSE=0.052416 RMSE=0.228946 MAE=0.156258 | val MSE=0.314910 RMSE=0.561168 MAE=0.378718\n",
            "[Epoch 3/100] TF=1.00 | train MSE=0.041373 RMSE=0.203405 MAE=0.138453 | val MSE=0.275440 RMSE=0.524824 MAE=0.348831\n",
            "  >> Saved best model (val MSE=0.275440)\n",
            "[Epoch 4/100] TF=1.00 | train MSE=0.035075 RMSE=0.187284 MAE=0.127586 | val MSE=0.294691 RMSE=0.542854 MAE=0.343358\n",
            "[Epoch 5/100] TF=1.00 | train MSE=0.031377 RMSE=0.177134 MAE=0.120206 | val MSE=0.287049 RMSE=0.535769 MAE=0.362786\n",
            "[Epoch 6/100] TF=1.00 | train MSE=0.028953 RMSE=0.170156 MAE=0.114649 | val MSE=0.214834 RMSE=0.463502 MAE=0.301598\n",
            "  >> Saved best model (val MSE=0.214834)\n",
            "[Epoch 7/100] TF=1.00 | train MSE=0.026798 RMSE=0.163701 MAE=0.109261 | val MSE=0.195323 RMSE=0.441954 MAE=0.287313\n",
            "  >> Saved best model (val MSE=0.195323)\n",
            "[Epoch 8/100] TF=1.00 | train MSE=0.025714 RMSE=0.160356 MAE=0.107270 | val MSE=0.240800 RMSE=0.490714 MAE=0.321865\n",
            "[Epoch 9/100] TF=1.00 | train MSE=0.024902 RMSE=0.157803 MAE=0.105554 | val MSE=0.247512 RMSE=0.497506 MAE=0.325603\n",
            "[Epoch 10/100] TF=1.00 | train MSE=0.023817 RMSE=0.154327 MAE=0.102317 | val MSE=0.310152 RMSE=0.556913 MAE=0.368229\n",
            "[Epoch 11/100] TF=1.00 | train MSE=0.023233 RMSE=0.152424 MAE=0.101166 | val MSE=0.214802 RMSE=0.463468 MAE=0.306300\n",
            "[Epoch 12/100] TF=1.00 | train MSE=0.021955 RMSE=0.148171 MAE=0.097027 | val MSE=0.169957 RMSE=0.412259 MAE=0.271848\n",
            "  >> Saved best model (val MSE=0.169957)\n",
            "[Epoch 13/100] TF=1.00 | train MSE=0.022093 RMSE=0.148637 MAE=0.098826 | val MSE=0.234100 RMSE=0.483839 MAE=0.317800\n",
            "[Epoch 14/100] TF=1.00 | train MSE=0.021052 RMSE=0.145093 MAE=0.095104 | val MSE=0.207586 RMSE=0.455616 MAE=0.305017\n",
            "[Epoch 15/100] TF=1.00 | train MSE=0.020369 RMSE=0.142719 MAE=0.093343 | val MSE=0.250315 RMSE=0.500315 MAE=0.320849\n",
            "[Epoch 16/100] TF=1.00 | train MSE=0.020773 RMSE=0.144129 MAE=0.094585 | val MSE=0.201009 RMSE=0.448340 MAE=0.293205\n",
            "[Epoch 17/100] TF=1.00 | train MSE=0.020016 RMSE=0.141477 MAE=0.093101 | val MSE=0.195902 RMSE=0.442609 MAE=0.287630\n",
            "[Epoch 18/100] TF=1.00 | train MSE=0.019155 RMSE=0.138401 MAE=0.090054 | val MSE=0.190426 RMSE=0.436378 MAE=0.275114\n",
            "[Epoch 19/100] TF=1.00 | train MSE=0.018966 RMSE=0.137719 MAE=0.090160 | val MSE=0.197578 RMSE=0.444498 MAE=0.278792\n",
            "[Epoch 20/100] TF=1.00 | train MSE=0.018541 RMSE=0.136166 MAE=0.088924 | val MSE=0.218938 RMSE=0.467908 MAE=0.319383\n",
            "[Epoch 21/100] TF=1.00 | train MSE=0.018132 RMSE=0.134655 MAE=0.087906 | val MSE=0.140296 RMSE=0.374562 MAE=0.236265\n",
            "  >> Saved best model (val MSE=0.140296)\n",
            "[Epoch 22/100] TF=1.00 | train MSE=0.018149 RMSE=0.134720 MAE=0.088215 | val MSE=0.181608 RMSE=0.426155 MAE=0.279397\n",
            "[Epoch 23/100] TF=1.00 | train MSE=0.017576 RMSE=0.132573 MAE=0.086413 | val MSE=0.164670 RMSE=0.405795 MAE=0.256086\n",
            "[Epoch 24/100] TF=1.00 | train MSE=0.017857 RMSE=0.133629 MAE=0.087682 | val MSE=0.168825 RMSE=0.410884 MAE=0.263341\n",
            "[Epoch 25/100] TF=1.00 | train MSE=0.017484 RMSE=0.132226 MAE=0.086146 | val MSE=0.405642 RMSE=0.636900 MAE=0.412885\n",
            "[Epoch 26/100] TF=1.00 | train MSE=0.017328 RMSE=0.131637 MAE=0.086344 | val MSE=0.142650 RMSE=0.377690 MAE=0.243879\n",
            "[Epoch 27/100] TF=1.00 | train MSE=0.016801 RMSE=0.129617 MAE=0.084198 | val MSE=0.281644 RMSE=0.530701 MAE=0.356582\n",
            "[Epoch 28/100] TF=1.00 | train MSE=0.017013 RMSE=0.130433 MAE=0.085950 | val MSE=0.142718 RMSE=0.377781 MAE=0.241013\n",
            "[Epoch 29/100] TF=1.00 | train MSE=0.016347 RMSE=0.127854 MAE=0.082828 | val MSE=0.175902 RMSE=0.419407 MAE=0.279593\n",
            "[Epoch 30/100] TF=1.00 | train MSE=0.016336 RMSE=0.127811 MAE=0.082991 | val MSE=0.131734 RMSE=0.362951 MAE=0.226404\n",
            "  >> Saved best model (val MSE=0.131734)\n",
            "[Epoch 31/100] TF=1.00 | train MSE=0.016025 RMSE=0.126591 MAE=0.082023 | val MSE=0.194619 RMSE=0.441156 MAE=0.266097\n",
            "[Epoch 32/100] TF=1.00 | train MSE=0.016744 RMSE=0.129398 MAE=0.084989 | val MSE=0.159635 RMSE=0.399544 MAE=0.251613\n",
            "[Epoch 33/100] TF=1.00 | train MSE=0.015730 RMSE=0.125419 MAE=0.081049 | val MSE=0.134214 RMSE=0.366353 MAE=0.230149\n",
            "[Epoch 34/100] TF=1.00 | train MSE=0.015657 RMSE=0.125129 MAE=0.081105 | val MSE=0.151597 RMSE=0.389355 MAE=0.241842\n",
            "[Epoch 35/100] TF=1.00 | train MSE=0.015188 RMSE=0.123239 MAE=0.079325 | val MSE=0.180639 RMSE=0.425017 MAE=0.285543\n",
            "[Epoch 36/100] TF=1.00 | train MSE=0.015696 RMSE=0.125283 MAE=0.081706 | val MSE=0.176512 RMSE=0.420134 MAE=0.246451\n",
            "[Epoch 37/100] TF=1.00 | train MSE=0.015222 RMSE=0.123377 MAE=0.079667 | val MSE=0.141389 RMSE=0.376017 MAE=0.228181\n",
            "[Epoch 38/100] TF=1.00 | train MSE=0.015640 RMSE=0.125061 MAE=0.081697 | val MSE=0.162902 RMSE=0.403611 MAE=0.256789\n",
            "[Epoch 39/100] TF=1.00 | train MSE=0.015035 RMSE=0.122617 MAE=0.079340 | val MSE=0.202034 RMSE=0.449482 MAE=0.296947\n",
            "[Epoch 40/100] TF=1.00 | train MSE=0.015001 RMSE=0.122478 MAE=0.079163 | val MSE=0.204002 RMSE=0.451666 MAE=0.284994\n",
            "[Epoch 41/100] TF=1.00 | train MSE=0.014944 RMSE=0.122247 MAE=0.079023 | val MSE=0.141041 RMSE=0.375555 MAE=0.241074\n",
            "[Epoch 42/100] TF=1.00 | train MSE=0.014894 RMSE=0.122040 MAE=0.078990 | val MSE=0.145592 RMSE=0.381565 MAE=0.235540\n",
            "[Epoch 43/100] TF=1.00 | train MSE=0.014983 RMSE=0.122407 MAE=0.079712 | val MSE=0.197728 RMSE=0.444666 MAE=0.283408\n",
            "[Epoch 44/100] TF=1.00 | train MSE=0.014933 RMSE=0.122199 MAE=0.079254 | val MSE=0.151286 RMSE=0.388955 MAE=0.229096\n",
            "[Epoch 45/100] TF=1.00 | train MSE=0.014385 RMSE=0.119939 MAE=0.077016 | val MSE=0.115962 RMSE=0.340532 MAE=0.214186\n",
            "  >> Saved best model (val MSE=0.115962)\n",
            "[Epoch 46/100] TF=1.00 | train MSE=0.014008 RMSE=0.118357 MAE=0.075545 | val MSE=0.155047 RMSE=0.393761 MAE=0.255991\n",
            "[Epoch 47/100] TF=1.00 | train MSE=0.014762 RMSE=0.121500 MAE=0.078880 | val MSE=0.225251 RMSE=0.474606 MAE=0.318173\n",
            "[Epoch 48/100] TF=1.00 | train MSE=0.014547 RMSE=0.120609 MAE=0.078080 | val MSE=0.132606 RMSE=0.364150 MAE=0.229154\n",
            "[Epoch 49/100] TF=1.00 | train MSE=0.014339 RMSE=0.119747 MAE=0.077759 | val MSE=0.274242 RMSE=0.523681 MAE=0.316707\n",
            "[Epoch 50/100] TF=1.00 | train MSE=0.014400 RMSE=0.119998 MAE=0.077672 | val MSE=0.189773 RMSE=0.435629 MAE=0.287968\n",
            "[Epoch 51/100] TF=1.00 | train MSE=0.014141 RMSE=0.118917 MAE=0.076581 | val MSE=0.142363 RMSE=0.377310 MAE=0.237046\n",
            "[Epoch 52/100] TF=1.00 | train MSE=0.013941 RMSE=0.118071 MAE=0.075949 | val MSE=0.188365 RMSE=0.434011 MAE=0.278270\n",
            "[Epoch 53/100] TF=1.00 | train MSE=0.014317 RMSE=0.119652 MAE=0.077789 | val MSE=0.168386 RMSE=0.410349 MAE=0.269095\n",
            "[Epoch 54/100] TF=1.00 | train MSE=0.013788 RMSE=0.117422 MAE=0.075201 | val MSE=0.115726 RMSE=0.340186 MAE=0.209083\n",
            "  >> Saved best model (val MSE=0.115726)\n",
            "[Epoch 55/100] TF=1.00 | train MSE=0.013858 RMSE=0.117721 MAE=0.075529 | val MSE=0.147377 RMSE=0.383897 MAE=0.232737\n",
            "[Epoch 56/100] TF=1.00 | train MSE=0.013982 RMSE=0.118247 MAE=0.076502 | val MSE=0.132058 RMSE=0.363398 MAE=0.228720\n",
            "[Epoch 57/100] TF=1.00 | train MSE=0.013448 RMSE=0.115966 MAE=0.074142 | val MSE=0.121480 RMSE=0.348539 MAE=0.218715\n",
            "[Epoch 58/100] TF=1.00 | train MSE=0.013499 RMSE=0.116186 MAE=0.074542 | val MSE=0.172943 RMSE=0.415864 MAE=0.265106\n",
            "[Epoch 59/100] TF=1.00 | train MSE=0.013480 RMSE=0.116103 MAE=0.074618 | val MSE=0.221184 RMSE=0.470302 MAE=0.283683\n",
            "[Epoch 60/100] TF=1.00 | train MSE=0.013638 RMSE=0.116782 MAE=0.074974 | val MSE=0.129474 RMSE=0.359825 MAE=0.224326\n",
            "[Epoch 61/100] TF=1.00 | train MSE=0.013387 RMSE=0.115702 MAE=0.073722 | val MSE=0.122541 RMSE=0.350059 MAE=0.219327\n",
            "[Epoch 62/100] TF=1.00 | train MSE=0.013268 RMSE=0.115186 MAE=0.073900 | val MSE=0.149826 RMSE=0.387074 MAE=0.243339\n",
            "[Epoch 63/100] TF=1.00 | train MSE=0.013492 RMSE=0.116156 MAE=0.075069 | val MSE=0.118719 RMSE=0.344557 MAE=0.217133\n",
            "[Epoch 64/100] TF=1.00 | train MSE=0.013198 RMSE=0.114881 MAE=0.073648 | val MSE=0.134270 RMSE=0.366429 MAE=0.234823\n",
            "[Epoch 65/100] TF=1.00 | train MSE=0.013470 RMSE=0.116060 MAE=0.074794 | val MSE=0.119905 RMSE=0.346273 MAE=0.209649\n",
            "[Epoch 66/100] TF=1.00 | train MSE=0.013103 RMSE=0.114470 MAE=0.072991 | val MSE=0.147674 RMSE=0.384283 MAE=0.241193\n",
            "[Epoch 67/100] TF=1.00 | train MSE=0.013191 RMSE=0.114853 MAE=0.073586 | val MSE=0.110371 RMSE=0.332221 MAE=0.207457\n",
            "  >> Saved best model (val MSE=0.110371)\n",
            "[Epoch 68/100] TF=1.00 | train MSE=0.012976 RMSE=0.113912 MAE=0.073140 | val MSE=0.127572 RMSE=0.357172 MAE=0.227424\n",
            "[Epoch 69/100] TF=1.00 | train MSE=0.012827 RMSE=0.113255 MAE=0.072329 | val MSE=0.133946 RMSE=0.365986 MAE=0.233449\n",
            "[Epoch 70/100] TF=1.00 | train MSE=0.013179 RMSE=0.114799 MAE=0.073865 | val MSE=0.126451 RMSE=0.355600 MAE=0.225749\n",
            "[Epoch 71/100] TF=1.00 | train MSE=0.012737 RMSE=0.112860 MAE=0.071908 | val MSE=0.109189 RMSE=0.330438 MAE=0.203520\n",
            "  >> Saved best model (val MSE=0.109189)\n",
            "[Epoch 72/100] TF=1.00 | train MSE=0.012489 RMSE=0.111753 MAE=0.070624 | val MSE=0.121286 RMSE=0.348262 MAE=0.210831\n",
            "[Epoch 73/100] TF=1.00 | train MSE=0.012615 RMSE=0.112315 MAE=0.071230 | val MSE=0.201351 RMSE=0.448721 MAE=0.277729\n",
            "[Epoch 74/100] TF=1.00 | train MSE=0.013818 RMSE=0.117548 MAE=0.075577 | val MSE=0.126093 RMSE=0.355096 MAE=0.224645\n",
            "[Epoch 75/100] TF=1.00 | train MSE=0.013007 RMSE=0.114049 MAE=0.073944 | val MSE=0.143039 RMSE=0.378205 MAE=0.254047\n",
            "[Epoch 76/100] TF=1.00 | train MSE=0.013028 RMSE=0.114140 MAE=0.073910 | val MSE=0.164670 RMSE=0.405795 MAE=0.246896\n",
            "[Epoch 77/100] TF=1.00 | train MSE=0.012953 RMSE=0.113811 MAE=0.073084 | val MSE=0.104861 RMSE=0.323823 MAE=0.200862\n",
            "  >> Saved best model (val MSE=0.104861)\n",
            "[Epoch 78/100] TF=1.00 | train MSE=0.012524 RMSE=0.111912 MAE=0.071603 | val MSE=0.118553 RMSE=0.344315 MAE=0.213880\n",
            "[Epoch 79/100] TF=1.00 | train MSE=0.012395 RMSE=0.111335 MAE=0.070996 | val MSE=0.124944 RMSE=0.353474 MAE=0.227843\n",
            "[Epoch 80/100] TF=1.00 | train MSE=0.012633 RMSE=0.112398 MAE=0.071732 | val MSE=0.141354 RMSE=0.375970 MAE=0.232922\n",
            "[Epoch 81/100] TF=1.00 | train MSE=0.012765 RMSE=0.112982 MAE=0.073246 | val MSE=0.119470 RMSE=0.345644 MAE=0.220322\n",
            "[Epoch 82/100] TF=1.00 | train MSE=0.012660 RMSE=0.112516 MAE=0.072407 | val MSE=0.124073 RMSE=0.352241 MAE=0.214197\n",
            "[Epoch 83/100] TF=1.00 | train MSE=0.012671 RMSE=0.112566 MAE=0.072163 | val MSE=0.138025 RMSE=0.371517 MAE=0.222343\n",
            "[Epoch 84/100] TF=1.00 | train MSE=0.012434 RMSE=0.111507 MAE=0.070886 | val MSE=0.117908 RMSE=0.343377 MAE=0.203966\n",
            "[Epoch 85/100] TF=1.00 | train MSE=0.012320 RMSE=0.110994 MAE=0.070740 | val MSE=0.116925 RMSE=0.341943 MAE=0.206190\n",
            "[Epoch 86/100] TF=1.00 | train MSE=0.012184 RMSE=0.110379 MAE=0.070373 | val MSE=0.138474 RMSE=0.372120 MAE=0.228510\n",
            "[Epoch 87/100] TF=1.00 | train MSE=0.012207 RMSE=0.110484 MAE=0.070510 | val MSE=0.198879 RMSE=0.445959 MAE=0.311880\n",
            "[Epoch 88/100] TF=1.00 | train MSE=0.012656 RMSE=0.112498 MAE=0.072737 | val MSE=0.135849 RMSE=0.368577 MAE=0.248136\n",
            "[Epoch 89/100] TF=1.00 | train MSE=0.012894 RMSE=0.113550 MAE=0.072772 | val MSE=0.148982 RMSE=0.385982 MAE=0.239927\n",
            "[Epoch 90/100] TF=1.00 | train MSE=0.012185 RMSE=0.110388 MAE=0.070460 | val MSE=0.110624 RMSE=0.332602 MAE=0.207847\n",
            "[Epoch 91/100] TF=1.00 | train MSE=0.012754 RMSE=0.112931 MAE=0.072763 | val MSE=0.141125 RMSE=0.375666 MAE=0.242254\n",
            "[Epoch 92/100] TF=1.00 | train MSE=0.012191 RMSE=0.110415 MAE=0.070528 | val MSE=0.128307 RMSE=0.358199 MAE=0.216334\n",
            "[Epoch 93/100] TF=1.00 | train MSE=0.011975 RMSE=0.109429 MAE=0.069554 | val MSE=0.112261 RMSE=0.335054 MAE=0.209332\n",
            "[Epoch 94/100] TF=1.00 | train MSE=0.011992 RMSE=0.109508 MAE=0.069684 | val MSE=0.108232 RMSE=0.328986 MAE=0.203056\n",
            "[Epoch 95/100] TF=1.00 | train MSE=0.011994 RMSE=0.109515 MAE=0.069444 | val MSE=0.126178 RMSE=0.355215 MAE=0.211777\n",
            "[Epoch 96/100] TF=1.00 | train MSE=0.012163 RMSE=0.110286 MAE=0.070434 | val MSE=0.110357 RMSE=0.332200 MAE=0.201013\n",
            "[Epoch 97/100] TF=1.00 | train MSE=0.012156 RMSE=0.110255 MAE=0.070900 | val MSE=0.136597 RMSE=0.369591 MAE=0.223809\n",
            "[Epoch 98/100] TF=1.00 | train MSE=0.011816 RMSE=0.108703 MAE=0.069211 | val MSE=0.129320 RMSE=0.359611 MAE=0.229821\n",
            "[Epoch 99/100] TF=1.00 | train MSE=0.011933 RMSE=0.109240 MAE=0.069453 | val MSE=0.104016 RMSE=0.322515 MAE=0.198343\n",
            "  >> Saved best model (val MSE=0.104016)\n",
            "[Epoch 100/100] TF=1.00 | train MSE=0.012043 RMSE=0.109739 MAE=0.069947 | val MSE=0.115984 RMSE=0.340564 MAE=0.212449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### convlstm+unet"
      ],
      "metadata": {
        "id": "t61MHrwcGkrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convlstm_unet_cfg = TrainConfig(\n",
        "    data_dir=\"./\",\n",
        "    max_epochs=100,\n",
        "    batch_size=2,\n",
        "    enc_cell_type=\"convlstm\",\n",
        "    dec_cell_type=\"convlstm\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=True,\n",
        "    unet_head=True,\n",
        "    out_root=\"./runs_w_unet\",\n",
        "    viz_every_n_epochs=10,     # 每 10 个 epoch 可视化一次（train+eval）\n",
        "    viz_use_last_t=True,       # 可切换 False 以随机时间步\n",
        "    viz_channel=None,          # None=随机通道；也可设 0/1/2...\n",
        "    save_all_channels_png=True\n",
        ")\n",
        "convlstm_unet_model, convlstm_unet_history = train(convlstm_unet_cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36wNPxUmGjye",
        "outputId": "1ff535c5-2e41-45dc-96e1-6a0bf50ca49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据集总数: 119 | 训练集: 95 | 验证集: 24\n",
            "[Epoch 1/100] TF=1.00 | train MSE=0.214036 RMSE=0.462641 MAE=0.299690 | val MSE=0.362628 RMSE=0.602186 MAE=0.401035\n",
            "  >> Saved best model (val MSE=0.362628)\n",
            "[Epoch 2/100] TF=1.00 | train MSE=0.049479 RMSE=0.222439 MAE=0.152822 | val MSE=0.293458 RMSE=0.541717 MAE=0.349391\n",
            "  >> Saved best model (val MSE=0.293458)\n",
            "[Epoch 3/100] TF=1.00 | train MSE=0.038516 RMSE=0.196256 MAE=0.134019 | val MSE=0.279627 RMSE=0.528798 MAE=0.339137\n",
            "  >> Saved best model (val MSE=0.279627)\n",
            "[Epoch 4/100] TF=1.00 | train MSE=0.032509 RMSE=0.180304 MAE=0.123485 | val MSE=0.223405 RMSE=0.472657 MAE=0.315398\n",
            "  >> Saved best model (val MSE=0.223405)\n",
            "[Epoch 5/100] TF=1.00 | train MSE=0.029138 RMSE=0.170699 MAE=0.116285 | val MSE=0.259078 RMSE=0.508997 MAE=0.352638\n",
            "[Epoch 6/100] TF=1.00 | train MSE=0.026996 RMSE=0.164303 MAE=0.111629 | val MSE=0.272162 RMSE=0.521692 MAE=0.320499\n",
            "[Epoch 7/100] TF=1.00 | train MSE=0.026019 RMSE=0.161303 MAE=0.109567 | val MSE=0.229228 RMSE=0.478778 MAE=0.311377\n",
            "[Epoch 8/100] TF=1.00 | train MSE=0.023921 RMSE=0.154665 MAE=0.103449 | val MSE=0.224764 RMSE=0.474093 MAE=0.317971\n",
            "[Epoch 9/100] TF=1.00 | train MSE=0.023169 RMSE=0.152213 MAE=0.101704 | val MSE=0.361829 RMSE=0.601522 MAE=0.437017\n",
            "[Epoch 10/100] TF=1.00 | train MSE=0.024240 RMSE=0.155691 MAE=0.106367 | val MSE=0.204625 RMSE=0.452355 MAE=0.287249\n",
            "  >> Saved best model (val MSE=0.204625)\n",
            "[Epoch 11/100] TF=1.00 | train MSE=0.022121 RMSE=0.148730 MAE=0.099344 | val MSE=0.279475 RMSE=0.528654 MAE=0.333059\n",
            "[Epoch 12/100] TF=1.00 | train MSE=0.021839 RMSE=0.147779 MAE=0.098799 | val MSE=0.195431 RMSE=0.442076 MAE=0.278524\n",
            "  >> Saved best model (val MSE=0.195431)\n",
            "[Epoch 13/100] TF=1.00 | train MSE=0.021274 RMSE=0.145856 MAE=0.097711 | val MSE=0.248281 RMSE=0.498278 MAE=0.334348\n",
            "[Epoch 14/100] TF=1.00 | train MSE=0.020836 RMSE=0.144348 MAE=0.095621 | val MSE=0.179720 RMSE=0.423934 MAE=0.258599\n",
            "  >> Saved best model (val MSE=0.179720)\n",
            "[Epoch 15/100] TF=1.00 | train MSE=0.020775 RMSE=0.144136 MAE=0.096463 | val MSE=0.158676 RMSE=0.398342 MAE=0.254228\n",
            "  >> Saved best model (val MSE=0.158676)\n",
            "[Epoch 16/100] TF=1.00 | train MSE=0.019919 RMSE=0.141136 MAE=0.093865 | val MSE=0.168704 RMSE=0.410735 MAE=0.255447\n",
            "[Epoch 17/100] TF=1.00 | train MSE=0.019566 RMSE=0.139877 MAE=0.093048 | val MSE=0.177638 RMSE=0.421471 MAE=0.266286\n",
            "[Epoch 18/100] TF=1.00 | train MSE=0.019339 RMSE=0.139063 MAE=0.092336 | val MSE=0.210160 RMSE=0.458432 MAE=0.290988\n",
            "[Epoch 19/100] TF=1.00 | train MSE=0.018652 RMSE=0.136571 MAE=0.089943 | val MSE=0.172577 RMSE=0.415423 MAE=0.267772\n",
            "[Epoch 20/100] TF=1.00 | train MSE=0.018238 RMSE=0.135050 MAE=0.088637 | val MSE=0.226514 RMSE=0.475935 MAE=0.289572\n",
            "[Epoch 21/100] TF=1.00 | train MSE=0.018344 RMSE=0.135441 MAE=0.089213 | val MSE=0.139392 RMSE=0.373353 MAE=0.225561\n",
            "  >> Saved best model (val MSE=0.139392)\n",
            "[Epoch 22/100] TF=1.00 | train MSE=0.017458 RMSE=0.132130 MAE=0.086310 | val MSE=0.144945 RMSE=0.380716 MAE=0.235437\n",
            "[Epoch 23/100] TF=1.00 | train MSE=0.017631 RMSE=0.132783 MAE=0.087297 | val MSE=0.214085 RMSE=0.462693 MAE=0.303528\n",
            "[Epoch 24/100] TF=1.00 | train MSE=0.017821 RMSE=0.133496 MAE=0.088464 | val MSE=0.332203 RMSE=0.576370 MAE=0.339407\n",
            "[Epoch 25/100] TF=1.00 | train MSE=0.017665 RMSE=0.132911 MAE=0.088178 | val MSE=0.187492 RMSE=0.433004 MAE=0.286025\n",
            "[Epoch 26/100] TF=1.00 | train MSE=0.017437 RMSE=0.132050 MAE=0.087275 | val MSE=0.195178 RMSE=0.441789 MAE=0.286730\n",
            "[Epoch 27/100] TF=1.00 | train MSE=0.016916 RMSE=0.130061 MAE=0.085392 | val MSE=0.204311 RMSE=0.452008 MAE=0.294885\n",
            "[Epoch 28/100] TF=1.00 | train MSE=0.016891 RMSE=0.129965 MAE=0.085907 | val MSE=0.158451 RMSE=0.398059 MAE=0.245693\n",
            "[Epoch 29/100] TF=1.00 | train MSE=0.016418 RMSE=0.128131 MAE=0.083930 | val MSE=0.125871 RMSE=0.354784 MAE=0.229043\n",
            "  >> Saved best model (val MSE=0.125871)\n",
            "[Epoch 30/100] TF=1.00 | train MSE=0.016609 RMSE=0.128876 MAE=0.084460 | val MSE=0.207899 RMSE=0.455959 MAE=0.305399\n",
            "[Epoch 31/100] TF=1.00 | train MSE=0.016732 RMSE=0.129353 MAE=0.085429 | val MSE=0.139086 RMSE=0.372942 MAE=0.221903\n",
            "[Epoch 32/100] TF=1.00 | train MSE=0.015459 RMSE=0.124335 MAE=0.080209 | val MSE=0.174439 RMSE=0.417659 MAE=0.269800\n",
            "[Epoch 33/100] TF=1.00 | train MSE=0.015589 RMSE=0.124854 MAE=0.080802 | val MSE=0.151766 RMSE=0.389571 MAE=0.243782\n",
            "[Epoch 34/100] TF=1.00 | train MSE=0.015557 RMSE=0.124728 MAE=0.081290 | val MSE=0.144254 RMSE=0.379808 MAE=0.235381\n",
            "[Epoch 35/100] TF=1.00 | train MSE=0.015780 RMSE=0.125617 MAE=0.082304 | val MSE=0.167772 RMSE=0.409600 MAE=0.251456\n",
            "[Epoch 36/100] TF=1.00 | train MSE=0.015360 RMSE=0.123934 MAE=0.080685 | val MSE=0.183981 RMSE=0.428930 MAE=0.268416\n",
            "[Epoch 37/100] TF=1.00 | train MSE=0.015174 RMSE=0.123182 MAE=0.079884 | val MSE=0.192391 RMSE=0.438624 MAE=0.259915\n",
            "[Epoch 38/100] TF=1.00 | train MSE=0.015088 RMSE=0.122835 MAE=0.079468 | val MSE=0.148972 RMSE=0.385969 MAE=0.227061\n",
            "[Epoch 39/100] TF=1.00 | train MSE=0.014939 RMSE=0.122225 MAE=0.079255 | val MSE=0.161221 RMSE=0.401523 MAE=0.241568\n",
            "[Epoch 40/100] TF=1.00 | train MSE=0.015299 RMSE=0.123687 MAE=0.080958 | val MSE=0.145404 RMSE=0.381319 MAE=0.227783\n",
            "[Epoch 41/100] TF=1.00 | train MSE=0.014409 RMSE=0.120037 MAE=0.077327 | val MSE=0.149969 RMSE=0.387258 MAE=0.233720\n",
            "[Epoch 42/100] TF=1.00 | train MSE=0.014636 RMSE=0.120978 MAE=0.077971 | val MSE=0.149839 RMSE=0.387090 MAE=0.252512\n",
            "[Epoch 43/100] TF=1.00 | train MSE=0.015599 RMSE=0.124895 MAE=0.082946 | val MSE=0.143606 RMSE=0.378953 MAE=0.233709\n",
            "[Epoch 44/100] TF=1.00 | train MSE=0.014670 RMSE=0.121118 MAE=0.078733 | val MSE=0.130939 RMSE=0.361855 MAE=0.223540\n",
            "[Epoch 45/100] TF=1.00 | train MSE=0.014095 RMSE=0.118724 MAE=0.076302 | val MSE=0.160432 RMSE=0.400540 MAE=0.250202\n",
            "[Epoch 46/100] TF=1.00 | train MSE=0.014007 RMSE=0.118353 MAE=0.076208 | val MSE=0.149781 RMSE=0.387015 MAE=0.231137\n",
            "[Epoch 47/100] TF=1.00 | train MSE=0.014116 RMSE=0.118810 MAE=0.076591 | val MSE=0.209589 RMSE=0.457809 MAE=0.266810\n",
            "[Epoch 48/100] TF=1.00 | train MSE=0.015851 RMSE=0.125902 MAE=0.084363 | val MSE=0.145673 RMSE=0.381672 MAE=0.246931\n",
            "[Epoch 49/100] TF=1.00 | train MSE=0.013916 RMSE=0.117965 MAE=0.075423 | val MSE=0.140532 RMSE=0.374876 MAE=0.223532\n",
            "[Epoch 50/100] TF=1.00 | train MSE=0.013867 RMSE=0.117759 MAE=0.075695 | val MSE=0.130259 RMSE=0.360914 MAE=0.220624\n",
            "[Epoch 51/100] TF=1.00 | train MSE=0.013695 RMSE=0.117026 MAE=0.075154 | val MSE=0.117163 RMSE=0.342291 MAE=0.207277\n",
            "  >> Saved best model (val MSE=0.117163)\n",
            "[Epoch 52/100] TF=1.00 | train MSE=0.013380 RMSE=0.115671 MAE=0.073392 | val MSE=0.130721 RMSE=0.361554 MAE=0.224780\n",
            "[Epoch 53/100] TF=1.00 | train MSE=0.013369 RMSE=0.115624 MAE=0.073954 | val MSE=0.198207 RMSE=0.445204 MAE=0.264458\n",
            "[Epoch 54/100] TF=1.00 | train MSE=0.013493 RMSE=0.116161 MAE=0.074445 | val MSE=0.123852 RMSE=0.351926 MAE=0.212536\n",
            "[Epoch 55/100] TF=1.00 | train MSE=0.013566 RMSE=0.116473 MAE=0.074866 | val MSE=0.149849 RMSE=0.387103 MAE=0.244027\n",
            "[Epoch 56/100] TF=1.00 | train MSE=0.013681 RMSE=0.116964 MAE=0.075454 | val MSE=0.121372 RMSE=0.348384 MAE=0.209212\n",
            "[Epoch 57/100] TF=1.00 | train MSE=0.013187 RMSE=0.114836 MAE=0.073662 | val MSE=0.154272 RMSE=0.392775 MAE=0.241995\n",
            "[Epoch 58/100] TF=1.00 | train MSE=0.013643 RMSE=0.116805 MAE=0.075376 | val MSE=0.128282 RMSE=0.358165 MAE=0.222274\n",
            "[Epoch 59/100] TF=1.00 | train MSE=0.013682 RMSE=0.116969 MAE=0.075976 | val MSE=0.171139 RMSE=0.413690 MAE=0.254854\n",
            "[Epoch 60/100] TF=1.00 | train MSE=0.013758 RMSE=0.117294 MAE=0.075868 | val MSE=0.128865 RMSE=0.358977 MAE=0.221574\n",
            "[Epoch 61/100] TF=1.00 | train MSE=0.013243 RMSE=0.115077 MAE=0.074343 | val MSE=0.129905 RMSE=0.360423 MAE=0.216546\n",
            "[Epoch 62/100] TF=1.00 | train MSE=0.012844 RMSE=0.113329 MAE=0.072246 | val MSE=0.157042 RMSE=0.396286 MAE=0.236051\n",
            "[Epoch 63/100] TF=1.00 | train MSE=0.012758 RMSE=0.112949 MAE=0.072129 | val MSE=0.132515 RMSE=0.364026 MAE=0.225833\n",
            "[Epoch 64/100] TF=1.00 | train MSE=0.013081 RMSE=0.114370 MAE=0.074108 | val MSE=0.164104 RMSE=0.405098 MAE=0.242872\n",
            "[Epoch 65/100] TF=1.00 | train MSE=0.013172 RMSE=0.114768 MAE=0.074386 | val MSE=0.127230 RMSE=0.356694 MAE=0.213497\n",
            "[Epoch 66/100] TF=1.00 | train MSE=0.013425 RMSE=0.115868 MAE=0.075706 | val MSE=0.208033 RMSE=0.456106 MAE=0.268465\n",
            "[Epoch 67/100] TF=1.00 | train MSE=0.013871 RMSE=0.117775 MAE=0.077779 | val MSE=0.124453 RMSE=0.352780 MAE=0.212883\n",
            "[Epoch 68/100] TF=1.00 | train MSE=0.012702 RMSE=0.112704 MAE=0.072076 | val MSE=0.129927 RMSE=0.360454 MAE=0.222625\n",
            "[Epoch 69/100] TF=1.00 | train MSE=0.012759 RMSE=0.112956 MAE=0.072584 | val MSE=0.139005 RMSE=0.372833 MAE=0.230752\n",
            "[Epoch 70/100] TF=1.00 | train MSE=0.012743 RMSE=0.112887 MAE=0.072197 | val MSE=0.196202 RMSE=0.442947 MAE=0.282227\n",
            "[Epoch 71/100] TF=1.00 | train MSE=0.013117 RMSE=0.114529 MAE=0.073801 | val MSE=0.121936 RMSE=0.349194 MAE=0.212386\n",
            "[Epoch 72/100] TF=1.00 | train MSE=0.012667 RMSE=0.112549 MAE=0.072152 | val MSE=0.120173 RMSE=0.346660 MAE=0.214385\n",
            "[Epoch 73/100] TF=1.00 | train MSE=0.012421 RMSE=0.111449 MAE=0.071071 | val MSE=0.180338 RMSE=0.424662 MAE=0.260012\n",
            "[Epoch 74/100] TF=1.00 | train MSE=0.012502 RMSE=0.111811 MAE=0.071824 | val MSE=0.168042 RMSE=0.409929 MAE=0.249898\n",
            "[Epoch 75/100] TF=1.00 | train MSE=0.012543 RMSE=0.111996 MAE=0.071728 | val MSE=0.116660 RMSE=0.341555 MAE=0.203164\n",
            "  >> Saved best model (val MSE=0.116660)\n",
            "[Epoch 76/100] TF=1.00 | train MSE=0.012470 RMSE=0.111667 MAE=0.071858 | val MSE=0.223131 RMSE=0.472367 MAE=0.284925\n",
            "[Epoch 77/100] TF=1.00 | train MSE=0.013189 RMSE=0.114844 MAE=0.075512 | val MSE=0.130382 RMSE=0.361084 MAE=0.226983\n",
            "[Epoch 78/100] TF=1.00 | train MSE=0.012183 RMSE=0.110375 MAE=0.070441 | val MSE=0.121225 RMSE=0.348174 MAE=0.214442\n",
            "[Epoch 79/100] TF=1.00 | train MSE=0.012220 RMSE=0.110544 MAE=0.070515 | val MSE=0.120284 RMSE=0.346820 MAE=0.209889\n",
            "[Epoch 80/100] TF=1.00 | train MSE=0.012500 RMSE=0.111803 MAE=0.071785 | val MSE=0.109680 RMSE=0.331179 MAE=0.201899\n",
            "  >> Saved best model (val MSE=0.109680)\n",
            "[Epoch 81/100] TF=1.00 | train MSE=0.011955 RMSE=0.109340 MAE=0.069315 | val MSE=0.126102 RMSE=0.355108 MAE=0.210251\n",
            "[Epoch 82/100] TF=1.00 | train MSE=0.012002 RMSE=0.109556 MAE=0.069766 | val MSE=0.114647 RMSE=0.338596 MAE=0.206243\n",
            "[Epoch 83/100] TF=1.00 | train MSE=0.012028 RMSE=0.109674 MAE=0.070096 | val MSE=0.155746 RMSE=0.394646 MAE=0.243713\n",
            "[Epoch 84/100] TF=1.00 | train MSE=0.012241 RMSE=0.110638 MAE=0.070819 | val MSE=0.132149 RMSE=0.363523 MAE=0.216082\n",
            "[Epoch 85/100] TF=1.00 | train MSE=0.011991 RMSE=0.109505 MAE=0.069663 | val MSE=0.164100 RMSE=0.405092 MAE=0.263456\n",
            "[Epoch 86/100] TF=1.00 | train MSE=0.012583 RMSE=0.112175 MAE=0.073050 | val MSE=0.159097 RMSE=0.398869 MAE=0.252897\n",
            "[Epoch 87/100] TF=1.00 | train MSE=0.012216 RMSE=0.110525 MAE=0.070897 | val MSE=0.144261 RMSE=0.379816 MAE=0.238773\n",
            "[Epoch 88/100] TF=1.00 | train MSE=0.011882 RMSE=0.109006 MAE=0.068914 | val MSE=0.093066 RMSE=0.305067 MAE=0.179378\n",
            "  >> Saved best model (val MSE=0.093066)\n",
            "[Epoch 89/100] TF=1.00 | train MSE=0.011821 RMSE=0.108723 MAE=0.069509 | val MSE=0.131536 RMSE=0.362679 MAE=0.221991\n",
            "[Epoch 90/100] TF=1.00 | train MSE=0.012766 RMSE=0.112987 MAE=0.073602 | val MSE=0.173872 RMSE=0.416980 MAE=0.266641\n",
            "[Epoch 91/100] TF=1.00 | train MSE=0.011895 RMSE=0.109064 MAE=0.069610 | val MSE=0.099435 RMSE=0.315333 MAE=0.189465\n",
            "[Epoch 92/100] TF=1.00 | train MSE=0.011663 RMSE=0.107997 MAE=0.068595 | val MSE=0.105669 RMSE=0.325068 MAE=0.196821\n",
            "[Epoch 93/100] TF=1.00 | train MSE=0.011654 RMSE=0.107954 MAE=0.068640 | val MSE=0.105710 RMSE=0.325130 MAE=0.194440\n",
            "[Epoch 94/100] TF=1.00 | train MSE=0.011749 RMSE=0.108392 MAE=0.069159 | val MSE=0.125149 RMSE=0.353764 MAE=0.217038\n",
            "[Epoch 95/100] TF=1.00 | train MSE=0.012388 RMSE=0.111303 MAE=0.072284 | val MSE=0.114830 RMSE=0.338865 MAE=0.206304\n",
            "[Epoch 96/100] TF=1.00 | train MSE=0.011939 RMSE=0.109266 MAE=0.070215 | val MSE=0.158605 RMSE=0.398253 MAE=0.239354\n",
            "[Epoch 97/100] TF=1.00 | train MSE=0.011583 RMSE=0.107624 MAE=0.068240 | val MSE=0.117413 RMSE=0.342656 MAE=0.212171\n",
            "[Epoch 98/100] TF=1.00 | train MSE=0.011807 RMSE=0.108658 MAE=0.069637 | val MSE=0.148384 RMSE=0.385207 MAE=0.229971\n",
            "[Epoch 99/100] TF=1.00 | train MSE=0.012136 RMSE=0.110165 MAE=0.071667 | val MSE=0.134131 RMSE=0.366239 MAE=0.235043\n",
            "[Epoch 100/100] TF=1.00 | train MSE=0.011831 RMSE=0.108771 MAE=0.069911 | val MSE=0.116812 RMSE=0.341778 MAE=0.205322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "GRaOs0EOSTYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### convgru"
      ],
      "metadata": {
        "id": "pspYcnceR_5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convgru_cfg = TrainConfig(\n",
        "    data_dir=\"./\",\n",
        "    max_epochs=100,\n",
        "    batch_size=2,\n",
        "    enc_cell_type=\"convgru\",\n",
        "    dec_cell_type=\"convgru\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=False,\n",
        "    unet_head=False,\n",
        "    out_root=\"./runs_wo_unet\",\n",
        "    viz_every_n_epochs=10,     # 每 10 个 epoch 可视化一次（train+eval）\n",
        "    viz_use_last_t=True,       # 可切换 False 以随机时间步\n",
        "    viz_channel=None,          # None=随机通道；也可设 0/1/2...\n",
        "    save_all_channels_png=True\n",
        ")\n",
        "convgru_model, convgru_history = train(convgru_cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11163b98-504c-47d6-d069-72dbd4613ff4",
        "id": "SkLwWKIhR_5O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据集总数: 119 | 训练集: 95 | 验证集: 24\n",
            "[Epoch 1/100] TF=1.00 | train MSE=0.222980 RMSE=0.472208 MAE=0.302870 | val MSE=0.263972 RMSE=0.513782 MAE=0.339584\n",
            "  >> Saved best model (val MSE=0.263972)\n",
            "[Epoch 2/100] TF=1.00 | train MSE=0.057572 RMSE=0.239941 MAE=0.157518 | val MSE=0.208743 RMSE=0.456884 MAE=0.298420\n",
            "  >> Saved best model (val MSE=0.208743)\n",
            "[Epoch 3/100] TF=1.00 | train MSE=0.038604 RMSE=0.196479 MAE=0.128045 | val MSE=0.192454 RMSE=0.438696 MAE=0.276414\n",
            "  >> Saved best model (val MSE=0.192454)\n",
            "[Epoch 4/100] TF=1.00 | train MSE=0.031092 RMSE=0.176328 MAE=0.113821 | val MSE=0.173346 RMSE=0.416349 MAE=0.257819\n",
            "  >> Saved best model (val MSE=0.173346)\n",
            "[Epoch 5/100] TF=1.00 | train MSE=0.027274 RMSE=0.165149 MAE=0.105648 | val MSE=0.171405 RMSE=0.414011 MAE=0.254026\n",
            "  >> Saved best model (val MSE=0.171405)\n",
            "[Epoch 6/100] TF=1.00 | train MSE=0.024840 RMSE=0.157607 MAE=0.100137 | val MSE=0.160515 RMSE=0.400644 MAE=0.248624\n",
            "  >> Saved best model (val MSE=0.160515)\n",
            "[Epoch 7/100] TF=1.00 | train MSE=0.023174 RMSE=0.152230 MAE=0.096113 | val MSE=0.161659 RMSE=0.402068 MAE=0.245926\n",
            "[Epoch 8/100] TF=1.00 | train MSE=0.022010 RMSE=0.148357 MAE=0.093340 | val MSE=0.149839 RMSE=0.387091 MAE=0.234716\n",
            "  >> Saved best model (val MSE=0.149839)\n",
            "[Epoch 9/100] TF=1.00 | train MSE=0.021119 RMSE=0.145323 MAE=0.090940 | val MSE=0.171662 RMSE=0.414321 MAE=0.247632\n",
            "[Epoch 10/100] TF=1.00 | train MSE=0.020408 RMSE=0.142858 MAE=0.089193 | val MSE=0.149027 RMSE=0.386040 MAE=0.233793\n",
            "  >> Saved best model (val MSE=0.149027)\n",
            "[Epoch 11/100] TF=1.00 | train MSE=0.019712 RMSE=0.140400 MAE=0.087164 | val MSE=0.156296 RMSE=0.395343 MAE=0.237986\n",
            "[Epoch 12/100] TF=1.00 | train MSE=0.019248 RMSE=0.138738 MAE=0.085853 | val MSE=0.147292 RMSE=0.383787 MAE=0.229512\n",
            "  >> Saved best model (val MSE=0.147292)\n",
            "[Epoch 13/100] TF=1.00 | train MSE=0.018822 RMSE=0.137194 MAE=0.084763 | val MSE=0.139278 RMSE=0.373200 MAE=0.224530\n",
            "  >> Saved best model (val MSE=0.139278)\n",
            "[Epoch 14/100] TF=1.00 | train MSE=0.018416 RMSE=0.135705 MAE=0.083471 | val MSE=0.150792 RMSE=0.388319 MAE=0.229308\n",
            "[Epoch 15/100] TF=1.00 | train MSE=0.018138 RMSE=0.134678 MAE=0.082723 | val MSE=0.148091 RMSE=0.384826 MAE=0.234640\n",
            "[Epoch 16/100] TF=1.00 | train MSE=0.017782 RMSE=0.133350 MAE=0.081731 | val MSE=0.133559 RMSE=0.365457 MAE=0.217645\n",
            "  >> Saved best model (val MSE=0.133559)\n",
            "[Epoch 17/100] TF=1.00 | train MSE=0.017548 RMSE=0.132470 MAE=0.081128 | val MSE=0.137159 RMSE=0.370349 MAE=0.224547\n",
            "[Epoch 18/100] TF=1.00 | train MSE=0.017264 RMSE=0.131392 MAE=0.080322 | val MSE=0.128516 RMSE=0.358492 MAE=0.217693\n",
            "  >> Saved best model (val MSE=0.128516)\n",
            "[Epoch 19/100] TF=1.00 | train MSE=0.017116 RMSE=0.130830 MAE=0.079912 | val MSE=0.146453 RMSE=0.382692 MAE=0.226707\n",
            "[Epoch 20/100] TF=1.00 | train MSE=0.016969 RMSE=0.130267 MAE=0.079581 | val MSE=0.129394 RMSE=0.359714 MAE=0.217017\n",
            "[Epoch 21/100] TF=1.00 | train MSE=0.016771 RMSE=0.129504 MAE=0.079107 | val MSE=0.143676 RMSE=0.379046 MAE=0.225837\n",
            "[Epoch 22/100] TF=1.00 | train MSE=0.016591 RMSE=0.128805 MAE=0.078406 | val MSE=0.156438 RMSE=0.395523 MAE=0.244600\n",
            "[Epoch 23/100] TF=1.00 | train MSE=0.016448 RMSE=0.128252 MAE=0.078089 | val MSE=0.122480 RMSE=0.349972 MAE=0.210739\n",
            "  >> Saved best model (val MSE=0.122480)\n",
            "[Epoch 24/100] TF=1.00 | train MSE=0.016295 RMSE=0.127650 MAE=0.077683 | val MSE=0.121638 RMSE=0.348766 MAE=0.207342\n",
            "  >> Saved best model (val MSE=0.121638)\n",
            "[Epoch 25/100] TF=1.00 | train MSE=0.016130 RMSE=0.127005 MAE=0.077196 | val MSE=0.124052 RMSE=0.352209 MAE=0.210884\n",
            "[Epoch 26/100] TF=1.00 | train MSE=0.015920 RMSE=0.126173 MAE=0.076555 | val MSE=0.134760 RMSE=0.367096 MAE=0.214851\n",
            "[Epoch 27/100] TF=1.00 | train MSE=0.015875 RMSE=0.125998 MAE=0.076688 | val MSE=0.120715 RMSE=0.347441 MAE=0.206491\n",
            "  >> Saved best model (val MSE=0.120715)\n",
            "[Epoch 28/100] TF=1.00 | train MSE=0.015777 RMSE=0.125607 MAE=0.076184 | val MSE=0.138834 RMSE=0.372604 MAE=0.218304\n",
            "[Epoch 29/100] TF=1.00 | train MSE=0.015642 RMSE=0.125068 MAE=0.075702 | val MSE=0.127129 RMSE=0.356551 MAE=0.206844\n",
            "[Epoch 30/100] TF=1.00 | train MSE=0.015505 RMSE=0.124517 MAE=0.075393 | val MSE=0.130745 RMSE=0.361587 MAE=0.212017\n",
            "[Epoch 31/100] TF=1.00 | train MSE=0.015426 RMSE=0.124200 MAE=0.075282 | val MSE=0.127260 RMSE=0.356736 MAE=0.207722\n",
            "[Epoch 32/100] TF=1.00 | train MSE=0.015307 RMSE=0.123723 MAE=0.074927 | val MSE=0.117852 RMSE=0.343295 MAE=0.200717\n",
            "  >> Saved best model (val MSE=0.117852)\n",
            "[Epoch 33/100] TF=1.00 | train MSE=0.015385 RMSE=0.124038 MAE=0.075149 | val MSE=0.131315 RMSE=0.362374 MAE=0.216885\n",
            "[Epoch 34/100] TF=1.00 | train MSE=0.015221 RMSE=0.123372 MAE=0.074691 | val MSE=0.124954 RMSE=0.353489 MAE=0.208844\n",
            "[Epoch 35/100] TF=1.00 | train MSE=0.015077 RMSE=0.122788 MAE=0.074140 | val MSE=0.124046 RMSE=0.352202 MAE=0.206729\n",
            "[Epoch 36/100] TF=1.00 | train MSE=0.014994 RMSE=0.122451 MAE=0.074059 | val MSE=0.125280 RMSE=0.353948 MAE=0.206874\n",
            "[Epoch 37/100] TF=1.00 | train MSE=0.014913 RMSE=0.122118 MAE=0.073724 | val MSE=0.115609 RMSE=0.340013 MAE=0.198242\n",
            "  >> Saved best model (val MSE=0.115609)\n",
            "[Epoch 38/100] TF=1.00 | train MSE=0.014953 RMSE=0.122281 MAE=0.074152 | val MSE=0.120447 RMSE=0.347055 MAE=0.202912\n",
            "[Epoch 39/100] TF=1.00 | train MSE=0.014785 RMSE=0.121594 MAE=0.073375 | val MSE=0.142307 RMSE=0.377236 MAE=0.221989\n",
            "[Epoch 40/100] TF=1.00 | train MSE=0.014798 RMSE=0.121649 MAE=0.073510 | val MSE=0.121247 RMSE=0.348206 MAE=0.208166\n",
            "[Epoch 41/100] TF=1.00 | train MSE=0.014755 RMSE=0.121471 MAE=0.073424 | val MSE=0.128830 RMSE=0.358929 MAE=0.204921\n",
            "[Epoch 42/100] TF=1.00 | train MSE=0.014571 RMSE=0.120710 MAE=0.072706 | val MSE=0.118017 RMSE=0.343536 MAE=0.200404\n",
            "[Epoch 43/100] TF=1.00 | train MSE=0.014525 RMSE=0.120521 MAE=0.072718 | val MSE=0.121697 RMSE=0.348850 MAE=0.205911\n",
            "[Epoch 44/100] TF=1.00 | train MSE=0.014623 RMSE=0.120927 MAE=0.072992 | val MSE=0.136843 RMSE=0.369923 MAE=0.214256\n",
            "[Epoch 45/100] TF=1.00 | train MSE=0.014545 RMSE=0.120603 MAE=0.072830 | val MSE=0.129229 RMSE=0.359485 MAE=0.213114\n",
            "[Epoch 46/100] TF=1.00 | train MSE=0.014424 RMSE=0.120101 MAE=0.072572 | val MSE=0.112128 RMSE=0.334855 MAE=0.198000\n",
            "  >> Saved best model (val MSE=0.112128)\n",
            "[Epoch 47/100] TF=1.00 | train MSE=0.014401 RMSE=0.120003 MAE=0.072351 | val MSE=0.117000 RMSE=0.342053 MAE=0.198847\n",
            "[Epoch 48/100] TF=1.00 | train MSE=0.014335 RMSE=0.119728 MAE=0.072144 | val MSE=0.120546 RMSE=0.347198 MAE=0.198716\n",
            "[Epoch 49/100] TF=1.00 | train MSE=0.014252 RMSE=0.119383 MAE=0.071899 | val MSE=0.135045 RMSE=0.367484 MAE=0.219192\n",
            "[Epoch 50/100] TF=1.00 | train MSE=0.014263 RMSE=0.119427 MAE=0.072053 | val MSE=0.121886 RMSE=0.349122 MAE=0.202346\n",
            "[Epoch 51/100] TF=1.00 | train MSE=0.014205 RMSE=0.119186 MAE=0.071912 | val MSE=0.117498 RMSE=0.342779 MAE=0.199806\n",
            "[Epoch 52/100] TF=1.00 | train MSE=0.014103 RMSE=0.118757 MAE=0.071638 | val MSE=0.128348 RMSE=0.358257 MAE=0.206850\n",
            "[Epoch 53/100] TF=1.00 | train MSE=0.014073 RMSE=0.118628 MAE=0.071490 | val MSE=0.131586 RMSE=0.362748 MAE=0.214680\n",
            "[Epoch 54/100] TF=1.00 | train MSE=0.014126 RMSE=0.118851 MAE=0.071732 | val MSE=0.121157 RMSE=0.348076 MAE=0.204492\n",
            "[Epoch 55/100] TF=1.00 | train MSE=0.014062 RMSE=0.118584 MAE=0.071457 | val MSE=0.115013 RMSE=0.339136 MAE=0.199384\n",
            "[Epoch 56/100] TF=1.00 | train MSE=0.013956 RMSE=0.118134 MAE=0.071175 | val MSE=0.125724 RMSE=0.354576 MAE=0.209059\n",
            "[Epoch 57/100] TF=1.00 | train MSE=0.013935 RMSE=0.118047 MAE=0.071084 | val MSE=0.126087 RMSE=0.355087 MAE=0.205694\n",
            "[Epoch 58/100] TF=1.00 | train MSE=0.013985 RMSE=0.118257 MAE=0.071293 | val MSE=0.150511 RMSE=0.387957 MAE=0.222136\n",
            "[Epoch 59/100] TF=1.00 | train MSE=0.013966 RMSE=0.118177 MAE=0.071436 | val MSE=0.109982 RMSE=0.331635 MAE=0.192007\n",
            "  >> Saved best model (val MSE=0.109982)\n",
            "[Epoch 60/100] TF=1.00 | train MSE=0.013817 RMSE=0.117547 MAE=0.070728 | val MSE=0.118533 RMSE=0.344286 MAE=0.201865\n",
            "[Epoch 61/100] TF=1.00 | train MSE=0.013884 RMSE=0.117831 MAE=0.071069 | val MSE=0.112388 RMSE=0.335244 MAE=0.196394\n",
            "[Epoch 62/100] TF=1.00 | train MSE=0.013797 RMSE=0.117462 MAE=0.070652 | val MSE=0.127774 RMSE=0.357455 MAE=0.206855\n",
            "[Epoch 63/100] TF=1.00 | train MSE=0.013829 RMSE=0.117599 MAE=0.070874 | val MSE=0.137536 RMSE=0.370859 MAE=0.214618\n",
            "[Epoch 64/100] TF=1.00 | train MSE=0.013756 RMSE=0.117286 MAE=0.070657 | val MSE=0.111576 RMSE=0.334030 MAE=0.192613\n",
            "[Epoch 65/100] TF=1.00 | train MSE=0.013696 RMSE=0.117031 MAE=0.070456 | val MSE=0.108500 RMSE=0.329394 MAE=0.188724\n",
            "  >> Saved best model (val MSE=0.108500)\n",
            "[Epoch 66/100] TF=1.00 | train MSE=0.013669 RMSE=0.116916 MAE=0.070424 | val MSE=0.117408 RMSE=0.342648 MAE=0.201438\n",
            "[Epoch 67/100] TF=1.00 | train MSE=0.013717 RMSE=0.117118 MAE=0.070662 | val MSE=0.126142 RMSE=0.355164 MAE=0.206331\n",
            "[Epoch 68/100] TF=1.00 | train MSE=0.013788 RMSE=0.117421 MAE=0.070879 | val MSE=0.117083 RMSE=0.342173 MAE=0.203431\n",
            "[Epoch 69/100] TF=1.00 | train MSE=0.013717 RMSE=0.117120 MAE=0.070739 | val MSE=0.125120 RMSE=0.353723 MAE=0.204667\n",
            "[Epoch 70/100] TF=1.00 | train MSE=0.013541 RMSE=0.116365 MAE=0.070027 | val MSE=0.124550 RMSE=0.352916 MAE=0.204521\n",
            "[Epoch 71/100] TF=1.00 | train MSE=0.013515 RMSE=0.116255 MAE=0.069932 | val MSE=0.141670 RMSE=0.376391 MAE=0.216610\n",
            "[Epoch 72/100] TF=1.00 | train MSE=0.013609 RMSE=0.116657 MAE=0.070351 | val MSE=0.109718 RMSE=0.331237 MAE=0.193587\n",
            "[Epoch 73/100] TF=1.00 | train MSE=0.013416 RMSE=0.115829 MAE=0.069675 | val MSE=0.117675 RMSE=0.343037 MAE=0.200992\n",
            "[Epoch 74/100] TF=1.00 | train MSE=0.013605 RMSE=0.116642 MAE=0.070278 | val MSE=0.122290 RMSE=0.349700 MAE=0.203122\n",
            "[Epoch 75/100] TF=1.00 | train MSE=0.013538 RMSE=0.116352 MAE=0.070095 | val MSE=0.106998 RMSE=0.327106 MAE=0.190677\n",
            "  >> Saved best model (val MSE=0.106998)\n",
            "[Epoch 76/100] TF=1.00 | train MSE=0.013367 RMSE=0.115615 MAE=0.069631 | val MSE=0.108294 RMSE=0.329081 MAE=0.191832\n",
            "[Epoch 77/100] TF=1.00 | train MSE=0.013410 RMSE=0.115803 MAE=0.069730 | val MSE=0.112657 RMSE=0.335645 MAE=0.196008\n",
            "[Epoch 78/100] TF=1.00 | train MSE=0.013451 RMSE=0.115977 MAE=0.069913 | val MSE=0.119659 RMSE=0.345917 MAE=0.201049\n",
            "[Epoch 79/100] TF=1.00 | train MSE=0.013360 RMSE=0.115586 MAE=0.069700 | val MSE=0.110046 RMSE=0.331733 MAE=0.192321\n",
            "[Epoch 80/100] TF=1.00 | train MSE=0.013368 RMSE=0.115619 MAE=0.069648 | val MSE=0.126946 RMSE=0.356295 MAE=0.204613\n",
            "[Epoch 81/100] TF=1.00 | train MSE=0.013371 RMSE=0.115634 MAE=0.069632 | val MSE=0.116590 RMSE=0.341453 MAE=0.199046\n",
            "[Epoch 82/100] TF=1.00 | train MSE=0.013349 RMSE=0.115536 MAE=0.069578 | val MSE=0.107564 RMSE=0.327970 MAE=0.188773\n",
            "[Epoch 83/100] TF=1.00 | train MSE=0.013227 RMSE=0.115007 MAE=0.069186 | val MSE=0.123593 RMSE=0.351557 MAE=0.204490\n",
            "[Epoch 84/100] TF=1.00 | train MSE=0.013271 RMSE=0.115199 MAE=0.069432 | val MSE=0.113958 RMSE=0.337576 MAE=0.195726\n",
            "[Epoch 85/100] TF=1.00 | train MSE=0.013199 RMSE=0.114886 MAE=0.069111 | val MSE=0.105925 RMSE=0.325461 MAE=0.188813\n",
            "  >> Saved best model (val MSE=0.105925)\n",
            "[Epoch 86/100] TF=1.00 | train MSE=0.013202 RMSE=0.114899 MAE=0.069266 | val MSE=0.118786 RMSE=0.344654 MAE=0.202358\n",
            "[Epoch 87/100] TF=1.00 | train MSE=0.013204 RMSE=0.114910 MAE=0.069230 | val MSE=0.117425 RMSE=0.342673 MAE=0.198316\n",
            "[Epoch 88/100] TF=1.00 | train MSE=0.013226 RMSE=0.115005 MAE=0.069308 | val MSE=0.109511 RMSE=0.330924 MAE=0.192149\n",
            "[Epoch 89/100] TF=1.00 | train MSE=0.013185 RMSE=0.114825 MAE=0.069254 | val MSE=0.107810 RMSE=0.328344 MAE=0.190398\n",
            "[Epoch 90/100] TF=1.00 | train MSE=0.013129 RMSE=0.114581 MAE=0.069023 | val MSE=0.110274 RMSE=0.332076 MAE=0.194687\n",
            "[Epoch 91/100] TF=1.00 | train MSE=0.013190 RMSE=0.114850 MAE=0.069321 | val MSE=0.116070 RMSE=0.340691 MAE=0.196135\n",
            "[Epoch 92/100] TF=1.00 | train MSE=0.013112 RMSE=0.114508 MAE=0.068997 | val MSE=0.106275 RMSE=0.325999 MAE=0.189816\n",
            "[Epoch 93/100] TF=1.00 | train MSE=0.013074 RMSE=0.114341 MAE=0.068817 | val MSE=0.107084 RMSE=0.327237 MAE=0.192457\n",
            "[Epoch 94/100] TF=1.00 | train MSE=0.013107 RMSE=0.114485 MAE=0.068916 | val MSE=0.116413 RMSE=0.341194 MAE=0.194589\n",
            "[Epoch 95/100] TF=1.00 | train MSE=0.013090 RMSE=0.114413 MAE=0.068981 | val MSE=0.141779 RMSE=0.376536 MAE=0.218106\n",
            "[Epoch 96/100] TF=1.00 | train MSE=0.013049 RMSE=0.114230 MAE=0.068751 | val MSE=0.107055 RMSE=0.327193 MAE=0.188658\n",
            "[Epoch 97/100] TF=1.00 | train MSE=0.013027 RMSE=0.114137 MAE=0.068712 | val MSE=0.107498 RMSE=0.327869 MAE=0.189393\n",
            "[Epoch 98/100] TF=1.00 | train MSE=0.013036 RMSE=0.114175 MAE=0.068779 | val MSE=0.114143 RMSE=0.337851 MAE=0.192805\n",
            "[Epoch 99/100] TF=1.00 | train MSE=0.012949 RMSE=0.113796 MAE=0.068427 | val MSE=0.107167 RMSE=0.327364 MAE=0.189918\n",
            "[Epoch 100/100] TF=1.00 | train MSE=0.012987 RMSE=0.113959 MAE=0.068598 | val MSE=0.105506 RMSE=0.324817 MAE=0.187454\n",
            "  >> Saved best model (val MSE=0.105506)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### convrnn"
      ],
      "metadata": {
        "id": "rZPwBELGR_5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convrnn_cfg = TrainConfig(\n",
        "    data_dir=\"./\",\n",
        "    max_epochs=100,\n",
        "    batch_size=2,\n",
        "    enc_cell_type=\"convrnn\",\n",
        "    dec_cell_type=\"convrnn\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=False,\n",
        "    unet_head=False,\n",
        "    out_root=\"./runs_wo_unet\",\n",
        "    viz_every_n_epochs=10,     # 每 10 个 epoch 可视化一次（train+eval）\n",
        "    viz_use_last_t=True,       # 可切换 False 以随机时间步\n",
        "    viz_channel=None,          # None=随机通道；也可设 0/1/2...\n",
        "    save_all_channels_png=True\n",
        ")\n",
        "convrnn_model, convrnn_history = train(convrnn_cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffcea6a5-0e78-4ba6-cf8e-3f134b4cd1f9",
        "id": "s6OdhQ62R_5O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据集总数: 119 | 训练集: 95 | 验证集: 24\n",
            "[Epoch 1/100] TF=1.00 | train MSE=0.228858 RMSE=0.478391 MAE=0.307553 | val MSE=0.278009 RMSE=0.527266 MAE=0.358716\n",
            "  >> Saved best model (val MSE=0.278009)\n",
            "[Epoch 2/100] TF=1.00 | train MSE=0.064741 RMSE=0.254443 MAE=0.168782 | val MSE=0.232402 RMSE=0.482081 MAE=0.305994\n",
            "  >> Saved best model (val MSE=0.232402)\n",
            "[Epoch 3/100] TF=1.00 | train MSE=0.045210 RMSE=0.212626 MAE=0.139613 | val MSE=0.218584 RMSE=0.467530 MAE=0.301286\n",
            "  >> Saved best model (val MSE=0.218584)\n",
            "[Epoch 4/100] TF=1.00 | train MSE=0.036992 RMSE=0.192334 MAE=0.124840 | val MSE=0.199810 RMSE=0.447001 MAE=0.282246\n",
            "  >> Saved best model (val MSE=0.199810)\n",
            "[Epoch 5/100] TF=1.00 | train MSE=0.032539 RMSE=0.180385 MAE=0.115509 | val MSE=0.189646 RMSE=0.435484 MAE=0.269302\n",
            "  >> Saved best model (val MSE=0.189646)\n",
            "[Epoch 6/100] TF=1.00 | train MSE=0.030017 RMSE=0.173254 MAE=0.109934 | val MSE=0.185114 RMSE=0.430249 MAE=0.265207\n",
            "  >> Saved best model (val MSE=0.185114)\n",
            "[Epoch 7/100] TF=1.00 | train MSE=0.028289 RMSE=0.168194 MAE=0.105632 | val MSE=0.180645 RMSE=0.425024 MAE=0.261414\n",
            "  >> Saved best model (val MSE=0.180645)\n",
            "[Epoch 8/100] TF=1.00 | train MSE=0.027080 RMSE=0.164559 MAE=0.102451 | val MSE=0.178563 RMSE=0.422567 MAE=0.261103\n",
            "  >> Saved best model (val MSE=0.178563)\n",
            "[Epoch 9/100] TF=1.00 | train MSE=0.026211 RMSE=0.161898 MAE=0.100050 | val MSE=0.178415 RMSE=0.422392 MAE=0.260433\n",
            "  >> Saved best model (val MSE=0.178415)\n",
            "[Epoch 10/100] TF=1.00 | train MSE=0.025547 RMSE=0.159834 MAE=0.098221 | val MSE=0.174310 RMSE=0.417505 MAE=0.257496\n",
            "  >> Saved best model (val MSE=0.174310)\n",
            "[Epoch 11/100] TF=1.00 | train MSE=0.024910 RMSE=0.157828 MAE=0.096223 | val MSE=0.169887 RMSE=0.412173 MAE=0.253140\n",
            "  >> Saved best model (val MSE=0.169887)\n",
            "[Epoch 12/100] TF=1.00 | train MSE=0.024497 RMSE=0.156515 MAE=0.094960 | val MSE=0.167983 RMSE=0.409857 MAE=0.252187\n",
            "  >> Saved best model (val MSE=0.167983)\n",
            "[Epoch 13/100] TF=1.00 | train MSE=0.024079 RMSE=0.155173 MAE=0.093634 | val MSE=0.164214 RMSE=0.405234 MAE=0.250294\n",
            "  >> Saved best model (val MSE=0.164214)\n",
            "[Epoch 14/100] TF=1.00 | train MSE=0.023801 RMSE=0.154275 MAE=0.092974 | val MSE=0.164578 RMSE=0.405682 MAE=0.248778\n",
            "[Epoch 15/100] TF=1.00 | train MSE=0.023484 RMSE=0.153246 MAE=0.092008 | val MSE=0.166430 RMSE=0.407958 MAE=0.253347\n",
            "[Epoch 16/100] TF=1.00 | train MSE=0.023281 RMSE=0.152580 MAE=0.091474 | val MSE=0.163502 RMSE=0.404353 MAE=0.245899\n",
            "  >> Saved best model (val MSE=0.163502)\n",
            "[Epoch 17/100] TF=1.00 | train MSE=0.023038 RMSE=0.151784 MAE=0.090655 | val MSE=0.161926 RMSE=0.402400 MAE=0.246566\n",
            "  >> Saved best model (val MSE=0.161926)\n",
            "[Epoch 18/100] TF=1.00 | train MSE=0.022872 RMSE=0.151235 MAE=0.090283 | val MSE=0.160605 RMSE=0.400756 MAE=0.248508\n",
            "  >> Saved best model (val MSE=0.160605)\n",
            "[Epoch 19/100] TF=1.00 | train MSE=0.022715 RMSE=0.150716 MAE=0.089812 | val MSE=0.170978 RMSE=0.413495 MAE=0.259662\n",
            "[Epoch 20/100] TF=1.00 | train MSE=0.022504 RMSE=0.150013 MAE=0.089243 | val MSE=0.156766 RMSE=0.395937 MAE=0.240805\n",
            "  >> Saved best model (val MSE=0.156766)\n",
            "[Epoch 21/100] TF=1.00 | train MSE=0.022341 RMSE=0.149470 MAE=0.088663 | val MSE=0.162285 RMSE=0.402846 MAE=0.248961\n",
            "[Epoch 22/100] TF=1.00 | train MSE=0.022206 RMSE=0.149018 MAE=0.088342 | val MSE=0.158260 RMSE=0.397820 MAE=0.243950\n",
            "[Epoch 23/100] TF=1.00 | train MSE=0.022092 RMSE=0.148635 MAE=0.088108 | val MSE=0.158925 RMSE=0.398654 MAE=0.248680\n",
            "[Epoch 24/100] TF=1.00 | train MSE=0.022016 RMSE=0.148378 MAE=0.088077 | val MSE=0.154115 RMSE=0.392574 MAE=0.242980\n",
            "  >> Saved best model (val MSE=0.154115)\n",
            "[Epoch 25/100] TF=1.00 | train MSE=0.021785 RMSE=0.147598 MAE=0.087318 | val MSE=0.152964 RMSE=0.391105 MAE=0.240327\n",
            "  >> Saved best model (val MSE=0.152964)\n",
            "[Epoch 26/100] TF=1.00 | train MSE=0.021672 RMSE=0.147215 MAE=0.087162 | val MSE=0.156816 RMSE=0.396000 MAE=0.239748\n",
            "[Epoch 27/100] TF=1.00 | train MSE=0.021638 RMSE=0.147098 MAE=0.087307 | val MSE=0.153180 RMSE=0.391382 MAE=0.239148\n",
            "[Epoch 28/100] TF=1.00 | train MSE=0.021425 RMSE=0.146372 MAE=0.086473 | val MSE=0.156659 RMSE=0.395802 MAE=0.242193\n",
            "[Epoch 29/100] TF=1.00 | train MSE=0.021280 RMSE=0.145876 MAE=0.085964 | val MSE=0.155779 RMSE=0.394689 MAE=0.241797\n",
            "[Epoch 30/100] TF=1.00 | train MSE=0.021174 RMSE=0.145512 MAE=0.085912 | val MSE=0.156921 RMSE=0.396133 MAE=0.244810\n",
            "[Epoch 31/100] TF=1.00 | train MSE=0.021031 RMSE=0.145022 MAE=0.085542 | val MSE=0.156296 RMSE=0.395343 MAE=0.240053\n",
            "[Epoch 32/100] TF=1.00 | train MSE=0.020927 RMSE=0.144661 MAE=0.085278 | val MSE=0.165068 RMSE=0.406286 MAE=0.248774\n",
            "[Epoch 33/100] TF=1.00 | train MSE=0.020858 RMSE=0.144422 MAE=0.085298 | val MSE=0.150660 RMSE=0.388149 MAE=0.236633\n",
            "  >> Saved best model (val MSE=0.150660)\n",
            "[Epoch 34/100] TF=1.00 | train MSE=0.020804 RMSE=0.144236 MAE=0.085352 | val MSE=0.166820 RMSE=0.408436 MAE=0.251167\n",
            "[Epoch 35/100] TF=1.00 | train MSE=0.020691 RMSE=0.143843 MAE=0.085267 | val MSE=0.159098 RMSE=0.398871 MAE=0.242475\n",
            "[Epoch 36/100] TF=1.00 | train MSE=0.020536 RMSE=0.143302 MAE=0.084679 | val MSE=0.150531 RMSE=0.387984 MAE=0.240406\n",
            "  >> Saved best model (val MSE=0.150531)\n",
            "[Epoch 37/100] TF=1.00 | train MSE=0.020387 RMSE=0.142781 MAE=0.084187 | val MSE=0.144677 RMSE=0.380364 MAE=0.230573\n",
            "  >> Saved best model (val MSE=0.144677)\n",
            "[Epoch 38/100] TF=1.00 | train MSE=0.020285 RMSE=0.142425 MAE=0.084085 | val MSE=0.151763 RMSE=0.389568 MAE=0.241370\n",
            "[Epoch 39/100] TF=1.00 | train MSE=0.020230 RMSE=0.142231 MAE=0.084032 | val MSE=0.155281 RMSE=0.394057 MAE=0.241221\n",
            "[Epoch 40/100] TF=1.00 | train MSE=0.020096 RMSE=0.141760 MAE=0.083751 | val MSE=0.142768 RMSE=0.377847 MAE=0.229229\n",
            "  >> Saved best model (val MSE=0.142768)\n",
            "[Epoch 41/100] TF=1.00 | train MSE=0.020060 RMSE=0.141633 MAE=0.083795 | val MSE=0.152645 RMSE=0.390698 MAE=0.238016\n",
            "[Epoch 42/100] TF=1.00 | train MSE=0.019943 RMSE=0.141220 MAE=0.083445 | val MSE=0.165752 RMSE=0.407127 MAE=0.247290\n",
            "[Epoch 43/100] TF=1.00 | train MSE=0.019876 RMSE=0.140981 MAE=0.083333 | val MSE=0.163520 RMSE=0.404375 MAE=0.249378\n",
            "[Epoch 44/100] TF=1.00 | train MSE=0.019810 RMSE=0.140747 MAE=0.083286 | val MSE=0.152041 RMSE=0.389924 MAE=0.236911\n",
            "[Epoch 45/100] TF=1.00 | train MSE=0.019711 RMSE=0.140396 MAE=0.083101 | val MSE=0.161377 RMSE=0.401717 MAE=0.245315\n",
            "[Epoch 46/100] TF=1.00 | train MSE=0.019667 RMSE=0.140240 MAE=0.083285 | val MSE=0.166550 RMSE=0.408105 MAE=0.256110\n",
            "[Epoch 47/100] TF=1.00 | train MSE=0.019507 RMSE=0.139667 MAE=0.082664 | val MSE=0.158658 RMSE=0.398319 MAE=0.241224\n",
            "[Epoch 48/100] TF=1.00 | train MSE=0.019377 RMSE=0.139202 MAE=0.082172 | val MSE=0.167529 RMSE=0.409303 MAE=0.251368\n",
            "[Epoch 49/100] TF=1.00 | train MSE=0.019281 RMSE=0.138857 MAE=0.081869 | val MSE=0.148066 RMSE=0.384793 MAE=0.233115\n",
            "[Epoch 50/100] TF=1.00 | train MSE=0.019275 RMSE=0.138834 MAE=0.082032 | val MSE=0.150272 RMSE=0.387650 MAE=0.237113\n",
            "[Epoch 51/100] TF=1.00 | train MSE=0.019216 RMSE=0.138623 MAE=0.081926 | val MSE=0.154342 RMSE=0.392864 MAE=0.238887\n",
            "[Epoch 52/100] TF=1.00 | train MSE=0.019235 RMSE=0.138691 MAE=0.082147 | val MSE=0.160543 RMSE=0.400679 MAE=0.258899\n",
            "[Epoch 53/100] TF=1.00 | train MSE=0.019092 RMSE=0.138174 MAE=0.081813 | val MSE=0.159855 RMSE=0.399819 MAE=0.243198\n",
            "[Epoch 54/100] TF=1.00 | train MSE=0.019040 RMSE=0.137987 MAE=0.081766 | val MSE=0.159747 RMSE=0.399684 MAE=0.244824\n",
            "[Epoch 55/100] TF=1.00 | train MSE=0.019103 RMSE=0.138212 MAE=0.082071 | val MSE=0.150588 RMSE=0.388057 MAE=0.236049\n",
            "[Epoch 56/100] TF=1.00 | train MSE=0.019017 RMSE=0.137901 MAE=0.081898 | val MSE=0.157996 RMSE=0.397488 MAE=0.239087\n",
            "[Epoch 57/100] TF=1.00 | train MSE=0.018898 RMSE=0.137471 MAE=0.081376 | val MSE=0.164898 RMSE=0.406076 MAE=0.248070\n",
            "[Epoch 58/100] TF=1.00 | train MSE=0.018792 RMSE=0.137082 MAE=0.080879 | val MSE=0.143887 RMSE=0.379324 MAE=0.230710\n",
            "[Epoch 59/100] TF=1.00 | train MSE=0.018775 RMSE=0.137021 MAE=0.080935 | val MSE=0.142822 RMSE=0.377917 MAE=0.228041\n",
            "[Epoch 60/100] TF=1.00 | train MSE=0.018651 RMSE=0.136569 MAE=0.080665 | val MSE=0.152447 RMSE=0.390445 MAE=0.245645\n",
            "[Epoch 61/100] TF=1.00 | train MSE=0.018665 RMSE=0.136622 MAE=0.080645 | val MSE=0.153032 RMSE=0.391193 MAE=0.240208\n",
            "[Epoch 62/100] TF=1.00 | train MSE=0.018635 RMSE=0.136509 MAE=0.080628 | val MSE=0.142026 RMSE=0.376863 MAE=0.234604\n",
            "  >> Saved best model (val MSE=0.142026)\n",
            "[Epoch 63/100] TF=1.00 | train MSE=0.018558 RMSE=0.136227 MAE=0.080497 | val MSE=0.186608 RMSE=0.431982 MAE=0.262450\n",
            "[Epoch 64/100] TF=1.00 | train MSE=0.018463 RMSE=0.135880 MAE=0.080017 | val MSE=0.136510 RMSE=0.369473 MAE=0.223194\n",
            "  >> Saved best model (val MSE=0.136510)\n",
            "[Epoch 65/100] TF=1.00 | train MSE=0.018537 RMSE=0.136150 MAE=0.080592 | val MSE=0.140184 RMSE=0.374412 MAE=0.228495\n",
            "[Epoch 66/100] TF=1.00 | train MSE=0.018419 RMSE=0.135715 MAE=0.080173 | val MSE=0.146458 RMSE=0.382698 MAE=0.237358\n",
            "[Epoch 67/100] TF=1.00 | train MSE=0.018417 RMSE=0.135708 MAE=0.080061 | val MSE=0.149554 RMSE=0.386722 MAE=0.236348\n",
            "[Epoch 68/100] TF=1.00 | train MSE=0.018325 RMSE=0.135371 MAE=0.079827 | val MSE=0.153087 RMSE=0.391263 MAE=0.235603\n",
            "[Epoch 69/100] TF=1.00 | train MSE=0.018259 RMSE=0.135127 MAE=0.079510 | val MSE=0.143107 RMSE=0.378295 MAE=0.223831\n",
            "[Epoch 70/100] TF=1.00 | train MSE=0.018196 RMSE=0.134894 MAE=0.079340 | val MSE=0.138880 RMSE=0.372666 MAE=0.225395\n",
            "[Epoch 71/100] TF=1.00 | train MSE=0.018170 RMSE=0.134795 MAE=0.079372 | val MSE=0.142732 RMSE=0.377800 MAE=0.225874\n",
            "[Epoch 72/100] TF=1.00 | train MSE=0.018179 RMSE=0.134828 MAE=0.079429 | val MSE=0.145500 RMSE=0.381444 MAE=0.229999\n",
            "[Epoch 73/100] TF=1.00 | train MSE=0.018165 RMSE=0.134779 MAE=0.079384 | val MSE=0.140477 RMSE=0.374803 MAE=0.227000\n",
            "[Epoch 74/100] TF=1.00 | train MSE=0.018175 RMSE=0.134813 MAE=0.079678 | val MSE=0.170789 RMSE=0.413267 MAE=0.250477\n",
            "[Epoch 75/100] TF=1.00 | train MSE=0.018086 RMSE=0.134486 MAE=0.079346 | val MSE=0.137732 RMSE=0.371123 MAE=0.222837\n",
            "[Epoch 76/100] TF=1.00 | train MSE=0.018021 RMSE=0.134244 MAE=0.078916 | val MSE=0.140439 RMSE=0.374752 MAE=0.228551\n",
            "[Epoch 77/100] TF=1.00 | train MSE=0.018036 RMSE=0.134297 MAE=0.079135 | val MSE=0.160877 RMSE=0.401095 MAE=0.240965\n",
            "[Epoch 78/100] TF=1.00 | train MSE=0.018027 RMSE=0.134265 MAE=0.079225 | val MSE=0.142180 RMSE=0.377067 MAE=0.224954\n",
            "[Epoch 79/100] TF=1.00 | train MSE=0.017914 RMSE=0.133842 MAE=0.078775 | val MSE=0.135019 RMSE=0.367450 MAE=0.221412\n",
            "  >> Saved best model (val MSE=0.135019)\n",
            "[Epoch 80/100] TF=1.00 | train MSE=0.017958 RMSE=0.134009 MAE=0.079041 | val MSE=0.143274 RMSE=0.378516 MAE=0.231804\n",
            "[Epoch 81/100] TF=1.00 | train MSE=0.017819 RMSE=0.133488 MAE=0.078513 | val MSE=0.143416 RMSE=0.378703 MAE=0.227877\n",
            "[Epoch 82/100] TF=1.00 | train MSE=0.017810 RMSE=0.133452 MAE=0.078416 | val MSE=0.136624 RMSE=0.369627 MAE=0.222395\n",
            "[Epoch 83/100] TF=1.00 | train MSE=0.017823 RMSE=0.133504 MAE=0.078668 | val MSE=0.140305 RMSE=0.374573 MAE=0.231270\n",
            "[Epoch 84/100] TF=1.00 | train MSE=0.017810 RMSE=0.133455 MAE=0.078636 | val MSE=0.131342 RMSE=0.362412 MAE=0.216635\n",
            "  >> Saved best model (val MSE=0.131342)\n",
            "[Epoch 85/100] TF=1.00 | train MSE=0.017776 RMSE=0.133327 MAE=0.078596 | val MSE=0.156918 RMSE=0.396129 MAE=0.240440\n",
            "[Epoch 86/100] TF=1.00 | train MSE=0.017777 RMSE=0.133331 MAE=0.078558 | val MSE=0.148964 RMSE=0.385959 MAE=0.232991\n",
            "[Epoch 87/100] TF=1.00 | train MSE=0.017762 RMSE=0.133275 MAE=0.078649 | val MSE=0.144783 RMSE=0.380504 MAE=0.231941\n",
            "[Epoch 88/100] TF=1.00 | train MSE=0.017759 RMSE=0.133264 MAE=0.078489 | val MSE=0.147593 RMSE=0.384179 MAE=0.231704\n",
            "[Epoch 89/100] TF=1.00 | train MSE=0.017662 RMSE=0.132899 MAE=0.078049 | val MSE=0.159921 RMSE=0.399902 MAE=0.240000\n",
            "[Epoch 90/100] TF=1.00 | train MSE=0.017729 RMSE=0.133149 MAE=0.078603 | val MSE=0.132286 RMSE=0.363712 MAE=0.218986\n",
            "[Epoch 91/100] TF=1.00 | train MSE=0.017653 RMSE=0.132864 MAE=0.078309 | val MSE=0.143305 RMSE=0.378556 MAE=0.231711\n",
            "[Epoch 92/100] TF=1.00 | train MSE=0.017567 RMSE=0.132542 MAE=0.078055 | val MSE=0.152610 RMSE=0.390654 MAE=0.233750\n",
            "[Epoch 93/100] TF=1.00 | train MSE=0.017581 RMSE=0.132594 MAE=0.078017 | val MSE=0.165531 RMSE=0.406856 MAE=0.239571\n",
            "[Epoch 94/100] TF=1.00 | train MSE=0.017606 RMSE=0.132686 MAE=0.078276 | val MSE=0.134002 RMSE=0.366062 MAE=0.216774\n",
            "[Epoch 95/100] TF=1.00 | train MSE=0.017485 RMSE=0.132229 MAE=0.077753 | val MSE=0.127122 RMSE=0.356541 MAE=0.210617\n",
            "  >> Saved best model (val MSE=0.127122)\n",
            "[Epoch 96/100] TF=1.00 | train MSE=0.017535 RMSE=0.132419 MAE=0.077946 | val MSE=0.132440 RMSE=0.363922 MAE=0.217698\n",
            "[Epoch 97/100] TF=1.00 | train MSE=0.017530 RMSE=0.132402 MAE=0.078085 | val MSE=0.133559 RMSE=0.365458 MAE=0.222334\n",
            "[Epoch 98/100] TF=1.00 | train MSE=0.017434 RMSE=0.132039 MAE=0.077645 | val MSE=0.141545 RMSE=0.376224 MAE=0.230418\n",
            "[Epoch 99/100] TF=1.00 | train MSE=0.017589 RMSE=0.132622 MAE=0.078293 | val MSE=0.146917 RMSE=0.383298 MAE=0.238651\n",
            "[Epoch 100/100] TF=1.00 | train MSE=0.017405 RMSE=0.131928 MAE=0.077494 | val MSE=0.132830 RMSE=0.364459 MAE=0.218164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### convlstm"
      ],
      "metadata": {
        "id": "VikW1yNcR_5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convlstm_cfg = TrainConfig(\n",
        "    data_dir=\"./\",\n",
        "    max_epochs=100,\n",
        "    batch_size=2,\n",
        "    enc_cell_type=\"convlstm\",\n",
        "    dec_cell_type=\"convlstm\",\n",
        "    n_enc_layers=1,\n",
        "    n_dec_layers=1,\n",
        "    enable_tf_ratio=False,\n",
        "    layernorm=True,\n",
        "    peephole=True,\n",
        "    unet_head=False,\n",
        "    out_root=\"./runs_wo_unet\",\n",
        "    viz_every_n_epochs=10,     # 每 10 个 epoch 可视化一次（train+eval）\n",
        "    viz_use_last_t=True,       # 可切换 False 以随机时间步\n",
        "    viz_channel=None,          # None=随机通道；也可设 0/1/2...\n",
        "    save_all_channels_png=True\n",
        ")\n",
        "convlstm_model, convlstm_history = train(convlstm_cfg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58743a0-4276-485d-b06d-732c3f8b66b6",
        "id": "nhimCWbaR_5O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据集总数: 119 | 训练集: 95 | 验证集: 24\n",
            "[Epoch 1/100] TF=1.00 | train MSE=0.340915 RMSE=0.583879 MAE=0.405214 | val MSE=0.292421 RMSE=0.540759 MAE=0.365355\n",
            "  >> Saved best model (val MSE=0.292421)\n",
            "[Epoch 2/100] TF=1.00 | train MSE=0.106657 RMSE=0.326584 MAE=0.219064 | val MSE=0.225298 RMSE=0.474655 MAE=0.310597\n",
            "  >> Saved best model (val MSE=0.225298)\n",
            "[Epoch 3/100] TF=1.00 | train MSE=0.051899 RMSE=0.227814 MAE=0.151023 | val MSE=0.199800 RMSE=0.446990 MAE=0.279797\n",
            "  >> Saved best model (val MSE=0.199800)\n",
            "[Epoch 4/100] TF=1.00 | train MSE=0.037465 RMSE=0.193560 MAE=0.126202 | val MSE=0.186121 RMSE=0.431418 MAE=0.268888\n",
            "  >> Saved best model (val MSE=0.186121)\n",
            "[Epoch 5/100] TF=1.00 | train MSE=0.031833 RMSE=0.178417 MAE=0.114850 | val MSE=0.179173 RMSE=0.423288 MAE=0.259909\n",
            "  >> Saved best model (val MSE=0.179173)\n",
            "[Epoch 6/100] TF=1.00 | train MSE=0.028764 RMSE=0.169599 MAE=0.108098 | val MSE=0.181497 RMSE=0.426025 MAE=0.260744\n",
            "[Epoch 7/100] TF=1.00 | train MSE=0.026688 RMSE=0.163364 MAE=0.103066 | val MSE=0.170111 RMSE=0.412445 MAE=0.250048\n",
            "  >> Saved best model (val MSE=0.170111)\n",
            "[Epoch 8/100] TF=1.00 | train MSE=0.025226 RMSE=0.158827 MAE=0.099540 | val MSE=0.158030 RMSE=0.397530 MAE=0.240957\n",
            "  >> Saved best model (val MSE=0.158030)\n",
            "[Epoch 9/100] TF=1.00 | train MSE=0.024178 RMSE=0.155493 MAE=0.097044 | val MSE=0.164786 RMSE=0.405939 MAE=0.247275\n",
            "[Epoch 10/100] TF=1.00 | train MSE=0.023291 RMSE=0.152613 MAE=0.094768 | val MSE=0.153678 RMSE=0.392017 MAE=0.235594\n",
            "  >> Saved best model (val MSE=0.153678)\n",
            "[Epoch 11/100] TF=1.00 | train MSE=0.022599 RMSE=0.150330 MAE=0.093021 | val MSE=0.152450 RMSE=0.390448 MAE=0.233965\n",
            "  >> Saved best model (val MSE=0.152450)\n",
            "[Epoch 12/100] TF=1.00 | train MSE=0.021995 RMSE=0.148307 MAE=0.091441 | val MSE=0.145911 RMSE=0.381983 MAE=0.229079\n",
            "  >> Saved best model (val MSE=0.145911)\n",
            "[Epoch 13/100] TF=1.00 | train MSE=0.021545 RMSE=0.146783 MAE=0.090305 | val MSE=0.147646 RMSE=0.384248 MAE=0.229089\n",
            "[Epoch 14/100] TF=1.00 | train MSE=0.021076 RMSE=0.145177 MAE=0.089160 | val MSE=0.149354 RMSE=0.386464 MAE=0.232811\n",
            "[Epoch 15/100] TF=1.00 | train MSE=0.020688 RMSE=0.143832 MAE=0.088139 | val MSE=0.144198 RMSE=0.379734 MAE=0.225699\n",
            "  >> Saved best model (val MSE=0.144198)\n",
            "[Epoch 16/100] TF=1.00 | train MSE=0.020306 RMSE=0.142498 MAE=0.087065 | val MSE=0.137770 RMSE=0.371174 MAE=0.219527\n",
            "  >> Saved best model (val MSE=0.137770)\n",
            "[Epoch 17/100] TF=1.00 | train MSE=0.020007 RMSE=0.141447 MAE=0.086289 | val MSE=0.136752 RMSE=0.369800 MAE=0.218284\n",
            "  >> Saved best model (val MSE=0.136752)\n",
            "[Epoch 18/100] TF=1.00 | train MSE=0.019714 RMSE=0.140406 MAE=0.085470 | val MSE=0.135253 RMSE=0.367767 MAE=0.216740\n",
            "  >> Saved best model (val MSE=0.135253)\n",
            "[Epoch 19/100] TF=1.00 | train MSE=0.019372 RMSE=0.139183 MAE=0.084431 | val MSE=0.141814 RMSE=0.376582 MAE=0.222091\n",
            "[Epoch 20/100] TF=1.00 | train MSE=0.019119 RMSE=0.138271 MAE=0.083700 | val MSE=0.137577 RMSE=0.370913 MAE=0.218481\n",
            "[Epoch 21/100] TF=1.00 | train MSE=0.018911 RMSE=0.137516 MAE=0.083155 | val MSE=0.144806 RMSE=0.380534 MAE=0.224241\n",
            "[Epoch 22/100] TF=1.00 | train MSE=0.018674 RMSE=0.136651 MAE=0.082520 | val MSE=0.132129 RMSE=0.363495 MAE=0.213646\n",
            "  >> Saved best model (val MSE=0.132129)\n",
            "[Epoch 23/100] TF=1.00 | train MSE=0.018483 RMSE=0.135952 MAE=0.081953 | val MSE=0.142116 RMSE=0.376982 MAE=0.222601\n",
            "[Epoch 24/100] TF=1.00 | train MSE=0.018346 RMSE=0.135447 MAE=0.081662 | val MSE=0.132560 RMSE=0.364088 MAE=0.223650\n",
            "[Epoch 25/100] TF=1.00 | train MSE=0.018156 RMSE=0.134744 MAE=0.081185 | val MSE=0.133759 RMSE=0.365730 MAE=0.214052\n",
            "[Epoch 26/100] TF=1.00 | train MSE=0.017996 RMSE=0.134150 MAE=0.080735 | val MSE=0.133012 RMSE=0.364708 MAE=0.215540\n",
            "[Epoch 27/100] TF=1.00 | train MSE=0.017884 RMSE=0.133731 MAE=0.080564 | val MSE=0.130760 RMSE=0.361608 MAE=0.217432\n",
            "  >> Saved best model (val MSE=0.130760)\n",
            "[Epoch 28/100] TF=1.00 | train MSE=0.017752 RMSE=0.133238 MAE=0.080171 | val MSE=0.137798 RMSE=0.371211 MAE=0.216145\n",
            "[Epoch 29/100] TF=1.00 | train MSE=0.017623 RMSE=0.132751 MAE=0.079749 | val MSE=0.132329 RMSE=0.363771 MAE=0.209506\n",
            "[Epoch 30/100] TF=1.00 | train MSE=0.017513 RMSE=0.132337 MAE=0.079431 | val MSE=0.134941 RMSE=0.367343 MAE=0.216017\n",
            "[Epoch 31/100] TF=1.00 | train MSE=0.017304 RMSE=0.131545 MAE=0.078923 | val MSE=0.135275 RMSE=0.367797 MAE=0.215446\n",
            "[Epoch 32/100] TF=1.00 | train MSE=0.017202 RMSE=0.131156 MAE=0.078637 | val MSE=0.127989 RMSE=0.357756 MAE=0.207407\n",
            "  >> Saved best model (val MSE=0.127989)\n",
            "[Epoch 33/100] TF=1.00 | train MSE=0.017043 RMSE=0.130549 MAE=0.078184 | val MSE=0.131282 RMSE=0.362328 MAE=0.213703\n",
            "[Epoch 34/100] TF=1.00 | train MSE=0.016968 RMSE=0.130261 MAE=0.078089 | val MSE=0.126845 RMSE=0.356153 MAE=0.207872\n",
            "  >> Saved best model (val MSE=0.126845)\n",
            "[Epoch 35/100] TF=1.00 | train MSE=0.016929 RMSE=0.130113 MAE=0.077987 | val MSE=0.121905 RMSE=0.349149 MAE=0.201529\n",
            "  >> Saved best model (val MSE=0.121905)\n",
            "[Epoch 36/100] TF=1.00 | train MSE=0.016821 RMSE=0.129695 MAE=0.077754 | val MSE=0.130741 RMSE=0.361582 MAE=0.214049\n",
            "[Epoch 37/100] TF=1.00 | train MSE=0.016704 RMSE=0.129245 MAE=0.077366 | val MSE=0.124704 RMSE=0.353135 MAE=0.202712\n",
            "[Epoch 38/100] TF=1.00 | train MSE=0.016610 RMSE=0.128879 MAE=0.077140 | val MSE=0.127348 RMSE=0.356858 MAE=0.205808\n",
            "[Epoch 39/100] TF=1.00 | train MSE=0.016531 RMSE=0.128573 MAE=0.076980 | val MSE=0.129560 RMSE=0.359945 MAE=0.207373\n",
            "[Epoch 40/100] TF=1.00 | train MSE=0.016431 RMSE=0.128182 MAE=0.076677 | val MSE=0.118131 RMSE=0.343701 MAE=0.198351\n",
            "  >> Saved best model (val MSE=0.118131)\n",
            "[Epoch 41/100] TF=1.00 | train MSE=0.016344 RMSE=0.127845 MAE=0.076409 | val MSE=0.136164 RMSE=0.369004 MAE=0.216911\n",
            "[Epoch 42/100] TF=1.00 | train MSE=0.016350 RMSE=0.127866 MAE=0.076697 | val MSE=0.130479 RMSE=0.361219 MAE=0.205247\n",
            "[Epoch 43/100] TF=1.00 | train MSE=0.016215 RMSE=0.127337 MAE=0.076269 | val MSE=0.121078 RMSE=0.347963 MAE=0.202322\n",
            "[Epoch 44/100] TF=1.00 | train MSE=0.016141 RMSE=0.127047 MAE=0.075970 | val MSE=0.124554 RMSE=0.352922 MAE=0.203860\n",
            "[Epoch 45/100] TF=1.00 | train MSE=0.016031 RMSE=0.126614 MAE=0.075593 | val MSE=0.117192 RMSE=0.342334 MAE=0.196878\n",
            "  >> Saved best model (val MSE=0.117192)\n",
            "[Epoch 46/100] TF=1.00 | train MSE=0.015954 RMSE=0.126308 MAE=0.075437 | val MSE=0.119671 RMSE=0.345935 MAE=0.201595\n",
            "[Epoch 47/100] TF=1.00 | train MSE=0.015933 RMSE=0.126225 MAE=0.075460 | val MSE=0.131660 RMSE=0.362849 MAE=0.209498\n",
            "[Epoch 48/100] TF=1.00 | train MSE=0.015877 RMSE=0.126005 MAE=0.075231 | val MSE=0.119186 RMSE=0.345233 MAE=0.200861\n",
            "[Epoch 49/100] TF=1.00 | train MSE=0.015780 RMSE=0.125617 MAE=0.074988 | val MSE=0.141192 RMSE=0.375756 MAE=0.217609\n",
            "[Epoch 50/100] TF=1.00 | train MSE=0.015771 RMSE=0.125583 MAE=0.075101 | val MSE=0.122753 RMSE=0.350362 MAE=0.205219\n",
            "[Epoch 51/100] TF=1.00 | train MSE=0.015612 RMSE=0.124950 MAE=0.074509 | val MSE=0.118738 RMSE=0.344584 MAE=0.198738\n",
            "[Epoch 52/100] TF=1.00 | train MSE=0.015683 RMSE=0.125232 MAE=0.075093 | val MSE=0.122814 RMSE=0.350449 MAE=0.203544\n",
            "[Epoch 53/100] TF=1.00 | train MSE=0.015537 RMSE=0.124647 MAE=0.074414 | val MSE=0.128494 RMSE=0.358461 MAE=0.210297\n",
            "[Epoch 54/100] TF=1.00 | train MSE=0.015478 RMSE=0.124411 MAE=0.074272 | val MSE=0.123078 RMSE=0.350825 MAE=0.203147\n",
            "[Epoch 55/100] TF=1.00 | train MSE=0.015485 RMSE=0.124440 MAE=0.074358 | val MSE=0.135497 RMSE=0.368099 MAE=0.215707\n",
            "[Epoch 56/100] TF=1.00 | train MSE=0.015436 RMSE=0.124241 MAE=0.074274 | val MSE=0.121028 RMSE=0.347891 MAE=0.201129\n",
            "[Epoch 57/100] TF=1.00 | train MSE=0.015325 RMSE=0.123794 MAE=0.073865 | val MSE=0.120875 RMSE=0.347670 MAE=0.202297\n",
            "[Epoch 58/100] TF=1.00 | train MSE=0.015321 RMSE=0.123777 MAE=0.073850 | val MSE=0.125071 RMSE=0.353654 MAE=0.203594\n",
            "[Epoch 59/100] TF=1.00 | train MSE=0.015209 RMSE=0.123326 MAE=0.073500 | val MSE=0.116202 RMSE=0.340883 MAE=0.195277\n",
            "  >> Saved best model (val MSE=0.116202)\n",
            "[Epoch 60/100] TF=1.00 | train MSE=0.015202 RMSE=0.123296 MAE=0.073554 | val MSE=0.122474 RMSE=0.349963 MAE=0.203218\n",
            "[Epoch 61/100] TF=1.00 | train MSE=0.015179 RMSE=0.123203 MAE=0.073521 | val MSE=0.126457 RMSE=0.355608 MAE=0.202017\n",
            "[Epoch 62/100] TF=1.00 | train MSE=0.015174 RMSE=0.123182 MAE=0.073509 | val MSE=0.127835 RMSE=0.357540 MAE=0.203875\n",
            "[Epoch 63/100] TF=1.00 | train MSE=0.015095 RMSE=0.122863 MAE=0.073338 | val MSE=0.121265 RMSE=0.348231 MAE=0.203619\n",
            "[Epoch 64/100] TF=1.00 | train MSE=0.015049 RMSE=0.122676 MAE=0.073189 | val MSE=0.118438 RMSE=0.344149 MAE=0.200530\n",
            "[Epoch 65/100] TF=1.00 | train MSE=0.014976 RMSE=0.122375 MAE=0.072944 | val MSE=0.116555 RMSE=0.341402 MAE=0.196499\n",
            "[Epoch 66/100] TF=1.00 | train MSE=0.014937 RMSE=0.122217 MAE=0.072812 | val MSE=0.119816 RMSE=0.346144 MAE=0.203984\n",
            "[Epoch 67/100] TF=1.00 | train MSE=0.014876 RMSE=0.121968 MAE=0.072581 | val MSE=0.123592 RMSE=0.351557 MAE=0.201148\n",
            "[Epoch 68/100] TF=1.00 | train MSE=0.014851 RMSE=0.121865 MAE=0.072571 | val MSE=0.122091 RMSE=0.349415 MAE=0.200738\n",
            "[Epoch 69/100] TF=1.00 | train MSE=0.014778 RMSE=0.121564 MAE=0.072298 | val MSE=0.113074 RMSE=0.336265 MAE=0.192223\n",
            "  >> Saved best model (val MSE=0.113074)\n",
            "[Epoch 70/100] TF=1.00 | train MSE=0.014771 RMSE=0.121537 MAE=0.072306 | val MSE=0.120892 RMSE=0.347695 MAE=0.199772\n",
            "[Epoch 71/100] TF=1.00 | train MSE=0.014752 RMSE=0.121458 MAE=0.072300 | val MSE=0.132171 RMSE=0.363553 MAE=0.210833\n",
            "[Epoch 72/100] TF=1.00 | train MSE=0.014809 RMSE=0.121693 MAE=0.072498 | val MSE=0.122526 RMSE=0.350037 MAE=0.202946\n",
            "[Epoch 73/100] TF=1.00 | train MSE=0.014681 RMSE=0.121164 MAE=0.072121 | val MSE=0.132887 RMSE=0.364537 MAE=0.208636\n",
            "[Epoch 74/100] TF=1.00 | train MSE=0.014809 RMSE=0.121691 MAE=0.072584 | val MSE=0.119672 RMSE=0.345936 MAE=0.197797\n",
            "[Epoch 75/100] TF=1.00 | train MSE=0.014597 RMSE=0.120817 MAE=0.071876 | val MSE=0.121580 RMSE=0.348683 MAE=0.199736\n",
            "[Epoch 76/100] TF=1.00 | train MSE=0.014543 RMSE=0.120593 MAE=0.071676 | val MSE=0.118328 RMSE=0.343988 MAE=0.198543\n",
            "[Epoch 77/100] TF=1.00 | train MSE=0.014510 RMSE=0.120456 MAE=0.071669 | val MSE=0.118850 RMSE=0.344746 MAE=0.197286\n",
            "[Epoch 78/100] TF=1.00 | train MSE=0.014553 RMSE=0.120637 MAE=0.071804 | val MSE=0.119088 RMSE=0.345092 MAE=0.200302\n",
            "[Epoch 79/100] TF=1.00 | train MSE=0.014488 RMSE=0.120366 MAE=0.071671 | val MSE=0.118028 RMSE=0.343551 MAE=0.197922\n",
            "[Epoch 80/100] TF=1.00 | train MSE=0.014428 RMSE=0.120117 MAE=0.071400 | val MSE=0.116931 RMSE=0.341952 MAE=0.199850\n",
            "[Epoch 81/100] TF=1.00 | train MSE=0.014427 RMSE=0.120112 MAE=0.071492 | val MSE=0.110811 RMSE=0.332883 MAE=0.190999\n",
            "  >> Saved best model (val MSE=0.110811)\n",
            "[Epoch 82/100] TF=1.00 | train MSE=0.014339 RMSE=0.119744 MAE=0.071126 | val MSE=0.119174 RMSE=0.345217 MAE=0.195607\n",
            "[Epoch 83/100] TF=1.00 | train MSE=0.014300 RMSE=0.119583 MAE=0.071022 | val MSE=0.119190 RMSE=0.345239 MAE=0.197480\n",
            "[Epoch 84/100] TF=1.00 | train MSE=0.014355 RMSE=0.119812 MAE=0.071321 | val MSE=0.116384 RMSE=0.341151 MAE=0.194351\n",
            "[Epoch 85/100] TF=1.00 | train MSE=0.014293 RMSE=0.119554 MAE=0.071006 | val MSE=0.120747 RMSE=0.347487 MAE=0.201441\n",
            "[Epoch 86/100] TF=1.00 | train MSE=0.014221 RMSE=0.119250 MAE=0.070839 | val MSE=0.121265 RMSE=0.348231 MAE=0.203149\n",
            "[Epoch 87/100] TF=1.00 | train MSE=0.014307 RMSE=0.119612 MAE=0.071126 | val MSE=0.113027 RMSE=0.336195 MAE=0.192892\n",
            "[Epoch 88/100] TF=1.00 | train MSE=0.014222 RMSE=0.119256 MAE=0.070985 | val MSE=0.113291 RMSE=0.336587 MAE=0.195549\n",
            "[Epoch 89/100] TF=1.00 | train MSE=0.014265 RMSE=0.119437 MAE=0.071028 | val MSE=0.122216 RMSE=0.349593 MAE=0.198257\n",
            "[Epoch 90/100] TF=1.00 | train MSE=0.014205 RMSE=0.119187 MAE=0.070854 | val MSE=0.118818 RMSE=0.344700 MAE=0.197160\n",
            "[Epoch 91/100] TF=1.00 | train MSE=0.014159 RMSE=0.118992 MAE=0.070707 | val MSE=0.117636 RMSE=0.342981 MAE=0.195162\n",
            "[Epoch 92/100] TF=1.00 | train MSE=0.014166 RMSE=0.119021 MAE=0.070767 | val MSE=0.118506 RMSE=0.344247 MAE=0.197851\n",
            "[Epoch 93/100] TF=1.00 | train MSE=0.014147 RMSE=0.118940 MAE=0.070700 | val MSE=0.116417 RMSE=0.341200 MAE=0.196049\n",
            "[Epoch 94/100] TF=1.00 | train MSE=0.014053 RMSE=0.118546 MAE=0.070354 | val MSE=0.126088 RMSE=0.355089 MAE=0.197035\n",
            "[Epoch 95/100] TF=1.00 | train MSE=0.014071 RMSE=0.118621 MAE=0.070437 | val MSE=0.110933 RMSE=0.333066 MAE=0.192026\n",
            "[Epoch 96/100] TF=1.00 | train MSE=0.014067 RMSE=0.118606 MAE=0.070448 | val MSE=0.122528 RMSE=0.350039 MAE=0.203064\n",
            "[Epoch 97/100] TF=1.00 | train MSE=0.013987 RMSE=0.118268 MAE=0.070179 | val MSE=0.121329 RMSE=0.348324 MAE=0.200829\n",
            "[Epoch 98/100] TF=1.00 | train MSE=0.013977 RMSE=0.118226 MAE=0.070126 | val MSE=0.120179 RMSE=0.346668 MAE=0.200023\n",
            "[Epoch 99/100] TF=1.00 | train MSE=0.013967 RMSE=0.118182 MAE=0.070227 | val MSE=0.120601 RMSE=0.347277 MAE=0.201153\n",
            "[Epoch 100/100] TF=1.00 | train MSE=0.013958 RMSE=0.118142 MAE=0.070182 | val MSE=0.110817 RMSE=0.332891 MAE=0.188727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD9eMW6D2Zdd",
        "outputId": "da28de54-79e7-4cc8-ff58-cb9319e9b2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvSeq2Seq(\n",
            "  (enc): RecurrentStack(\n",
            "    (layers): ModuleList(\n",
            "      (0): ConvGRUCell(\n",
            "        (z): Conv2d(37, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (r): Conv2d(37, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (h): Conv2d(37, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (ln_z): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
            "        (ln_r): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
            "        (ln_h): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dec): RecurrentStack(\n",
            "    (layers): ModuleList(\n",
            "      (0): ConvGRUCell(\n",
            "        (z): Conv2d(37, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (r): Conv2d(37, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (h): Conv2d(37, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (ln_z): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
            "        (ln_r): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
            "        (ln_h): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): UNetHead(\n",
            "    (enc1): DoubleConv(\n",
            "      (net): Sequential(\n",
            "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (enc2): DoubleConv(\n",
            "      (net): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (mid): DoubleConv(\n",
            "      (net): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (up2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (dec2): DoubleConv(\n",
            "      (net): Sequential(\n",
            "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (up1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (dec1): DoubleConv(\n",
            "      (net): Sequential(\n",
            "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (out): Conv2d(32, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_cfg = TrainConfig(\n",
        "        data_dir=\"./\",\n",
        "        max_epochs=100,\n",
        "        batch_size=2,\n",
        "        enc_cell_type=\"convlstm\",\n",
        "        dec_cell_type=\"convlstm\",\n",
        "        n_enc_layers=1,\n",
        "        n_dec_layers=1,\n",
        "        enable_tf_ratio=False,\n",
        "        layernorm=True,\n",
        "        peephole=False,\n",
        "        unet_head=False,\n",
        "        out_root=\"./runs\",\n",
        "        viz_every_n_epochs=10,     # 每 10 个 epoch 可视化一次（train+eval）\n",
        "        viz_use_last_t=True,       # 可切换 False 以随机时间步\n",
        "        viz_channel=None,          # None=随机通道；也可设 0/1/2...\n",
        "        save_all_channels_png=True\n",
        "    )\n",
        "lstm_model, lstm_history = train(lstm_cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "id": "_frBnFE02-Gz",
        "outputId": "48c5d8ea-48cd-47bb-f8f2-d970d6885325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据集总数: 119 | 训练集: 95 | 验证集: 24\n",
            "[Epoch 1/100] TF=1.00 | train MSE=0.375060 | val MSE=0.310306\n",
            "  >> Saved best model (val MSE=0.310306)\n",
            "[Epoch 2/100] TF=1.00 | train MSE=0.119030 | val MSE=0.221961\n",
            "  >> Saved best model (val MSE=0.221961)\n",
            "[Epoch 3/100] TF=1.00 | train MSE=0.055772 | val MSE=0.198284\n",
            "  >> Saved best model (val MSE=0.198284)\n",
            "[Epoch 4/100] TF=1.00 | train MSE=0.039263 | val MSE=0.181580\n",
            "  >> Saved best model (val MSE=0.181580)\n",
            "[Epoch 5/100] TF=1.00 | train MSE=0.032847 | val MSE=0.168140\n",
            "  >> Saved best model (val MSE=0.168140)\n",
            "[Epoch 6/100] TF=1.00 | train MSE=0.029480 | val MSE=0.175374\n",
            "[Epoch 7/100] TF=1.00 | train MSE=0.027318 | val MSE=0.160536\n",
            "  >> Saved best model (val MSE=0.160536)\n",
            "[Epoch 8/100] TF=1.00 | train MSE=0.025808 | val MSE=0.159731\n",
            "  >> Saved best model (val MSE=0.159731)\n",
            "[Epoch 9/100] TF=1.00 | train MSE=0.024653 | val MSE=0.148896\n",
            "  >> Saved best model (val MSE=0.148896)\n",
            "[Epoch 10/100] TF=1.00 | train MSE=0.023757 | val MSE=0.151932\n",
            "[Epoch 11/100] TF=1.00 | train MSE=0.023072 | val MSE=0.150141\n",
            "[Epoch 12/100] TF=1.00 | train MSE=0.022409 | val MSE=0.150173\n",
            "[Epoch 13/100] TF=1.00 | train MSE=0.021918 | val MSE=0.148755\n",
            "  >> Saved best model (val MSE=0.148755)\n",
            "[Epoch 14/100] TF=1.00 | train MSE=0.021460 | val MSE=0.143151\n",
            "  >> Saved best model (val MSE=0.143151)\n",
            "[Epoch 15/100] TF=1.00 | train MSE=0.021081 | val MSE=0.149342\n",
            "[Epoch 16/100] TF=1.00 | train MSE=0.020690 | val MSE=0.156438\n",
            "[Epoch 17/100] TF=1.00 | train MSE=0.020505 | val MSE=0.139946\n",
            "  >> Saved best model (val MSE=0.139946)\n",
            "[Epoch 18/100] TF=1.00 | train MSE=0.020040 | val MSE=0.135543\n",
            "  >> Saved best model (val MSE=0.135543)\n",
            "[Epoch 19/100] TF=1.00 | train MSE=0.019817 | val MSE=0.141709\n",
            "[Epoch 20/100] TF=1.00 | train MSE=0.019504 | val MSE=0.144342\n",
            "[Epoch 21/100] TF=1.00 | train MSE=0.019329 | val MSE=0.139541\n",
            "[Epoch 22/100] TF=1.00 | train MSE=0.019062 | val MSE=0.146115\n",
            "[Epoch 23/100] TF=1.00 | train MSE=0.018836 | val MSE=0.138076\n",
            "[Epoch 24/100] TF=1.00 | train MSE=0.018631 | val MSE=0.137680\n",
            "[Epoch 25/100] TF=1.00 | train MSE=0.018443 | val MSE=0.142870\n",
            "[Epoch 26/100] TF=1.00 | train MSE=0.018260 | val MSE=0.133153\n",
            "  >> Saved best model (val MSE=0.133153)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1852434259.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msave_all_channels_png\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1458676453.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_forcing_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                 \u001b[0mval_loss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mc_loss_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mper_channel_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "dataset = ERA5ZInOutDataset(\n",
        "    data_dir=\"./\",\n",
        "    z_name=\"Z_2020_seq24.npy\",\n",
        "    meta_name=\"Z_2020_seq24_meta.npz\",\n",
        "    stats_name=\"Z_2020_norm_stats_2020.npz\",\n",
        "    normalize=True,\n",
        ")\n",
        "\n",
        "print(f\"Dataset size: {len(dataset)} 条样本\")\n",
        "print(\n",
        "    f\"每条输入 patch: (T_in={dataset.input_len}, C={dataset.C}, \"\n",
        "    f\"Hc={dataset.H}, Wc={dataset.W})\"\n",
        ")\n",
        "\n",
        "# ---- 2. DataLoader ----\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2,     # patch 很小\n",
        "    shuffle=True,\n",
        "    num_workers=0,    # 先 0，稳定了再开多进程！！小心这个东西，我不知道怎么选\n",
        "    pin_memory=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_EfHCx_PCTM",
        "outputId": "15495634-d5d0-4c86-d1b5-96bc1334dd15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Dataset size: 119 条样本\n",
            "每条输入 patch: (T_in=16, C=5, Hc=121, Wc=240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvRNNCell(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3,\n",
        "                 bias: bool = True, layernorm: bool = False):\n",
        "        super().__init__()\n",
        "        p = kernel_size // 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.conv = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        self.ln = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
        "        h = torch.tanh(self.ln(self.conv(torch.cat([x, h_prev], dim=1))))\n",
        "        return h\n",
        "\n",
        "    def init_hidden(self, B, H, W, device=None, dtype=None):\n",
        "        return torch.zeros(B, self.hidden_dim, H, W, device=device, dtype=dtype)\n",
        "\n",
        "\n",
        "\n",
        "class ConvGRUCell(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3,\n",
        "                 bias: bool = True, layernorm: bool = False):\n",
        "        super().__init__()\n",
        "        p = kernel_size // 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.z = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        self.r = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        self.h = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        # 对门前激活/候选做LN（可选）\n",
        "        self.ln_z = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_r = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_h = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
        "        xh = torch.cat([x, h_prev], dim=1)\n",
        "        z = torch.sigmoid(self.ln_z(self.z(xh)))\n",
        "        r = torch.sigmoid(self.ln_r(self.r(xh)))\n",
        "        xrh = torch.cat([x, r * h_prev], dim=1)\n",
        "        h_tilde = torch.tanh(self.ln_h(self.h(xrh)))\n",
        "        h = (1 - z) * h_prev + z * h_tilde\n",
        "        return h\n",
        "\n",
        "    def init_hidden(self, B, H, W, device=None, dtype=None):\n",
        "        return torch.zeros(B, self.hidden_dim, H, W, device=device, dtype=dtype)\n",
        "\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3,\n",
        "                 bias: bool = True, layernorm: bool = False, peephole: bool = False):\n",
        "        super().__init__()\n",
        "        p = kernel_size // 2\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.peephole = peephole\n",
        "\n",
        "        self.conv = nn.Conv2d(input_dim + hidden_dim, 4 * hidden_dim, kernel_size, padding=p, bias=bias)\n",
        "        # LN 应用于 i,f,o,g 的 pre-activations\n",
        "        self.ln_i = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_f = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_o = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "        self.ln_g = layer_norm_2d(hidden_dim) if layernorm else nn.Identity()\n",
        "\n",
        "        if peephole:\n",
        "            self.Wci = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "            self.Wcf = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "            self.Wco = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor, c_prev: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        gates = self.conv(torch.cat([x, h_prev], dim=1))\n",
        "        i, f, o, g = torch.split(gates, self.hidden_dim, dim=1)\n",
        "\n",
        "        # LN\n",
        "        i = self.ln_i(i); f = self.ln_f(f); o = self.ln_o(o); g = self.ln_g(g)\n",
        "\n",
        "        # Peephole on i,f (c_prev)\n",
        "        if self.peephole:\n",
        "            i = torch.sigmoid(i + self.Wci * c_prev)\n",
        "            f = torch.sigmoid(f + self.Wcf * c_prev)\n",
        "        else:\n",
        "            i = torch.sigmoid(i)\n",
        "            f = torch.sigmoid(f)\n",
        "\n",
        "        g = torch.tanh(g)\n",
        "        c = f * c_prev + i * g\n",
        "\n",
        "        # Peephole on o (c_new)\n",
        "        if self.peephole:\n",
        "            o = torch.sigmoid(o + self.Wco * c)\n",
        "        else:\n",
        "            o = torch.sigmoid(o)\n",
        "\n",
        "        h = o * torch.tanh(c)\n",
        "        return h, c\n",
        "\n",
        "    def init_hidden(self, B, H, W, device=None, dtype=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        h = torch.zeros(B, self.hidden_dim, H, W, device=device, dtype=dtype)\n",
        "        c = torch.zeros(B, self.hidden_dim, H, W, device=device, dtype=dtype)\n",
        "        return h, c\n"
      ],
      "metadata": {
        "id": "TSAkg5YPcd0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conv_cells.py\n",
        "# -*- coding: utf-8 -*-\n",
        "from typing import Tuple, Optional\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1) 标准 ConvRNN (Elman RNN with Conv)\n",
        "#    h_t = tanh( W * [x_t, h_{t-1}] )\n",
        "# ============================================================\n",
        "class ConvRNNCell(nn.Module):\n",
        "    \"\"\"\n",
        "    标准卷积RNN单元（tanh 激活）。\n",
        "    Args:\n",
        "        input_dim: 输入通道数 C_in\n",
        "        hidden_dim: 隐状态通道数 C_h\n",
        "        kernel_size: 卷积核大小（奇数）\n",
        "        bias: 是否使用偏置\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3, bias: bool = True):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.conv = nn.Conv2d(input_dim + hidden_dim, hidden_dim,\n",
        "                              kernel_size=kernel_size, padding=padding, bias=bias)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x:      (B, C_in, H, W)\n",
        "        h_prev: (B, C_h,  H, W)\n",
        "        return: h_new (B, C_h, H, W)\n",
        "        \"\"\"\n",
        "        combined = torch.cat([x, h_prev], dim=1)\n",
        "        h_new = torch.tanh(self.conv(combined))\n",
        "        return h_new\n",
        "\n",
        "    def init_hidden(self, batch: int, height: int, width: int, device=None, dtype=None) -> torch.Tensor:\n",
        "        return torch.zeros(batch, self.hidden_dim, height, width, device=device, dtype=dtype)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2) 标准 ConvGRU\n",
        "#    z_t = σ(Wz * [x, h])\n",
        "#    r_t = σ(Wr * [x, h])\n",
        "#    h~_t = tanh(Wh * [x, r⊙h])\n",
        "#    h_t = (1 - z) ⊙ h + z ⊙ h~\n",
        "# ============================================================\n",
        "class ConvGRUCell(nn.Module):\n",
        "    \"\"\"\n",
        "    标准 ConvGRU 单元。\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3, bias: bool = True):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.conv_z = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=padding, bias=bias)\n",
        "        self.conv_r = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=padding, bias=bias)\n",
        "        self.conv_h = nn.Conv2d(input_dim + hidden_dim, hidden_dim, kernel_size, padding=padding, bias=bias)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        x:      (B, C_in, H, W)\n",
        "        h_prev: (B, C_h,  H, W)\n",
        "        return: h_new (B, C_h, H, W)\n",
        "        \"\"\"\n",
        "        xh = torch.cat([x, h_prev], dim=1)\n",
        "        z = torch.sigmoid(self.conv_z(xh))\n",
        "        r = torch.sigmoid(self.conv_r(xh))\n",
        "        xrh = torch.cat([x, r * h_prev], dim=1)\n",
        "        h_tilde = torch.tanh(self.conv_h(xrh))\n",
        "        h_new = (1 - z) * h_prev + z * h_tilde\n",
        "        return h_new\n",
        "\n",
        "    def init_hidden(self, batch: int, height: int, width: int, device=None, dtype=None) -> torch.Tensor:\n",
        "        return torch.zeros(batch, self.hidden_dim, height, width, device=device, dtype=dtype)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3) 标准 ConvLSTM（可选 peephole）\n",
        "#    i = σ(W_i * [x, h] + peephole(c_{t-1}))\n",
        "#    f = σ(W_f * [x, h] + peephole(c_{t-1}))\n",
        "#    g = tanh(W_g * [x, h])\n",
        "#    c = f⊙c_prev + i⊙g\n",
        "#    o = σ(W_o * [x, h] + peephole(c))\n",
        "#    h = o⊙tanh(c)\n",
        "# ============================================================\n",
        "class ConvLSTMCell(nn.Module):\n",
        "    \"\"\"\n",
        "    标准 ConvLSTM 单元（可选 peephole）。\n",
        "    Args:\n",
        "        input_dim: 输入通道数\n",
        "        hidden_dim: 隐状态/细胞状态通道数\n",
        "        kernel_size: 卷积核\n",
        "        bias: 偏置\n",
        "        peephole: 是否启用 peephole 连接（对 i,f,o 门引入 c 的逐元素作用）\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, kernel_size: int = 3,\n",
        "                 bias: bool = True, peephole: bool = False):\n",
        "        super().__init__()\n",
        "        padding = kernel_size // 2\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.peephole = peephole\n",
        "\n",
        "        # 一次卷积得到 4 * hidden: i, f, o, g\n",
        "        self.conv = nn.Conv2d(input_dim + hidden_dim, 4 * hidden_dim,\n",
        "                              kernel_size=kernel_size, padding=padding, bias=bias)\n",
        "\n",
        "        if peephole:\n",
        "            # peephole 参数，逐通道、逐空间共享（C_h,1,1）\n",
        "            self.Wci = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "            self.Wcf = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "            self.Wco = nn.Parameter(torch.zeros(1, hidden_dim, 1, 1))\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h_prev: torch.Tensor, c_prev: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        x:      (B, C_in, H, W)\n",
        "        h_prev: (B, C_h,  H, W)\n",
        "        c_prev: (B, C_h,  H, W)\n",
        "        return: (h_new, c_new)\n",
        "        \"\"\"\n",
        "        combined = torch.cat([x, h_prev], dim=1)\n",
        "        gates = self.conv(combined)\n",
        "        i, f, o, g = torch.split(gates, self.hidden_dim, dim=1)\n",
        "\n",
        "        if self.peephole:\n",
        "            # peephole: i,f 使用 c_prev；o 使用 c_new（因此先算 c_new 前要暂存）\n",
        "            i = torch.sigmoid(i + self.Wci * c_prev)\n",
        "            f = torch.sigmoid(f + self.Wcf * c_prev)\n",
        "        else:\n",
        "            i = torch.sigmoid(i)\n",
        "            f = torch.sigmoid(f)\n",
        "\n",
        "        g = torch.tanh(g)\n",
        "        c_new = f * c_prev + i * g\n",
        "\n",
        "        if self.peephole:\n",
        "            o = torch.sigmoid(o + self.Wco * c_new)\n",
        "        else:\n",
        "            o = torch.sigmoid(o)\n",
        "\n",
        "        h_new = o * torch.tanh(c_new)\n",
        "        return h_new, c_new\n",
        "\n",
        "    def init_hidden(self, batch: int, height: int, width: int, device=None, dtype=None) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        h = torch.zeros(batch, self.hidden_dim, height, width, device=device, dtype=dtype)\n",
        "        c = torch.zeros(batch, self.hidden_dim, height, width, device=device, dtype=dtype)\n",
        "        return h, c\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# （可选）小测试：确保能前向\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    B, C_in, H, W = 2, 5, 32, 64\n",
        "    C_h = 16\n",
        "    x = torch.randn(B, C_in, H, W)\n",
        "\n",
        "    # ConvRNN\n",
        "    rnn = ConvRNNCell(C_in, C_h, 3)\n",
        "    h0 = rnn.init_hidden(B, H, W, device=x.device, dtype=x.dtype)\n",
        "    h1 = rnn(x, h0)\n",
        "    print(\"ConvRNN:\", h1.shape)\n",
        "\n",
        "    # ConvGRU\n",
        "    gru = ConvGRUCell(C_in, C_h, 3)\n",
        "    h0 = gru.init_hidden(B, H, W, device=x.device, dtype=x.dtype)\n",
        "    h1 = gru(x, h0)\n",
        "    print(\"ConvGRU:\", h1.shape)\n",
        "\n",
        "    # ConvLSTM (peephole off)\n",
        "    lstm = ConvLSTMCell(C_in, C_h, 3, peephole=False)\n",
        "    h0, c0 = lstm.init_hidden(B, H, W, device=x.device, dtype=x.dtype)\n",
        "    h1, c1 = lstm(x, h0, c0)\n",
        "    print(\"ConvLSTM (no peephole):\", h1.shape, c1.shape)\n",
        "\n",
        "    # ConvLSTM (peephole on)\n",
        "    lstm_p = ConvLSTMCell(C_in, C_h, 3, peephole=True)\n",
        "    h0, c0 = lstm_p.init_hidden(B, H, W, device=x.device, dtype=x.dtype)\n",
        "    h1, c1 = lstm_p(x, h0, c0)\n",
        "    print(\"ConvLSTM (peephole):\", h1.shape, c1.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rr7whUYVTOxh",
        "outputId": "53ed340b-54e1-49e8-864b-403379e9ed1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvRNN: torch.Size([2, 16, 32, 64])\n",
            "ConvGRU: torch.Size([2, 16, 32, 64])\n",
            "ConvLSTM (no peephole): torch.Size([2, 16, 32, 64]) torch.Size([2, 16, 32, 64])\n",
            "ConvLSTM (peephole): torch.Size([2, 16, 32, 64]) torch.Size([2, 16, 32, 64])\n"
          ]
        }
      ]
    }
  ]
}